\chapter{Generación de imágenes por computadora} % 20 páginas mas o menos...

\section{Introducción}

Este proyecto aborda la generación de imágenes fotorealistas en tiempos de cálculo bajos, que es una problemática actual de la computación gráfica. Existen muchos algoritmos para la generación de imágenes fotorrealistas, esto se evidencia por la cantidad de películas de animación con modelos 3D o que simplemente utilizan efectos 3D para realzar las escenas. Un tema importante es el tiempo de procesamiento que requieren este tipo de técnicas, cada una de las imágenes que se van a incluir en la versión final de la película implican varios minutos u horas dependiendo de la complejidad de la imagen a generar. Estos tiempos dependen de si la escena tiene reflejos o no, si tiene transparencias, si tiene muchos fragmentos pequeños de objetos, entre otros aspectos de calidad del modelo 3D a mostrar en la pantalla. No sólo es un problema los tiempos que se requieren para generar las imágenes, sino que además estas imágenes requieren de una capacidad de cómputo enorme. Por esto, en general, se utilizan potentes \emph{clusters} de computadoras para realizar la generación de las imágenes.

Para comprender la forma en que se generan las imágenes foto-realistas por computadora es necesario conocer en profundidad: cómo se especifican los modelos y cuáles son las formas en que se puede, a partir de los modelos, generar las imágenes. En las siguientes secciones se introducen dichas temáticas, abordando conceptos esenciales tales como: qué es una escena y los algoritmos comúnmente utilizados para generar imágenes. También se mostrarán los modelos para la iluminación que se utilizan, así como la clasificación de los algoritmos en base a estos modelos.


\subsection{Concepto de escena}
Una escena, en computación gráfica, es una colección de objetos y fuentes de luz que será vista por medio de una cámara. Cada una de estas partes está colocada en lo que se llama ``mundo'', que es un espacio resultante de modelar cuerpos tridimensionales en una imagen bidimensional \cite{Hearn88}. Por ejemplo, si se quiere una imagen de una habitación con una mesa, la escena debe estar compuesta por dos objetos principales que representen la habitación y la mesa, una o más fuentes de luz, y la cámara, que es desde donde se ve la escena.

Cada objeto de una escena es una ``primitiva geométrica'', que por lo general es una figura geométrica simple como un polígono, una esfera ó un cono. Sin embargo las primitivas en una escena pueden ser matemáticamente más complejas, algunos ejemplos pueden ser superficies de Bezier, sub-divisiones de superficies, superficies ISO, etc. Casi cualquier tipo de objeto puede ser usado como primitiva de una escena.

\subsection{Trazado de rayos}
Un rayo es por lo general representado mediante un punto de origen $O$ y una dirección $D$, $R(t) = O + tD$. En el marco de un algoritmo que traza rayos hay fundamentalmente tres problemas que deben ser resueltos: encontrar la intersección más cercana al origen del rayo $O$, encontrar alguna intersección a lo largo del rayo\footnote{Se define $t_{max}$, si $t > t_{max}$ no se consideran las intersecciones.} y encontrar todas las intersecciones a lo largo de él.
La clave de la eficiencia de cualquier tipo de algoritmo trazador de rayos es encontrar eficientemente la intersección de un rayo con una escena compuesta por una lista de primitivas geométricas.

La operación más utilizada en este tipo de algoritmos es obtener la in\-ter\-sec\-ción más cercana al origen del rayo. Los datos que se requieren son la primitiva $P$ más cercana que interseca con el rayo y la distancia $t_{hit}$ desde $O$ al punto de intersección. Además pueden determinarse otros pa\-r\'a\-me\-tros opcionales que serán utilizados en pasos posteriores del algoritmo, como pueden ser propiedades de la superficie o la normal a la misma en el punto de intersección.
Para la mayor parte de las primitivas usadas al construir una escena se dispone de diferentes algoritmos que evalúan la intersección con un rayo. Cada uno de los algoritmos tiene ventajas y desventajas respecto a propiedades como tiempo de ejecución, mantenibilidad, precisión o robustez lo cual hace que no resulte fácil la elección del mismo \cite{RealTimeRendering02}. Las escenas serán entonces aptas para un algoritmo de trazas mientras sea posible evaluar su intersección con un rayo.

La segunda operación por orden de relevancia es la que determina si existe alguna intersección a lo largo del rayo. El problema que surge a partir de esta operación es igual a la prueba de visibilidad entre dos puntos, en este caso los puntos son: $O$ y $O + t_{max}D$. Encontrar si existe alguna intersección en el camino del rayo es un problema más simple que encontrar la intersección más cercana. Si bien puede emplearse el mismo procedimiento que para encontrar la intersección más cercana, existen algoritmos más eficientes que resuelven este caso especial de trazado de rayo.

El tercer problema, encontrar todas las intersecciones a lo largo de un rayo, es el menos empleado y sólo es requerido para algoritmos de iluminación avanzados. Este problema no es común en los algoritmos trazadores de rayos, excepto para los que implementan modelos de iluminación especiales.


\section{Modelos computacionales de iluminación}
En esta sección se abordan las técnicas más populares para la generación de imágenes foto-realistas, comenzando por los algoritmos en el que se basan la mayoría de los algoritmos actuales:\emph{ray casting} de Appel \cite{Appel1968} y \emph{ray tracing} de Whitted \cite{PaperDel80}. Hay que tener en cuenta que estos algoritmos no son los algoritmos más rápidos para la generación de imágenes. La técnica más popular para la generación de gráficos tridimensionales por computadora es ras\-te\-ri\-za\-ción que funciona en tiempo real. La técnica es simplemente el proceso de computar la correspondencia entre la geometría de la escena y los píxeles de la imagen y no tiene una forma particular de computar el color de esos píxeles. Esta técnica no tiene en cuenta el cálculo de sombras ni las re\-fle\-xio\-nes entre objetos, como si lo hace, entre otros \emph{ray tracing}. Una de las implementaciones más usadas de la ras\-te\-ri\-za\-ción es \emph{scan lines} \cite{LibroCompGrafica}.

\subsection{\emph{Ray casting}}
El algoritmo de \emph{ray casting} fue introducido por Arthur Appel en 1968 \cite{Appel1968}. Es un algoritmo cuyo funcionamiento se basa en lanzar rayos desde el punto de vista del observador hacia un plano de vista que se encuentra entre el observador y la escena. La unidad mínima de visualización en los dispositivos actuales (monitores o dispositivos similares) es el píxel, cada uno de los cuadros de la grilla en la que se basa la vi\-sua\-li\-za\-ción de imágenes. Por esto, el algoritmo genera tantos rayos como píxeles haya en el dispositivo de visualización a utilizar. También puede ser que se tenga un tamaño de imagen en píxeles, en este caso se genera un rayo por cada píxel de la imagen a generar. Las coordenadas de los píxeles se mapean a coordenadas del plano de vista, lanzando un rayo desde el punto de vista del observador que pase por la coordenada del plano de vista y calculando el punto de intersección con la escena, en caso de haberlo. Luego de hallado el punto de intersección con la escena se procede a calcular cuánta energía le llega al punto desde las fuentes de luz, sin tener en cuenta los posibles ``rebotes'' de la luz, como tampoco la posibilidad de que un objeto se encuentre interpuesto entre el objeto y la fuente de luz. Este algoritmo permite calcular fácilmente cuales son los objetos visibles además de facilitar la inclusión de objetos geométricos no planares en las escenas. Este último hecho, en el momento que se propuso el algoritmo, fue muy novedoso porque con los algoritmos que se utilizaban en la generación de gráficos no era posible incluir este tipo de objetos de forma sencilla. Los algoritmos utilizados en esa época eran algoritmos de \emph{scan lines}, que se basan en rasterización mientras que en el algoritmo de \emph{ray casting} los rayos no van más allá del primer objeto encontrado.


\subsection{Clasificación de los algoritmos de generación de imágenes por computadora}

Todos los algoritmos de generación de imágenes, independientemente de la categoría en la que se encuentren, dada una escena, definición matemática o algún tipo de representación abstracta, buscan generar una imagen. En el trabajo se referencia siempre al concepto de generación de imágenes realistas aunque los mismos algoritmos podrían ser utilizados para generar otro tipo de escenas. No obstante la diferencia de enfoque de los algoritmos, todos buscan de alguna manera modelar la cantidad de energía lumínica, o radiancia, que está presente en cada punto de los distintos objetos que forman la escena, y así poder calcular de que manera se debería ver la imagen según los parámetros de iluminación que se establezcan. Los distintos modelos para calcular la iluminación que se identifican son los siguientes:

\begin{itemize}
\item el modelo planteado por Whitted, es el modelo más simple de iluminación y es de iluminación local.

\item el modelo basado en elementos finitos, es bastante simple al igual que el modelo de Whitted pero a su vez muy diferente, ya que para calcular la radiancia plantea la división de la escena en pequeñas partes y utiliza alguna solución numérica para aproximar los valores \cite{LibroCompGrafica}. Además, es un modelo de iluminación global.

\item el modelo basado en métodos de Monte Carlo, el cual busca aproximar los valores de radiancia empleando aproximaciones estadísticas basadas en la integración de Monte Carlo \cite{Jensen2001}. Además, es un modelo de iluminación global. Dentro de los algoritmos que usan este tipo de métodos se encuentra su mayor exponente actualmente en el algoritmo de \emph{photon mapping} \cite{Jensen2001}.
\end{itemize}

Los algoritmos de generación de imágenes, que surgen en base al algoritmo original de \emph{ray casting} y que emplean alguno de los modelos descritos anteriormente para el cálculo de la iluminación, pueden ser clasificados utilizando distintas estrategias, en este trabajo se presentan agrupados por el modelo de iluminación utilizado. Entonces, se identifican dos categorías de algoritmos:

\begin{itemize}
  \item algoritmos de iluminación local: incluye los algoritmos que utilizan el modelo simple de iluminación local diseñado por Whitted.
  \item algoritmos de iluminación global: incluye los algoritmos que utilizan el modelo basado en elementos finitos o el basado en métodos de Monte Carlo.
\end{itemize}

Para cada modelo de iluminación presentado se describirá el algoritmo más representativo disponible. Estas técnicas que se presentan son: \emph{ray tracing} para el modelo de Whitted, radiosidad para los algoritmos basados en elementos finitos y \emph{photon mapping} para los basados en métodos de Monte Carlo.

\subsubsection{\emph{Ray tracing}}
El algoritmo de \emph{ray tracing} propuesto por Turner Whitted en 1980 \cite{PaperDel80} está basado en el algoritmo de \emph{ray casting}. Whitted extendió la idea proponiendo hacer la traza de rayos recursiva. Entonces el algoritmo no termina cuando el rayo encuentra un objeto en su trayectoria, sino que en ese momento se hace la invocación recursiva del trazado de rayo, desde el punto de la intersección en caso de ser necesario. Con la posibilidad de la invocación recursiva del algoritmo se añade la capacidad de sombreado realista dado que se puede calcular la interposición de otros objetos de la escena entre el objeto y la luz.
Al igual que \emph{ray casting} es un algoritmo sencillo para la ge\-ne\-ra\-ción de imágenes, que tiene un modelo de iluminación propio que se basa en emular las características que cumple la luz al llegar a los objetos o al cambiar de un medio de transmisión a otro. Por ejemplo, al pasar del aire al agua, se genera una desviación de la luz, dando la impresión de que los objetos se deforman. Asimismo, introduce los conceptos de reflexión a las imágenes, admitiendo objetos que reflejan luz en las escenas, obteniendo un grado de realismo visual superior al generado por \emph{ray casting}.


\subsubsection{Radiosidad}
El algoritmo de radiosidad utiliza los principios de \emph{ray tracing} para el cálculo de las superficies visibles y sombras, así como las reflexiones y refracciones pero a diferencia del algoritmo de \emph{ray tracing} básico plantea que para hacer el cálculo de la iluminación es necesario precalcular los valores de iluminación en cada uno de los parches en los que se divide arbitrariamente la escena, por esta división es que este es un método de elementos finitos. Luego de realizado el cálculo de la radiancia de cada uno de los parches se utiliza un rastreo de la escena para el cálculo de los valores de color de los píxeles de la imagen que se quiere generar. Como se precalculan los valores de iluminación en toda la escena se pueden utilizar los mismos valores de radiancia precalculados para generar imágenes desde distintos puntos de vista (variando la posición de la cámara), mientras no se modifique la escena y ni las fuentes de luz.

\subsubsection{\emph{Photon mapping}}

El algoritmo de \emph{photon mapping} fue introducido por Henrik Wan Jensen en el año 1996\cite{Jensen2001}. La técnica ha evolucionado fuertemente en los últimos años y genera imágenes con una calidad excelente, además de ser menos costosa, en tiempo de cómputo, que el algoritmo de radiosidad. En lugar de utilizar el modelo de elementos finitos utiliza un modelo basado en métodos de Monte Carlo para el cálculo de la cantidad de energía en cada punto.
El algoritmo de \emph{photon mapping} tiene dos etapas diferenciadas al igual que el algoritmo de radiosidad, pero tiene una aproximación distinta para el cálculo de la radiancia de los puntos. La primera pasada es similar a la recorrida de la escena por el algoritmo de \emph{ray tracing} con la diferencia que sigue el sentido inverso. Esta primer pasada se llama emisión de fotones, se generan fotones que son lanzados desde los emisores de luz hacia la escena en direcciones que sean factibles, cuantos más fotones se generen más fiable será el resultado de la iluminación. Se calcula el lugar en el que el fotón incide en la escena recursivamente de manera análoga al algoritmo de \emph{ray tracing}. Esto es debido a que en el caso de los objetos reales, estos no absorben toda la luz incidente sino que hay luz que es reflejada y por lo tanto fotones son vueltos a lanzar desde el punto en el que chocaron con un objeto. Para hallar la dirección con la que es emitido el nuevo fotón y la energía que tendrá el mismo se utiliza un modelo para los materiales de los objetos de la escena teniendo que agregar al material de los objetos una función de BRDF (Función de Distribución de Reflectancia Bidireccional). Esta función representa la proporción de radiación reflejada por una determinada superficie en cada dirección del rayo reflejado, proyectada sobre el plano horizontal.


\section{\emph{Ray tracing}}

Este trabajo profundiza el estudio del algoritmo de \emph{ray tracing}, ya que por su simplicidad y versatilidad se presenta como la mejor alternativa para ser implementada. Además, este algoritmo puede verse como el padre de la familia de algoritmos actuales, tal como se presenta en la clasificación de algoritmos de generación de imagen.

En el algoritmo original de \emph{ray tracing}, además de considerar las fuentes de luz para obtener sombras en la escena, el algoritmo de trazado de rayos recursivo de Whitted genera rayos de reflexión y de refracción desde el punto de intersección, como se muestra en la Figura~\ref{fig:exampleRT}.

Los rayos de sombra ($L_{i}$), reflexión ($R_{i}$) y refracción ($T_{i}$) son llamados secundarios para diferenciarlos de los primarios que son los que salen desde el punto de vista del observador o cámara.

\begin{figure}[H]
  \centering
    \includegraphics[width=0.7\textwidth]{../DOC_Relevamiento/exampleRT}
  \caption{Generación de rayos del algoritmo de Whitted a partir de un único rayo primario.}
  \label{fig:exampleRT}
\end{figure}

En el primer nivel del algoritmo, cuando se traza un rayo primario, solo se tienen dos posibilidades: el rayo interseca con algún objeto de la escena o no lo hace. Si el rayo no encuentra ningún objeto en su camino, entonces, se debe usar el color de fondo de la escena para pintar ese píxel. Por el contrario, si encuentra un objeto en su trayectoria, se deben realizar los siguientes pasos en el punto de intersección:
\begin{itemize}
  \item Paso uno: para calcular las sombras, se traza un rayo de sombra ($L_{1}$) desde el punto de intersección del rayo con el objeto hacia cada fuente de luz existente en la escena. Si alguno de estos rayos interseca cualquier objeto en su camino hacia la fuente de luz, dependiendo del material del objeto se debe calcular la cantidad de luz que pasa a través de él. Si el objeto es opaco, como es el caso del objeto más pequeño de la Figura~\ref{fig:exampleRT}, la luz es bloqueada totalmente y el punto de intersección estará bajo la sombra del objeto. Esto quiere decir que esta fuente de luz no será tomada en cuenta para calcular la iluminación en el punto. Si el objeto es transparente, como es el caso del objeto más grande de la Figura~\ref{fig:exampleRT}, la intensidad de la fuente de luz se ve disminuida, incluso puede ser absorbida totalmente por el objeto. Existen tablas que indican que cantidad de luz es absorbida por cierto material transparente. En caso de que la luz no sea bloqueada totalmente por el objeto, esta contribuirá a la iluminación del punto de intersección del rayo primario.
  \item Paso dos: si el objeto tiene reflexión especular, como es el caso de la Figura~\ref{fig:exampleRT}, un rayo de reflexión es reflejado a partir del rayo primario, con respecto a la normal ($N_{1}$) en el punto de intersección, en la dirección del vector $R_{1}$. Este rayo permite obtener la cantidad de luz que llega al punto de intersección del rayo primario por el fenómeno de reflexión. Esta cantidad de luz puede verse afectada por el material del objeto, para considerar esto se usa un coeficiente dependiente del material, que escala la cantidad de luz.
  \item Paso tres: si el objeto es transparente, como es el caso de la Figura~\ref{fig:exampleRT} y no ocurre refracción total, es decir si la luz no es absorbida totalmente por la transparencia que posee el objeto, entonces un rayo de refracción es trazado a través del objeto siguiendo la dirección del vector $T_{1}$. Esta dirección es calculada usando la ley de Snell \cite{LibroCompGrafica}. Este rayo permite obtener la cantidad de luz que llega al punto de intersección del rayo primario por el fenómeno de refracción. Esta cantidad de luz puede verse afectada por el material del objeto, para considerar esto se usa un coeficiente dependiente del material, que escala la cantidad de luz.
\end{itemize}
Cada uno de los rayos de reflexión genera rayos de sombra, reflexión y refracción. Lo mismo sucede con cada uno de los de refracción. En el ejemplo de la Figura~\ref{fig:exampleRT}, para calcular la intensidad de luz aportada por $R_{1}$ se usan los mismos pasos que para calcular la intensidad aportada por el rayo primario. Por consiguiente los pasos dos y tres se deben calcular recursivamente. De esta manera se forma un árbol de rayos para cada rayo primario, como se muestra en la Figura~\ref{fig:TreeExample}.
\begin{figure}[H]
  \centering
    \includegraphics[width=0.4\textwidth]{../DOC_Relevamiento/TreeExample}
  \caption{Árbol de rayos que surge del ejemplo de la Figura~\ref{fig:exampleRT}.}
  \label{fig:TreeExample}
\end{figure}
La profundidad del árbol de rayos afecta directamente el tiempo de ejecución del algoritmo y la calidad de la imagen que se obtiene. Dicha profundidad está determinada por distintos aspectos como por ejemplo un máximo dispuesto por el usuario del algoritmo o por no haber intersección entre los rayos reflejados y refractados y algún objeto o por la capacidad de almacenamiento del sistema donde ejecuta el algoritmo.

Luego de obtener la cantidad de luz aportada por cada uno de los pasos anteriores, están dadas las condiciones para calcular la iluminación en el punto de intersección del rayo primario. Para esto se debe recorrer un árbol de rayos (por ejemplo el de la Figura~\ref{fig:TreeExample}) de abajo hacia arriba, aplicando la ecuación de iluminación desarrollada por Whitted.

La ecuación de Whitted que se presenta en la Ecuación \ref{eqn:EcIluWhitted}, considera tres componentes, la primera es la iluminación local, es decir, la iluminación dada por el ambiente y por las fuentes de luz de la escena pero sin considerar que los objetos reflejan o refractan luz. Esta primera parte usa la ecuación de iluminación de Phong \cite{LibroCompGrafica}. La segunda ($k_{s}I_{r\lambda}$) y la tercera ($k_{t}I_{t\lambda}$) componente consideran la reflexión y la refracción de los objetos respectivamente.

\begin{equation}
    I_{\lambda} = I_{a\lambda}k_{a}O_{d\lambda}
                + \sum_{1 \leq i \leq m} S_{i} f_{att_{i}} I_{p\lambda_{i}} [k_{d}O_{d\lambda}(\overline{N} \cdot \overline{L_{i}})
                                                                            + k_{s} (\overline{N} \cdot \overline{H_{i}})^n]
                + k_{s}I_{r\lambda}
                + k_{t}I_{t\lambda}
    \label{eqn:EcIluWhitted}
\end{equation}

En la siguiente lista se puede observar el significado de cada variable presente en la Ecuación \ref{eqn:EcIluWhitted}:
\begin{itemize}
  \item $I_{a\lambda}$ - Intensidad de la luz ambiente: luz que ha sido esparcida por todo el ambiente y es imposible determinar su origen, cuando golpea una superficie se esparce igualmente en todas direcciones.
  \item $k_{a}$ - Coeficiente de reflexión de luz ambiente: se encuentra entre 0 y 1. Determina la cantidad de luz ambiente reflejada por la superficie del objeto. Es una propiedad del material del objeto.
  \item $O_{d\lambda}$ - Componente difusa del color del objeto.
  \item $m$ - Cantidad de luces de la escena.
  \item $S_{i}$ - Indicador de sombra: indica si hay algún objeto entre la fuente de luz número $i$ y el punto de evaluación. Toma el valor 1 si la luz no está bloqueada y 0 en caso contrario.
  \item $f_{att_{i}}$ - Factor de atenuación para la luz número $i$: soluciona el problema de que dos superficies se vean iguales al estar a distinta distancia de una fuente de luz. Lo más común es usar el inverso del cuadrado de la distancia hacia la luz.
  \item $I_{p\lambda_{i}}$ - Intensidad de la fuente de luz número $i$ en el punto de evaluación.
  \item $k_{d}$ - Coeficiente de reflexión de luz difusa: se encuentra entre 0 y 1. Determina la cantidad de luz difusa reflejada por la superficie del objeto. Es una propiedad del material del objeto.
  \item $k_{s}$ - Coeficiente de reflexión de luz especular: se encuentra entre 0 y 1. Determina la cantidad de luz especular reflejada por la superficie del objeto. Es una propiedad del material del objeto.
  \item $\overline{H_{i}}$ - Vector de dirección media o vector de iluminación máxima: vector utilizado por la ecuación de iluminación de Phong \cite{LibroCompGrafica}. Se calcula como la dirección media entre el vector normal y el vector que indica la dirección del observador.
  \item $n$ - Exponente de ajuste de la iluminación: este exponente sirve para ajustar la imagen, no es un resultado teórico sino que es resultado de la observación empírica.
  \item $I_{r\lambda}$ - Intensidad del rayo reflejado: esta intensidad es determinada evaluando recursivamente la Ecuación \ref{eqn:EcIluWhitted}.
  \item $k_{t}$ - Coeficiente de trasmisión: se encuentra entre 0 y 1. Determina la cantidad de luz que pasa a través del objeto. Es una propiedad del material del objeto. Existen tablas con valores para distintos materiales.
  \item $I_{t\lambda}$ - Intensidad del rayo refractado: esta intensidad es determinada evaluando recursivamente la Ecuación \ref{eqn:EcIluWhitted}.
\end{itemize}

\subsubsection{Algoritmo de \emph{ray tracing}}

El algoritmo de \emph{ray tracing} tiene como ventajas la simplicidad de su implementación, así como también el realismo que logra frente a otros métodos como la Rasterización. Las simplificaciones que utiliza el modelo de iluminación no permiten que se generen envolventes de los rayos de luz reflejados o refractados por una superficie curva. A los efectos generados por este fenómeno se les llama cáusticas.

Otra simplificación en el cálculo de la iluminación es la introducción de un componente de color de ``luz ambiente'', luz que tiene origen en alguna fuente de luz desconocida y parece llegar de todas las direcciones, esto permite no calcular algunos rebotes de la luz en objetos de la escena que harían más complejo al algoritmo. Dada esta última simplificación tampoco se generan efectos de ``sangrado de luz'', este fenómeno es causado por la reflexión de luz de los objetos en forma parcial que hace que el color de una pared, por ejemplo, sea extendido por la zona del suelo cercana a la pared, dando la idea de que la pared ``sangra'' color sobre el suelo.

Una de las principales desventajas que muestra el algoritmo es el costo computacional, en especial en los modelos utilizados por la mayoría de las aplicaciones 3D basados en la ras\-te\-ri\-za\-ci\'on de imágenes formadas por polígonos. Por este motivo, \emph{ray tracing} no es una técnica utilizable para la aplicaciones que necesiten mostrar imágenes que se actualicen en tiempo real. Sin embargo, en los últimos tiempos se han desarrollado diferentes esfuerzos por alcanzar tiempo real en aplicaciones basadas en \emph{ray tracing}, como por ejemplo el \emph{framework} para video-juegos \emph{Quake Wars} \cite{QuakeWarsWebSite} que emplea el motor \emph{openRT} \cite{OpenRTWebSite}. Una demostración del \emph{framework} hecha en agosto de 2008 genera entre 20 y 35 imágenes de 1024 por 720 píxeles por segundo, utilizando una plataforma de ejecución \emph{Caneland}, la cual esta compuesta por cuatro sistemas \emph{Dunnington} de seis núcleos.

En el Algoritmo \ref{alg:algoritmoRTracingI} se muestra un pseudo-código del algoritmo de \emph{ray tracing}.

En el Algoritmo \ref{alg:algoritmoRTracingII} se presenta el pseudo-código de la función $trazarRayo$. Cada objeto de la escena es analizado para probar si el mismo es atravesado por el rayo; del conjunto de objetos atravesados interesa el objeto que tiene el punto de intersección más cercano al observador. Una vez obtenido el punto de intersección más cercano (si existe) se aplica la Ecuación \ref{eqn:EcIluWhitted}.

La función del Algoritmo \ref{alg:algoritmoRTracingII} que verifica si el punto de intersección más cercano esta en sombra se resuelve lanzando un rayo desde el punto de intersección hacia cada uno de los focos de luz para comprobar cuanta luz incide en el objeto. Si todos los rayos intersecan a un objeto antes de llegar al foco de luz entonces el punto está en sombra, caso contrario se tendrá alguna función que calcule cuanto aporta el foco a la iluminación del punto.
Si el objeto atravesado más cercano tiene reflexión se genera un rayo reflejado con origen en la intersección y cuya dirección es calculada en función del ángulo de incidencia del rayo original sobre la superficie del objeto. Si la superficie del objeto tiene refracción se genera un rayo refractado con origen en la intersección cuya dirección es calculada en base a las densidades de los medios por los que atraviesa el rayo utilizando, por ejemplo, la ley de Snell \cite{LibroCompGrafica}. Los rayos reflejado y refractado se usan para invocar recursivamente. Con el color del objeto, el trazado de los rayos de sombra y las dos invocaciones recursivas, de reflexión y refracción se calcula el color del píxel invocando a la función $calcularColorFinal$. Esta función aplica la ecuación de iluminación del modelo de Whitted.

\begin{algorithm}
    \caption{Pseudo-código del algoritmo de \emph{ray tracing}.}
    \label{alg:algoritmoRTracingI}
    \begin{algorithmic}
        \ForAll{píxel $p$ en imagen a generar}
            \State $r = rayo(observador, p);$
            \State $p.color = trazarRayo(r, 1);$
        \EndFor
    \end{algorithmic}
\end{algorithm}

\begin{algorithm}
    \caption{Pseudo-código de la función trazarRayo.}
    \label{alg:algoritmoRTracingII}
    \begin{algorithmic}
        \Require Rayo $r$, Entero $profActual$
        \Ensure Color $color$
        \If {$profActual < MAXPROF$}
            \State \Return $colorNulo$;
        \EndIf
        \State $objetoMasCercano = \infty;$
        \ForAll{objeto $o$ en la escena}
            \If {$hayInterseccion(o, r)$}
                \If {$masCercaObservador(o, objetoMasCercano)$}
                    \State $objetoMasCercano = o;$
                \EndIf
            \EndIf
        \EndFor
        \If {$objetoMasCercano <> \infty$}
            \State $sombra = verificarSombra(objetoMasCercano,r,luces);$
            \If {$objetoMasCercano$ es reflectivo}
                \State $rR = rayoReflejado(objetoMasCercano, r);$
			    \State $reflex = trazarRayo(rR, profActual + 1);$
            \EndIf
            \If {$objetoMasCercano$ es transparente}
                \State $rT = rayoRefractado(objetoMasCercano, r);$
    			\State $refrac = trazarRayo(rT, profActual + 1);$
            \EndIf
            \State $color = calcularColorFinal(objetoMasCercano, sombra, reflex, refrac);$
        \Else
            \State $color = obtenerColorFondo(r)$;
        \EndIf
    \end{algorithmic}
\end{algorithm}



