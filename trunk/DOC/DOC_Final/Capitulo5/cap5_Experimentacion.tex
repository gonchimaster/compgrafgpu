\chapter{Análisis experimental} % 20 páginas mas o menos...

\section{Introducción}

En esta sección se detallan las estrategias seguidas para evaluar los algoritmos implementados, explicando las pruebas realizadas, así como también los resultados obtenidos en estas pruebas. La evaluación también involucra el estudio comparativo de la eficiencia de las implementaciones desarrolladas con otras implementaciones similares.

\section{Estrategias de evaluación de calidad de imagen}

Para evaluar los algoritmos implementados es necesario, además de una e\-va\-lua\-ción de la velocidad de generación de las imágenes, una medida de la calidad de las mismas. Por esta razón se relevaron los métodos con los que se suele evaluar la calidad de los generadores de imágenes. Como resultado de esta investigación no se pudieron determinar estrategias sólidas para evaluar la calidad de las imágenes generadas. Si bien no se encontraron metodologías de evaluación que se adaptaran específicamente a las necesidades del trabajo, se presentan a continuación ideas interesantes que podrían ser útiles a la hora de desarrollar métodos para evaluar la calidad de imágenes generadas por trabajos similares a este.

Se realizó una categorización de las medidas de evaluación de calidad, basada en el artículo de Avcibas y Sankur \cite{AvcibasSankur2001} y analizando el resto de la información disponible \cite{ZhaiEtAl2006, DirikEtAl2007, GhanemEtAl2008, RaoReddy2007}. En el trabajo de Avcibas y Sankur se proponen medidas de calidad de imagen ordenadas según la estrategia en que se basan. Cabe señalar que si bien el trabajo no es sobre generación de imágenes, se pueden establecer ciertas similitudes en los objetivos de todas y cada una de las medidas de calidad de imágenes. Las categorías en las que se dividen los algoritmos de evaluación de calidad son:
\begin{itemize}
    \item Basados en diferencias a nivel de píxeles.
    \item Basados en correlación.
    \item Basados en aristas.
    \item Basados en análisis espectral.
    \item Basados en contexto.
    \item Basados en el sistema visual humano (HVS por su sigla en inglés).
\end{itemize}

Las estrategias basadas en diferencias a nivel de píxeles son las más simples. Consisten en calcular la diferencia entre dos imágenes tomando como referencia que un pixel en una imagen se corresponde con el mismo pixel de la imagen objetivo, dicho valor indica la diferencia que hay entre ambas imágenes, la generada y la imagen objetivo.

Las estrategias basadas en correlación son muy similares a los anteriores pero pueden introducir una nueva variable: los píxeles se pueden mover y no estar en el mismo lugar en ambas imágenes. Este tipo de algoritmos son útiles en muchos casos para el área de procesamiento de imagen, en especial porque una misma imagen puede ser generada vista de distintos ángulos y en el análisis de calidad de las mismas considerar que no tienen diferencias.

Otra opción para la evaluación, se basa en notar que las aristas (bordes que separan los objetos de la imagen) que componen las imágenes pueden ser utilizadas para el análisis de la calidad de la imagen. Esta técnica toma como referencia que para dos imágenes generadas por la misma escena, si una es la correcta (imagen objetivo) entonces en la imagen de la cual se quiere saber si es correcta también deben aparecer las mismas aristas.

Las estrategias que se basan en el análisis espectral miden la distorsión de la señal en fase y magnitud, siguiendo un enfoque del tratamiento de señales. Si bien son particularmente útiles en el análisis de algoritmos de compresión en los que se da este tipo de distorsión, no se encontró una aplicación directa a este trabajo.

En el análisis de contexto para medir la calidad de imagen se analiza para cada pixel sus vecinos en una cantidad de niveles arbitraria. Estos píxeles en caso de que difieran de alguna manera (varía para cada algoritmo dentro de la familia) modificarán, no solamente la calidad de ellos mismos como se analiza con las estrategias de diferencia por pixel, sino también la calidad de los vecinos. A modo de ejemplo no será lo mismo un pixel negro entre píxeles rojos que un pixel negro entre píxeles blancos.

Por último, para brindar una medida de calidad de la imagen generada existen métodos basados en el análisis de la percepción humana, los cuales utilizan los modelos que se han generado para la percepción del ojo humano. En este tipo de estrategias se considera que dos imágenes son iguales si para la percepción del ojo humano no tienen diferencias. Este es un modelo razonable en muchos aspectos, en particular para la industria audiovisual por ejemplo películas, video juegos, generación de imágenes fotorealistas, entre otras.

Como se puede ver, todas estas estrategias sirven para comparar imágenes y la que más se acerca a los requerimientos de evaluación de este proyecto es la basada en las capacidades de percepción del sistema visual humano, que apuntan a evaluar que imágenes son iguales para el ojo humano. Dentro de esta categoría se analizaron las técnicas más recientes, las cuales permiten calcular una medida de calidad de una imagen distorsionada con respecto a la imagen original. Por más detalles sobre dichas técnicas se pueden consultar los artículos propuestos por Zhai et al. \cite{ZhaiEtAl2006}, Ghanem et al. \cite{GhanemEtAl2008} y Rao et al. \cite{RaoReddy2007}. Ninguna de estas medidas de calidad es aplicable en el contexto de este proyecto, debido a que no se cuenta con una imagen original que sirva de base para realizar la comparación con la imagen generada por el algoritmo.

Dirik et al. \cite{DirikEtAl2007} abordan el problema de la evaluación de imágenes generadas por un algoritmo. En este trabajo se plantea la distinción entre imágenes generadas por un algoritmo de generación de imágenes y imágenes reales tomadas con una cámara. El objetivo que persiguen los autores es similar al que se persigue en el análisis de este trabajo, de esta manera se puede utilizar la medida propuesta por Dirik et al. para decidir si la imagen generada por el algoritmo implementado en este proyecto tiene buena calidad (es decir si parece tomada con una cámara fotográfica). El problema que se presenta es que en este proyecto no se abordan las imágenes fotorealistas dado que el modelo (Raytracing) no es un modelo tan preciso. Por este motivo no se puede utilizar el método propuesto en el artículo de Dirik et al.


\section{Casos de prueba}

Para probar el desempeño de los algoritmos de generación de imágenes implementados es necesario disponer de un conjunto de casos de prueba con distintas características.

La comparación con implementaciones similares es importante para establecer la calidad del algoritmo de Raytracing desarrollado en el marco de este proyecto. Por este motivo se incluyen dentro de los casos de prueba escenas pertenecientes a distintas instituciones que realizan investigación y desarrollo sobre el algoritmo de Raytracing. Dentro de esta clase de escenas externas al proyecto, hay escenas usadas en todo proyecto de generación de imágenes, por ejemplo ``\emph{stanford bunny}'' y también hay escenas únicas de proyectos particulares.

Al no disponer de un conjunto estándar de pruebas a realizar sobre el algoritmo, ya que no están establecidas por la diversidad de pruebas a realizarse, es que se eligieron y diseñaron casos de prueba según criterios justificados que se adapten a los objetivos del trabajo.

En este sentido, al momento de diseñar los casos de prueba para las versiones de Raytracing se buscó cubrir los aspectos críticos del algoritmo. Un aspecto importante a tener en cuenta es que los algoritmos implementados usan una grilla uniforme como estructura de aceleración. Como se analizó anteriormente este tipo de estructura no es buena cuando la escena tiene una distribución espacial no uniforme de sus elementos. Por ello resulta importante probar las versiones con un conjunto de escenas que mantengan fija la cantidad de objetos, pero que varíen la distribución de ellos.

La cantidad de objetos de la escena es un aspecto que afecta directamente el tiempo de ejecución de un algoritmo de Raytracing. Por este motivo es importante verificar el tiempo de ejecución del algoritmo implementado con escenas que tengan distinta cantidad de objetos pero que mantengan fijas todas las demás propiedades.

\subsection{Distribución de los objetos en la escena}

Para verificar el comportamiento del algoritmo implementado frente a la uniformidad espacial de los objetos de la escena se diseñaron tres casos de prueba. Como se muestra en la Figura \ref{fig:CPDistrEspacial} los tres casos son similares, la única diferencia entre ellos es la posición de los objetos (cada uno esta compuesto por 1148 triángulos) en la escena.

\begin{figure}
    \centering
    \subfigure[]{
        \label{fig:CPDistrEspacial:a} %% label for first subfigure
        \includegraphics[width=0.3\textwidth]{./Capitulo5/DIST_I}
    }
    \subfigure[]{
        \label{fig:CPDistrEspacial:b} %% label for second subfigure
        \includegraphics[width=0.3\textwidth]{./Capitulo5/DIST_II}
    }
    \subfigure[]{
        \label{fig:CPDistrEspacial:c} %% label for second subfigure
        \includegraphics[width=0.3\textwidth]{./Capitulo5/DIST_III}
    }
    \caption{Escenas con distinta disposición espacial de los objetos.}
    \label{fig:CPDistrEspacial} %% label for entire figure
\end{figure}

En la Tabla \ref{table:CPDistrEspacial} se muestran algunas características importantes de estos casos de prueba, en especial en la primer columna se muestra el nombre con el que se hará referencia a la escena de aquí en más.

\begin{table}[!hbt]
\begin{center}
\resizebox{12cm}{!}{
    \begin{tabular}{|c|c|c|c|c|c|}
    \hline
    Escena & Objetos & Luces & Triángulos & Archivo & Imagen\\
    \hline
    DIST\_I & 9 & 1 & 10338 & elefantesChicosDistUniforme.obj & \ref{fig:CPDistrEspacial:a}\\
    \hline
    DIST\_II & 9 & 1 & 10338 & elefantesChicosDistNoUniforme.obj & \ref{fig:CPDistrEspacial:b}\\
    \hline
    DIST\_III & 9 & 1 & 10338 & elefantesChicosDistNoUniformeSOLAP.obj & \ref{fig:CPDistrEspacial:c}\\
    \hline
    \end{tabular}
}
\caption{Datos de entrada para pruebas de distribución.}
\label{table:CPDistrEspacial}
\end{center}
\end{table}


\subsection{Cantidad de primitivas de la escena}

Para verificar el comportamiento del algoritmo implementado frente a la cantidad de objetos de la escena de entrada se diseñaron cinco casos de prueba. Los cinco casos de prueba definen la misma escena, la única propiedad que cambia entre uno o otro es la cantidad de primitivas (triángulos) usadas para construir los objetos de la misma. Como se muestra en las Figuras \ref{fig:CPCantidadPrimitivas:a} y \ref{fig:CPCantidadPrimitivas:b} cada escena contiene una esfera y un cubo, y existe una diferencia entre las imágenes generadas dada por la variación de la cantidad de triángulos.

\begin{figure}
    \centering
    \subfigure[]{
        \label{fig:CPCantidadPrimitivas:a} %% label for first subfigure
        \includegraphics[width=0.3\textwidth]{./Capitulo5/PRI_I}
    }
    \subfigure[]{
        \label{fig:CPCantidadPrimitivas:b} %% label for second subfigure
        \includegraphics[width=0.3\textwidth]{./Capitulo5/PRI_V}
    }
    \caption{Imágenes de los casos de prueba de cantidad de primitivas.}
    \label{fig:CPCantidadPrimitivas} %% label for entire figure
\end{figure}

En la Tabla \ref{table:CPCantPrimitivas} se muestran algunas características importantes de estos casos de prueba, en especial en la primer columna se muestra el nombre con el que se hará referencia a la escena de aquí en más.

\begin{table}[!hbt]
\begin{center}
\resizebox{12cm}{!}{
    \begin{tabular}{|c|c|c|c|c|c|}
    \hline
    Escena & Objetos & Luces & Triángulos & Archivo & Imagen\\
    \hline
    PRI\_I & 2 & 2 & 194 & cajaEsfera1.obj & \ref{fig:CPCantidadPrimitivas:a}\\
    \hline
    PRI\_II & 2 & 2 & 274 & cajaEsfera2.obj & -\\
    \hline
    PRI\_III & 2 & 2 & 348 & cajaEsfera3.obj & -\\
    \hline
    PRI\_IV & 2 & 2 & 482 & cajaEsfera4.obj & -\\
    \hline
    PRI\_V & 2 & 2 & 606 & cajaEsfera5.obj & \ref{fig:CPCantidadPrimitivas:b}\\
    \hline
    \end{tabular}
}
\caption{Datos de entrada para pruebas de cantidad de primitivas.}
\label{table:CPCantPrimitivas}
\end{center}
\end{table}

\subsection{Comparación con otras implementaciones}

Para la evaluación de desempeño de los algoritmos implementados en el marco de este proyecto, resulta imprescindible la comparación con otros algoritmos de Raytracing similares. Por ello se buscaron algoritmos que se ajustaran al modelo de Whitted, implementados sobre CUDA por desarrolladores de Raytracing.

Los integrantes del grupo de Computación Gráfica del \emph{Alexandra Institute} de Dinamarca \cite{BlogAlexandraInst} implementaron un algoritmo de Raytracing y se encuentra publicado en su página web. Este algoritmo no permite cambiar la escena que renderiza de forma sencilla, ya que su cargador de escena es distinto al que se usa en este proyecto. Como se dispone de información (cantidad de triángulos de cada uno de los elementos) sobre la escena del algoritmo del \emph{Alexandra Institute}, se decidió replicar manualmente dicha escena en el formato que usa el algoritmo implementado en este proyecto. Esta escena esta formada por un conjunto de 13 cajas y una esfera como se muestra en la Figura \ref{fig:CPTerceros:a}. Cada caja tiene 2 triángulos por cara y la esfera tiene 80 caras, por lo tanto la escena completa tiene 236 triángulos.

Las escenas cuyos renders se muestran en las Figuras \ref{fig:CPTerceros:b}, \ref{fig:CPTerceros:c} y \ref{fig:CPTerceros:d}, se encuentran dentro de las escenas clásicas de todo proyecto de ge\-ne\-ra\-ción de imágenes. Contar con estas escenas dentro de los casos de prueba de este proyecto es muy importante porque permite comparar con otros proyectos similares. Además es importante que el algoritmo implementado en este proyecto soporte este tipo de casos de prueba, que por lo general se componen de una cantidad considerable (100.000) de primitivas.

\begin{figure}
    \centering
    \subfigure[]{
        \label{fig:CPTerceros:a} %% label for first subfigure
        \includegraphics[width=0.2\textwidth]{./Capitulo5/alexandra}
    }
    \subfigure[]{
        \label{fig:CPTerceros:b} %% label for second subfigure
        \includegraphics[width=0.2\textwidth]{./Capitulo5/buddha}
    }
    \subfigure[]{
        \label{fig:CPTerceros:c} %% label for second subfigure
        \includegraphics[width=0.2\textwidth]{./Capitulo5/dragon}
    }
    \subfigure[]{
        \label{fig:CPTerceros:d} %% label for second subfigure
        \includegraphics[width=0.2\textwidth]{./Capitulo5/StanfordBunny}
    }
    \caption{Imágenes de los casos de prueba de cantidad de primitivas.}
    \label{fig:CPTerceros} %% label for entire figure
\end{figure}

En la Tabla \ref{table:CPTerceros} se muestran algunas características destacables de estos casos de prueba, en especial en la primer columna se muestra una referencia que será usada de aquí en más.

\begin{table}[!hbt]
\begin{center}
\resizebox{12cm}{!}{
    \begin{tabular}{|c|c|c|c|c|c|}
    \hline
    Escena & Objetos & Luces & Triángulos & Archivo & Imagen\\
    \hline
    ALEXANDRA & 14 & 1 & 236 & escenaAlexandra.obj & \ref{fig:CPTerceros:a}\\
    \hline
    BUDDHA & 1 & 1 & 100.000 & buddhaRT.obj & \ref{fig:CPTerceros:b}\\
    \hline
    DRAGON & 1 & 1 & 100.000 & dragonRT.obj & \ref{fig:CPTerceros:c}\\
    \hline
    BUNNY & 1 & 1 & 69.698 & StanfordBunny.obj & \ref{fig:CPTerceros:d}\\
    \hline
    \end{tabular}
}
\caption{Escenas que permiten la comparación con otros proyectos.}
\label{table:CPTerceros}
\end{center}
\end{table}

\section{Plataforma de ejecución}

Las características de los equipos utilizados para ejecutar los casos de prueba se muestran en la Tabla \ref{table:EquiposUtilizados}. Todos los equipos utilizados usan \emph{Windows} como sistema operativo, a excepción del equipo GTX9800 que utiliza \emph{Linux}.

\begin{table}[!hbt]
\begin{center}
\resizebox{12cm}{!}{
    \small {
    \begin{tabular}{|c|c|c|c|c|}
    \hline
    Equipo & CPU & Memoria Ram & GPU & Memoria GPU\\
    \hline
    9500M & Core 2 Duo T7500 2.20GHz & 4GB DDR2 667 MHz & GeForce 9500M GS & 512 MB\\
    \hline
    9600M & Core 2 Duo P8400 2.26GHz & 4GB DDR2 667 MHz & GeForce 9600M GT & 512 MB\\
    \hline
    GTX260 & Core 2 Duo E7500 2.93GHz & 4GB DDR2 667 MHz & GeForce GTX 260 & 896 MB\\
    \hline
    GTX9800 & Core 2 Duo E5200 2.50GHz & 2GB DDR2 667 MHz & GeForce GTX 9800 & 512 MB\\
    \hline
    \end{tabular}
    }
}
\caption{Equipos utilizados para ejecutar los casos de prueba.}
\label{table:EquiposUtilizados}
\end{center}
\end{table}

Todos los equipos utilizados para ejecutar los casos de prueba del proyecto usan la versión 2.3 del \emph{driver} de CUDA. Los equipos poseen tarjetas gráficas distintas lo cual implica que las propiedades que afectan la ejecución de las aplicaciones CUDA sobre ellas también lo sean. En la Tabla \ref{table:PropCUDA} se muestran las principales propiedades relacionadas con CUDA de cada tarjeta gráfica utilizada en el proyecto.

\begin{table}[!hbt]
\begin{center}
\resizebox{12cm}{!}{
    \begin{tabular}{|c|c|c|c|c|c|}
    \hline
    Equipo & Multiprocesadores & Núcleos & Clock (MHz)& Shader clock (MHz)& Memory clock (MHz)\\
    \hline
    9500M & 4 & 32 & 475 & 950 & 400\\
    \hline
    9500M & 4 & 32 & 500 & 1250 & 400\\
    \hline
    GTX260 & 27 & 216 & 576 & 1242 & 999\\
    \hline
    GTX9800 & 16 & 128 & 675 & 1688 & 1100\\
    \hline
    \end{tabular}
}
\caption{Características de las GPUs utilizadas.}
\label{table:PropCUDA}
\end{center}
\end{table}


\section{Resultados experimentales}

Las pruebas realizadas en este proyecto se pueden dividir en dos grandes líneas. La primera es comparar resultados dentro del propio proyecto, por ejemplo la comparación entre los dos algoritmos implementados, uno para CPU y el otro para GPU. La otra línea de prueba es la comparación con algoritmos similares implementados por terceros. En esta clase de pruebas se hicieron comparaciones con implementaciones que pudieron ser ejecutadas en los equipos utilizados en el proyecto y también con resultados de otras experiencias similares extraídos de artículos científicos.

La mayoría de las pruebas realizadas se hicieron fijando la resolución de la imagen a generar en 640 por 480 pixeles. Las únicas excepciones a esta regla se dan cuando se hacen pruebas de comparación con algoritmos implementados por terceros. Para las pruebas de comparación con el \emph{Alexandra Institute} se uso una resolución de 800 por 600, mientras que para la comparación con los resultados del artículo de Günther et al. \cite{GuntherPopov} se uso una resolución de 1024 por 1024 pixeles. En el caso del \emph{Alexandra Institute} la resolución quedó determinada por su implementación del algoritmo de Raytracing, que no permite variar la misma. En el caso del artículo de Günther la resolución quedó determinada por los resultados descritos en él, ya que fueron obtenidos usando una resolución fija (1024 por 1024).

Las pruebas realizadas a lo largo del proyecto mostraron que una buena elección del tamaño de la grilla puede incrementar notablemente la velocidad de generación de imágenes, siendo esto un parámetro crítico que se debe definir correctamente. Como primer aproximación se toma la medida sugerida por Thrane y Ole \cite{TesisEstructuras}, la cual indica que la resolución sea $3\sqrt[3]{N}$ voxeles a lo largo del eje más corto, donde $N$ es el número de triángulos de la escena. Después de varias pruebas se comprobó que esta división no siempre es la mejor y que una buena resolución para la grilla se encuentra entre $\sqrt[3]{N}$ y $3\sqrt[3]{N}$ a lo largo del eje más corto. Dentro de este intervalo se debe buscar empíricamente la grilla de mejor rendimiento. En todas las pruebas realizadas en esta sección se siguió esta metodología para encontrar el tamaño de grilla óptimo (o grilla optima), así mismo se muestran también otros tamaños de grilla para cada escena.

\subsection{Estudio de las versiones implementadas}

La comparación de rendimiento entre las diferentes versiones del algoritmo para GPU se hizo usando los casos de prueba PRI\_I a PRI\_V. Esta comparación entre versiones consta de dos partes, en la primera se determina la grilla óptima para cada caso de prueba y en la segunda se ejecuta cada caso de prueba en cada una de las versiones del algoritmo utilizando su grilla óptima.

Para determinar la grilla óptima para cada escena de prueba se usa la Versión RT-GPU-JM-IR del algoritmo para GPU, ejecutando en el Equipo GTX260. En la Tabla \ref{table:CompVersionesBuscarGrilla} se muestran los resultados obtenidos al ejecutar los casos de prueba sobre GPU. Observando los resultados se puede concluir que la grilla óptima para todos los casos de prueba se construye partiendo en dos cada eje.

Los resultados obtenidos en estas primeras pruebas muestran que a medida que aumenta la cantidad de primitivas con que esta construida la escena aumenta el tiempo de generación de imagen, y por lo tanto disminuyen los \emph{frames} por segundo (FPS). Antes de ejecutar los casos de prueba se planteo la hipótesis de que a mayor cantidad de primitivas en la escena mayor es el tiempo de generación de imagen, la cual es validada por las pruebas realizadas en este sentido. También se pensaba que al aumentar la cantidad de primitivas de la escena aumentaría la cantidad de voxels que debía tener la grilla óptima, pero esto no fue validado por los resultados obtenidos. Esto puede deberse a que el incremento de la cantidad de primitivas no es suficientemente grande como para obligar a aumentar la resolución de la grilla.

\begin{table}[!hbt]
\begin{center}
\resizebox{10cm}{!}{
  \small {
    \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
    \multirow{2}{*}{\textbf{Escena}}&\multicolumn{6}{|c|}{\textbf{Tamaño de grilla}}\\
    \cline{2-7}
    & 1x1x1 & 2x2x2 & 4x4x4 & 6x6x6 & 10x10x10 & 15x15x15\\
    \hline
    PRI\_I & 18.7 & 36.7 & 32.7 & 29.7 & 27.3 & 24.7\\
    \hline
    PRI\_II & 13.9 & 27.6 & 25.4 & 23.3 & 21.5 & 20.1\\
    \hline
    PRI\_III & 11.3 & 24.5 & 22.8 & 20.9 & 19.2 & 18.0\\
    \hline
    PRI\_IV & 8.4 & 18.5 & 18.0 & 16.5 & 15.9 & 15.1\\
    \hline
    PRI\_V & 6.7 & 16.6 & 15.5 & 14.6 & 13.8 & 13.5\\
    \hline
    \end{tabular}
  }
}
\caption{FPS de PRI\_I, PRI\_II, PRI\_III, PRI\_IV, PRI\_V en el Equipo GTX260 sobre GPU.}
\label{table:CompVersionesBuscarGrilla}
\end{center}
\end{table}

Una vez determinada la grilla óptima para cada caso de prueba, se ejecuta cada caso utilizando su grilla óptima en cada una de las versiones del algoritmo para GPU, en la Tabla \ref{table:CompVersionesFPS} se muestran los resultados obtenidos. Los resultados de la Tabla \ref{table:CompVersionesFPS} reflejan la evolución del algoritmo a medida que se fue mejorando la implementación, incrementándose los FPS para todos los casos de prueba.

\begin{table}[!hbt]
\begin{center}
\resizebox{12cm}{!}{
    \begin{tabular}{|c|c|c|c|c|}
    \hline
    Escena & Tamaño Grilla Óptimo & RT-GPU (FPS) & RT-GPU-JM (FPS) & RT-GPU-JM-IR (FPS)\\
    \hline
    PRI\_I & 2x2x2 & 5.8 & 26.2 & 36.7\\
    \hline
    PRI\_II & 2x2x2 & 5.1 & 20.2 & 27.6\\
    \hline
    PRI\_III & 2x2x2 & 4.9 & 18.2 & 24.5\\
    \hline
    PRI\_IV & 2x2x2 & 4.3 & 14.1 & 18.5\\
    \hline
    PRI\_V & 2x2x2 & 3.9 & 12.6 & 16.6\\
    \hline
    \end{tabular}
}
\caption{FPS de PRI\_I, PRI\_II, PRI\_III, PRI\_IV, PRI\_V en el Equipo GTX260 sobre GPU para cada versión del algoritmo.}
\label{table:CompVersionesFPS}
\end{center}
\end{table}

El incremento del tiempo de generación de imagen es mayor en el primer cambio de versión, esta diferencia está determinada por el uso de la jerarquía de memoria de la GPU. En la Versión RT-GPU todos los accesos a memoria son a memoria global mientras que en la Versión RT-GPU-JM la mayoría de los datos de entrada del algoritmo de Raytracing se encuentran en memoria de textura. Considerando estos casos de prueba, el correcto uso de la jerarquía de memoria permite que el algoritmo pierda menos tiempo accediendo a memoria, siendo tres veces y media en promedio más rápido que el algoritmo que no la usa.

En el segundo cambio de versión se mejora el algoritmo de intersección rayo-triángulo, el nuevo test de intersección logra el mismo objetivo que el anterior pero con menos operaciones aritméticas, lo cual implica una dis\-mi\-nu\-ción del tiempo de generación de la imagen. Considerando los resultados obtenidos esta mejora del algoritmo de Raytracing ayuda a que la Versión RT-GPU-JM-IR genere la imagen un 30\% más rápido que en la Versión RT-GPU-JM.

En la Figura \ref{fig:CompVersionesRenders} se muestran los renders del caso de prueba PRI\_V con cada una de las versiones del algoritmo implementado en CUDA. No se observan diferencias importantes entre las imágenes generadas por las diferentes versiones del algoritmo. El aumento en la cantidad de FPS de las diferentes versiones implementadas no implica una perdida de calidad de imagen.


\begin{figure}
    \centering
    \subfigure[]{
        \label{fig:CompVersionesRenders:a} %% label for first subfigure
        \includegraphics[width=0.3\textwidth]{./Capitulo5/renderPRI5Version1}
    }
    \subfigure[]{
        \label{fig:CompVersionesRenders:b} %% label for second subfigure
        \includegraphics[width=0.3\textwidth]{./Capitulo5/renderPRI5Version2}
    }
    \subfigure[]{
        \label{fig:CompVersionesRenders:c} %% label for second subfigure
        \includegraphics[width=0.3\textwidth]{./Capitulo5/renderPRI5Version3}
    }
    \caption{Render de PRI\_V en GPU con la Versión RT-GPU, RT-GPU-JM y RT-GPU-JM-IR respectivamente.}
    \label{fig:CompVersionesRenders} %% label for entire figure
\end{figure}


\subsection{Estudio de las implementaciones en C y en CUDA}\label{sec:ComparacionCvsCUDA}

La comparación de rendimiento entre el algoritmo para CPU y el algoritmo para GPU se hizo usando los casos de prueba DIST\_I, DIST\_II, DIST\_II y BUNNY. Para esta comparación se usa la versión más eficiente de los algoritmos la Versión RT-GPU-JM-IR y la Versión RT-CPU-IR, ejecutando en el Equipo GTX260. En la Tabla \ref{table:CvsCUDACPU} se muestran los resultados obtenidos al ejecutar los casos de prueba sobre CPU, mientras que en la Tabla \ref{table:CvsCUDAGPU} se muestran los resultados obtenidos al ejecutar los mismos casos sobre GPU.

\begin{table}[!hbt]
\begin{center}
\resizebox{12cm}{!}{
    \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
    \multirow{2}{*}{\textbf{Escena}}&\multicolumn{6}{|c|}{\textbf{Tamaño de grilla}}\\
    \cline{2-7}
    &10x10x10&22x22x22&50x50x50&65x65x65&100x100x100&200x200x200\\
    \hline
    DIST\_I&0.3&0.9&1.4&1.3&1.1&0.3\\
    \hline
    DIST\_II&0.3&1.0&1.5&1.4&1.1&0.3\\
    \hline
    DIST\_III&0.4&1.3&1.6&1.4&1.1&0.3\\
    \hline
    \multirow{2}{*}{}&\multicolumn{6}{|c|}{}\\
    \cline{2-7}
    &20x20x20&41x41x41&80x80x80&123x123x123&200x200x200&300x300x300\\
    \hline
    BUNNY&1.2&3.0&4.2&4.0&3.2&2.1\\
    \hline
    \end{tabular}
}
\caption{FPS de DIST\_I, DIST\_II, DIST\_III y BUNNY en el Equipo GTX260 sobre CPU.}
\label{table:CvsCUDACPU}
\end{center}
\end{table}

\begin{table}[!hbt]
\begin{center}
\resizebox{10cm}{!}{
  \small {
    \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
    \multirow{2}{*}{\textbf{Escena}}&\multicolumn{6}{|c|}{\textbf{Tamaño de grilla}}\\
    \cline{2-7}
    &10x10x10&22x22x22&50x50x50&65x65x65&100x100x100&200x200x200\\
    \hline
    DIST\_I&10.5&15.4&17.2&14.2&10.7&5.1\\
    \hline
    DIST\_II&10.7&16.7&20.1&17.5&12.0&5.1\\
    \hline
    DIST\_III&8.9&18.5&21.1&18.2&12.5&5.1\\
    \hline
    \multirow{2}{*}{}&\multicolumn{6}{|c|}{}\\
    \cline{2-7}
    &20x20x20&41x41x41&80x80x80&123x123x123&200x200x200&300x300x300\\
    \hline
    BUNNY&13.9&20.7&23.8&20.8&14.4&10.1\\
    \hline
    \end{tabular}
  }
}
\caption{FPS de DIST\_I, DIST\_II, DIST\_III y BUNNY en el Equipo GTX260 sobre GPU.}
\label{table:CvsCUDAGPU}
\end{center}
\end{table}

Los resultados obtenidos sugieren que el tamaño de la grilla depende exclusivamente de la cantidad de triángulos con que esta construida la escena, ya que en los tres primeros casos (que tienen la misma cantidad de triángulos) el tamaño de grilla donde se logran más FPS es siempre el mismo. Además como lo muestra el caso BUNNY, al incrementarse la cantidad de primitivas de la escena aumenta la resolución de la grilla óptima. Se concluye también que el tamaño de la grilla óptima es independiente al \emph{hardware} de ejecución, la grilla que permite más FPS tiene igual resolución en CPU y en GPU.

Los casos de prueba DIST\_I, DIST\_II y DIST\_III fueron pensados para buscar una debilidad de la estructura de aceleración. La debilidad de la estructura de subdivisión espacial uniforme se da cuando los objetos de la escena están distribuidos de forma no uniforme en la misma. Es por esto que se pensaba que con el caso DIST\_III, que tiene todos los objetos concentrados en el centro de la escena, se lograrían menos FPS que con el DIST\_II y con el DIST\_I. De la misma forma se pensaba que con el caso DIST\_II se lograrían menos FPS que con el caso DIST\_I. Los resultados obtenidos reflejan totalmente lo contrario a lo que se pensaba de antemano. La explicación para este comportamiento en este tipo de escenas, es que cuánto más uniformemente distribuidos en la escena estén los objetos, más sombra arrojan. Como el cálculo de sombra es computacionalmente costoso, se cree que este costo contrarresta al beneficio que brinda la grilla cuando los objetos están distribuidos de forma uniforme en la escena.

Los resultados obtenidos con los casos de prueba DIST\_I, DIST\_II, DIST\_III y BUNNY demuestran que el algoritmo para GPU genera imágenes en un tiempo menor que el algoritmo para CPU. En la Tabla \ref{table:CvsCudaAceleracion} se muestra la aceleración lograda por el algoritmo para GPU para cada caso de prueba. En promedio, considerando los cuatro casos de prueba, el algoritmo para GPU es más de 11 veces más rápido que el algoritmo para CPU. En la Figura \ref{fig:CvsCudaRenderBunny:a} se muestra la imagen generada por el algoritmo implementado en C, mientras que en la Figura \ref{fig:CvsCudaRenderBunny:b} se muestra la imagen generada por el algoritmo implementado en CUDA. Observando estas imágenes no se percibe diferencia alguna, por lo que es posible concluir que el algoritmo para GPU logra una muy buena aceleración con respecto al que ejecuta en CPU y sin pérdida en la calidad de imagen.

\begin{table}[!hbt]
\begin{center}
\resizebox{10cm}{!}{
    \small {
    \begin{tabular}{|c|c|c|c|c|}
    \hline
    Escena & Tamaño Grilla & CPU (FPS) & GPU (FPS) & Aceleración\\
    \hline
    DIST\_I & 50x50x50 & 1.4 & 17.2 & 12\\
    \hline
    DIST\_II & 50x50x50 & 1.5 & 20.1 & 14\\
    \hline
    DIST\_III & 50x50x50 & 1.6 & 21.1 & 13\\
    \hline
    BUNNY & 80x80x80 & 4.2 & 23.8 & 6\\
    \hline
    \end{tabular}
    }
}
\caption{Aceleración lograda por algoritmo para GPU.}
\label{table:CvsCudaAceleracion}
\end{center}
\end{table}

\begin{figure}
    \centering
    \subfigure[]{
        \label{fig:CvsCudaRenderBunny:a} %% label for first subfigure
        \includegraphics[width=0.3\textwidth]{./Capitulo5/renderBunnyCPU}
    }
    \subfigure[]{
        \label{fig:CvsCudaRenderBunny:b} %% label for second subfigure
        \includegraphics[width=0.3\textwidth]{./Capitulo5/renderBunnyGPU}
    }
    \caption{Render de BUNNY en CPU y en GPU respectivamente.}
    \label{fig:CvsCudaRenderBunny} %% label for entire figure
\end{figure}


\subsection{Estudio entre distintos equipos}\label{sec:ComparacionEquipos}

La comparación de rendimiento entre los diferentes equipos del proyecto se hizo usando la Versión RT-GPU-JM-IR del algoritmo implementado para GPU. Los casos de prueba de esta comparación son: DRAGON, BUDDHA y ALEXANDRA. En cada equipo del proyecto, se corren los casos de prueba usando varios tamaños de grilla, de esta forma se puede determinar el tamaño de grilla óptimo para cada caso y equipo. El mejor tiempo de generación de imagen para cada caso y equipo es analizado y comparado con los demás.

En las Tablas \ref{table:EquiposEquipo1}, \ref{table:EquiposEquipo2}, \ref{table:EquiposEquipo3} y \ref{table:EquiposEquipo4} se muestran los resultados obtenidos para los equipos 9500M, 9600M, GTX260 y GTX9800 respectivamente.

\begin{table}[!hbt]
\begin{center}
\resizebox{12cm}{!}{
    \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
    \multirow{2}{*}{\textbf{Escena}}&\multicolumn{6}{|c|}{\textbf{Tamaño de grilla}}\\
    \cline{2-7}
    & 20x20x20 & 46x46x46 & 92x92x92 & 138x138x138 & 180x180x180 & 230x230x230\\
    \hline
    DRAGON & 1.4 & 2.3 & 2.8 & 2.0 & 1.6 & 1.3\\
    \hline
    BUDDHA & 1.3 & 2.4 & 2.5 & 2.1 & 1.7 & 1.3\\
    \hline
    \multirow{2}{*}{}&\multicolumn{6}{|c|}{}\\
    \cline{2-7}
    & 1x1x1 & 3x3x3 & 6x6x6 & 10x10x10 & 15x15x15 & 30x30x30\\
    \hline
    ALEXANDRA & 4.6 & 11.5 & 15.6 & 13.1 & 12.3 & 9.1\\
    \hline
    \end{tabular}
}
\caption{FPS de DRAGON, BUDDHA y ALEXANDRA en el equipo 9500M sobre GPU.}
\label{table:EquiposEquipo1}
\end{center}
\end{table}

\begin{table}[!hbt]
\begin{center}
\resizebox{12cm}{!}{
    \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
    \multirow{2}{*}{\textbf{Escena}}&\multicolumn{6}{|c|}{\textbf{Tamaño de grilla}}\\
    \cline{2-7}
    & 20x20x20 & 46x46x46 & 92x92x92 & 138x138x138 & 180x180x180 & 230x230x230\\
    \hline
    DRAGON & 1.7 & 3.3 & 3.4 & 2.6 & 2.0 & 1.6\\
    \hline
    BUDDHA & 1.4 & 2.8 & 3.1 & 2.6 & 2.1 & 1.7\\
    \hline
    \multirow{2}{*}{}&\multicolumn{6}{|c|}{}\\
    \cline{2-7}
    & 1x1x1 & 3x3x3 & 6x6x6 & 10x10x10 & 15x15x15 & 30x30x30\\
    \hline
    ALEXANDRA & 5.9 & 14.0 & 20.0 & 18.4 & 17.5 & 12.8\\
    \hline
    \end{tabular}
}
\caption{FPS de DRAGON, BUDDHA y ALEXANDRA en el equipo 9600M sobre GPU.}
\label{table:EquiposEquipo2}
\end{center}
\end{table}

\begin{table}[!hbt]
\begin{center}
\resizebox{12cm}{!}{
    \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
    \multirow{2}{*}{\textbf{Escena}}&\multicolumn{6}{|c|}{\textbf{Tamaño de grilla}}\\
    \cline{2-7}
    & 20x20x20 & 46x46x46 & 92x92x92 & 138x138x138 & 180x180x180 & 230x230x230\\
    \hline
    DRAGON & 5.0 & 12.2 & 16.8 & 14.2 & 11.4 & 9.3\\
    \hline
    BUDDHA & 4.9 & 9.8 & 12.4 & 11.4 & 10.3 & 8.4\\
    \hline
    \multirow{2}{*}{}&\multicolumn{6}{|c|}{}\\
    \cline{2-7}
    & 1x1x1 & 3x3x3 & 6x6x6 & 10x10x10 & 15x15x15 & 30x30x30\\
    \hline
    ALEXANDRA & 28.0 & 49.3 & 71.2 & 67.6 & 62.5 & 49.4\\
    \hline
    \end{tabular}
}
\caption{FPS de DRAGON, BUDDHA y ALEXANDRA en el equipo GTX260 sobre GPU.}
\label{table:EquiposEquipo3}
\end{center}
\end{table}

\begin{table}[!hbt]
\begin{center}
\resizebox{12cm}{!}{
    \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
    \multirow{2}{*}{\textbf{Escena}}&\multicolumn{6}{|c|}{\textbf{Tamaño de grilla}}\\
    \cline{2-7}
    & 20x20x20 & 46x46x46 & 92x92x92 & 138x138x138 & 180x180x180 & 230x230x230\\
    \hline
    DRAGON & 5.6 & 12.3 & 12.8 & 9.0 & 6.8 & 5.0\\
    \hline
    BUDDHA & 5.0 & 10.0 & 10.4 & 7.9 & 6.1 & 4.5\\
    \hline
    \multirow{2}{*}{}&\multicolumn{6}{|c|}{}\\
    \cline{2-7}
    & 1x1x1 & 3x3x3 & 6x6x6 & 10x10x10 & 15x15x15 & 30x30x30\\
    \hline
    ALEXANDRA & 29.5 & 57.7 & 74.4 & 70.5 & 69.6 & 50.1\\
    \hline
    \end{tabular}
}
\caption{FPS de DRAGON, BUDDHA y ALEXANDRA en el equipo GTX9800 sobre GPU.}
\label{table:EquiposEquipo4}
\end{center}
\end{table}

De los resultados obtenidos se desprende que para los casos de prueba DRAGON, BUDDHA y ALEXANDRA el tamaño de grilla donde se logran más FPS es el mismo independientemente del equipo en donde se ejecuten. El modelo de programación de CUDA es capaz de ejecutar más hilos en paralelo cuanto más procesadores tenga la GPU. Basado en esto se puede afirmar que el tamaño de grilla óptimo no depende del grado de paralelismo que se logre.

En la Figura \ref{fig:GraficoFPSFuncionProc} se muestra un gráfico de la cantidad de FPS en función de la cantidad de procesadores de la GPU para cada caso de prueba utilizando su grilla optima.
\begin{figure}[H]
    \centering
        \includegraphics[width=0.85\textwidth]{./Capitulo5/graficaFPS-F(cant_proc)}
    \caption{FPS en función de la cantidad de procesadores de la GPU.}
    \label{fig:GraficoFPSFuncionProc}
\end{figure}

Todas las pruebas realizadas en esta comparación con los casos de prueba DRAGON y BUDDHA (los cuales se consideran complejos por estar conformados por 100.000 triángulos), confirmaron que cuanto más procesadores posea la GPU más rápido será la generación de imágenes mediante el algoritmo de Raytracing para CUDA. Por otro lado los resultados de las pruebas realizadas con el caso ALEXANDRA (considerado una escena sencilla por estar conformado por 236 triángulos) permiten afirmar que el \emph{overhead} generado por el uso de más procesadores afecta al tiempo de generación de imagen. Igualmente los resultados demuestran que la aplicación CUDA implementada puede escalar automáticamente en el número de procesadores de la GPU, esta importante característica surge como consecuencia del modelo de programación de CUDA que permite lograrlo muy fácilmente.

La GPU del equipo GTX260 tiene un poco más de seis veces más procesadores que la del equipo 9600M. Como se muestra en la Figura \ref{fig:GraficoFPSFuncionProc}, si consideramos los resultados de los casos DRAGON, BUDDHA y ALEXANDRA con sus grillas óptimas, se observa que la a\-ce\-le\-ra\-ción en la generación de imagen nunca llega a 6, sino que es aproximadamente 5, 4 y 4 respectivamente. Basado en esta información se puede concluir que la ganancia de FPS no es lineal con respecto al aumento de procesadores. Esto se debe al tiempo empleado para la lectura de datos de entrada, a retrasos por se\-ria\-li\-za\-ción de los accesos a memoria o por sincronizaciones entre hilos al momento de escribir los resultados.

En la Figura \ref{fig:CompEquiposRenders} se muestran renders del caso de prueba BUDDHA con el algoritmo implementado en CUDA. El render de la Figura \ref{fig:CompEquiposRenders:a} fue generado usando el equipo 9500M, el de la Figura \ref{fig:CompEquiposRenders:b} fue generado usando el equipo 9600M, el de la Figura \ref{fig:CompEquiposRenders:c} usando el equipo GTX260 y el de la Figura \ref{fig:CompEquiposRenders:d} con el equipo GTX9800. No se observan diferencias importantes entre las imágenes generadas por los diferentes equipos utilizados en el proyecto. El aumento del poder de cómputo de la GPU implica un aumento en la cantidad de FPS, esta disminución del tiempo de generación de imágenes no implica perdida de calidad de las mismas.

\begin{figure}
    \centering
    \subfigure[]{
        \label{fig:CompEquiposRenders:a} %% label for first subfigure
        \includegraphics[width=0.3\textwidth]{./Capitulo5/renderBuddhaEquipo1}
    }
    \subfigure[]{
        \label{fig:CompEquiposRenders:b} %% label for second subfigure
        \includegraphics[width=0.3\textwidth]{./Capitulo5/renderBuddhaEquipo2}
    }
    \subfigure[]{
        \label{fig:CompEquiposRenders:c} %% label for second subfigure
        \includegraphics[width=0.3\textwidth]{./Capitulo5/renderBuddhaEquipo3}
    }
    \subfigure[]{
        \label{fig:CompEquiposRenders:d} %% label for second subfigure
        \includegraphics[width=0.3\textwidth]{./Capitulo5/renderBuddhaEquipo4}
    }
    \caption{Render de BUDDHA en GPU sobre los equipos 9500M, 9600M, GTX260 y GTX9800 respectivamente.}
    \label{fig:CompEquiposRenders} %% label for entire figure
\end{figure}

\subsection{Estudio comparativo con otras implementaciones}

En el trabajo de Günther et al. \cite{GuntherPopov} se desarrolló una implementación del algoritmo de Raytracing similar a la de este proyecto. En este trabajo se generan renders de una escena que es igual a la escena BUNNY y se presentan resultados de los tiempos de generación de imágenes.

Se deben considerar algunas excepciones con respecto a la igualdad de las escenas, la escena BUNNY utilizada en este proyecto esta construida mediante la observación minuciosa de un render del trabajo de Günther et al.. Por ejemplo, la cantidad de luces es la misma pero la posición de estas no son exactamente las mismas, ya que en el artículo no se brinda este tipo de información. El material del objeto principal de la escena no pudo ser reproducido con exactitud debido a que en el trabajo no se brinda esa información.

Debido a que en el trabajo de Günther et al. solamente se presentan resultados y no se tiene acceso al código fuente y a la especificación de la escena, las pruebas con el algoritmo implementado en este proyecto se adaptaron a dicho trabajo para lograr resultados comparables. En dicho trabajo se usa una resolución de 1024 por 1024 pixeles, por lo tanto las pruebas de comparación se hacen utilizando esta resolución.

Günther et al. usan la estructura Kd-Tree como método de a\-ce\-le\-ra\-ción espacial, como se dijo en la sección de relevamiento de estructuras de a\-ce\-le\-ra\-ción, esa estructura es más eficiente que la utilizada en este proyecto. Debido a esto, para la comparación con el algoritmo implementado en este proyecto se usa el tamaño de grilla que permite generar la imagen en el menor tiempo posible (dicho tamaño se definió empíricamente en la Sección \ref{sec:ComparacionCvsCUDA}).

La GPU utilizada en el trabajo de Günther es nVidia modelo GeForce 8800 GTX, la cual posee 112 núcleos. En el marco de este proyecto la GPU que más se adapta para este caso es la del equipo GTX260, ya que si bien posee más cantidad de núcleos de procesamiento esta cantidad se ve compensada por el uso de la estructura Kd-Tree por parte del algoritmo de Günther et al.

En la Figura \ref{fig:ExitosoBunnyRenders:a} se muestra el render extraído del trabajo de Günther et al. y en la Figura \ref{fig:ExitosoBunnyRenders:b} se muestra el render de la escena BUNNY generado con la Versión RT-GPU-JM-IR del algoritmo implementado para GPU.

\begin{figure}
    \centering
    \subfigure[]{
        \label{fig:ExitosoBunnyRenders:a} %% label for first subfigure
        \includegraphics[width=0.45\textwidth]{./Capitulo5/renderPaperBunny}
    }
    \subfigure[]{
        \label{fig:ExitosoBunnyRenders:b} %% label for second subfigure
        \includegraphics[width=0.45\textwidth]{./Capitulo5/renderGPU3Bunny}
    }
    \caption{Render de BUNNY en el trabajo de Günther et al. y en este proyecto respectivamente.}
    \label{fig:ExitosoBunnyRenders} %% label for entire figure
\end{figure}

El rendimiento en FPS del algoritmo implementado en este proyecto bajo las condiciones descritas anteriormente es de $6\ldotp1$ FPS, mientras que el rendimiento del algoritmo del trabajo de Günther es de $5\ldotp9$ FPS. El desempeño de ambos algoritmos para este caso de prueba es muy similar. El algoritmo implementado en este proyecto tiene a favor que la GPU donde ejecuta es más potente y en contra que usa una estructura de aceleración menos eficiente. El algoritmo implementado en el trabajo de Günther tiene a favor que usa una estructura de aceleración más eficiente y en contra que ejecuta en una GPU de menor capacidad de cálculo. De todas formas es importante que el algoritmo implementado en este proyecto tenga rendimientos competitivos con algoritmos desarrollados en otros proyectos similares.

El \emph{Alexandra Institute} \cite{BlogAlexandraInst} ha desarrollado un algoritmo de Raytracing para CUDA que permite comparar su rendimiento con el implementado en este proyecto. La comparación se realiza únicamente mediante el caso de prueba ALEXANDRA, debido a que el algoritmo implementado por este instituto no permite cambiar de escena fácilmente. Cabe destacar que la escena ALEXANDRA fue construida mediante observación de imágenes generadas por el Raytracing desarrollado en dicho instituto, por ende las escenas de entrada de ambos algoritmos no son formalmente iguales, aunque sí muy similares.

La resolución de la imagen que genera el algoritmo de Raytracing implementado por el \emph{Alexandra Institute} es de 800 por 600 pixeles y no puede ser modificada, por lo tanto se usa esta resolución para las pruebas de comparación. El Raytracing del \emph{Alexandra Institute} no usa estructura de aceleración espacial, mientras que el algoritmo implementado en este proyecto usa un tamaño de grilla de 6 voxels por dimensión. Este tamaño de grilla genera el mejor rendimiento del algoritmo y fue hallado empíricamente en la sección \ref{sec:ComparacionEquipos}.

Debido a que se tiene acceso al ejecutable del algoritmo del \emph{Alexandra Institute} y que esta compilado para \emph{Windows x86} se optó por ejecutar la comparación de rendimiento entre ambos algoritmos en el equipo 9600M, que es el más potente dentro de los equipos disponibles.

En la Figura \ref{fig:ExitosoAlexRenders:a} se muestra un render generado por la aplicación desarrollada por el \emph{Alexandra Institute} y en la Figura \ref{fig:ExitosoAlexRenders:b} se muestra el render de la escena ALEXANDRA generado con la Versión RT-GPU-JM-IR del algoritmo implementado para GPU sobre el equipo 9600M.

\begin{figure}
    \centering
    \subfigure[]{
        \label{fig:ExitosoAlexRenders:a} %% label for first subfigure
        \includegraphics[width=0.45\textwidth]{./Capitulo5/renderAlexTercero}
    }
    \subfigure[]{
        \label{fig:ExitosoAlexRenders:b} %% label for second subfigure
        \includegraphics[width=0.45\textwidth]{./Capitulo5/renderAlexNuestro}
    }
    \caption{Render de la aplicación del \emph{Alexandra Institute} y render de ALEXANDRA en GPU sobre Equipo 9600M usando la Versión RT-GPU-JM-IR, respectivamente.}
    \label{fig:ExitosoAlexRenders} %% label for entire figure
\end{figure}

El rendimiento en FPS del algoritmo implementado en este proyecto bajo las condiciones descritas anteriormente es de $13$ FPS, mientras que el rendimiento del raytracing del \emph{Alexandra Institute} es de $11\ldotp7$ FPS. Es necesario recalcar que el algoritmo implementado en este proyecto renderiza escenas genéricas, es decir, no fue concebido para generar imágenes de sólo un tipo de escena, lo cual implica que para una misma escena se requiere mayor espacio de almacenamiento y más accesos a memoria. Parte de la escena del algoritmo desarrollado por el instituto de Dinamarca se encuentra en el código fuente del mismo, lo cual brinda mayor eficiencia para el caso particular. Es posible afirmar que para este caso de prueba ambos algoritmos tienen rendimientos similares, esto demuestra que el algoritmo implementado es competitivo con otros algoritmos de raytracing implementados en CUDA.

En las imágenes generadas por ambos algoritmos se pueden apreciar diferencias, como por ejemplo el color de fondo que no pudo ser correctamente reproducido en la escena de prueba ALEXANDRA. Se nota otra diferencia en el brillo especular de la esfera, esto se debe a la reproducción incorrecta del material de la misma. Aunque en el render generado por el algoritmo implementado en este proyecto se aprecia mejor el reflejo de los objetos cercanos a la esfera sobre la superficie de la misma. Otra diferencia que es que el algoritmo del \emph{Alexandra Institute} trata a las luces de la escena como un objeto más de la misma, esto no es considerado por el algoritmo implementado en este proyecto. Se puede concluir que no existen diferencias de calidad significativas entre ambos renders.

\section{Conclusiones}

Entre los resultados más importantes de las pruebas realizadas se puede destacar que el algoritmo para GPU es más de 10 veces más rápido que el algoritmo implementado para CPU. Lo que demuestra que la paralelización a nivel de rayos primarios realizada sirve para acelerar Raytracing.

Por otro lado, el método de aceleración mediante GPU permitió lograr tiempos interactivos de generación de imagen para escenas simples. Asimismo, es posible lograr tiempos interactivos para escenas complejas debido a que aun existen puntos del algoritmo por mejorar, como por ejemplo la estructura de aceleración espacial.

Otro punto relevante es la comparación con proyectos similares, en este sentido se obtuvieron buenos resultados debido a que el tiempo de generación de imagen del algoritmo implementado en este proyecto resultó competitivo con los demás.

Por último, las pruebas realizadas en los diversos equipos utilizados en este proyecto permiten afirmar que el algoritmo de Raytracing implementado para CUDA escala de buena manera y au\-to\-má\-ti\-ca\-men\-te en el número de procesadores de la GPU. Esta propiedad permite mejorar de forma automática los tiempos de generación de imagen a medida que el poder de computo de las tarjetas gráficas se incrementa.

%%% Resumir las tres o cuatro conclusiones mas importantes.
%%% Se supero ampliamente al algoritmo para CPU.
%%% Se esta cerca de tiempo interactivo pero todavía hay que mejorar y hay puntos como para hacerlo.
%%% Competitivo con otros algoritmos.
%%% El algoritmo escala bien en el número de procesadores.
