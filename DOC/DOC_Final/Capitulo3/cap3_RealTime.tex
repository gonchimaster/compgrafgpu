\chapter{Aceleración del algoritmo de \emph{ray tracing}}\label{cap:AceleracionRaytracing}

\section{Introducción}
Esta sección presenta en detalle los algoritmos y técnicas existentes para la aceleración de la generación de imágenes por computadora. Se verán los métodos que fueron analizados durante el desarrollo de este trabajo, centrándose en dos puntos principales que son: las estructuras de aceleración espacial y la paralelización de procesos. Por un lado se busca reducir la cantidad de cálculos requeridos para la generación de una imagen y por otro lado hacer que los cálculos se realicen en menos tiempo. Para la paralelización de algoritmos en este proyecto se optó por utilizar una paralelización del algoritmo en la GPU, en este capítulo se justifica además por que se consideró esta plataforma para el proyecto.

\section{Paralelización de algoritmos en GPU}

En noviembre de 2006 NVIDIA lanzó CUDA (Compute Unified Device Architecture), una arquitectura de computación paralela de propósito general que hace uso del núcleo de procesamiento paralelo de las GPUs de NVIDIA para resolver una amplia variedad de problemas computacionales de una manera más eficiente que en una CPU. El modelo de programación paralela propuesto por NVIDIA fue totalmente nuevo y la programación sobre el mismo se hace a través del lenguaje de alto nivel CUDA que permite el uso del lenguaje C para la programación.

La arquitectura CUDA basa su poder de procesamiento en un conjunto de multiprocesadores (variable dependiente del modelo de GPU), donde cada uno de ellos procesa parte de la carga de trabajo en paralelo. Un multiprocesador está compuesto por 8 procesadores, una unidad de memoria compartida y otras 3 unidades que permiten controlar el funcionamiento del mismo. Cada multiprocesador crea, administra y ejecuta hilos concurrentemente en el hardware sin incrementar el tiempo de ejecución por la planificación (\emph{scheduling}).

El modelo de programación esta basado en tres abstracciones fundamentales: una jerarquía de grupos de hilos de ejecución, memoria compartida y barreras de sincronización. Estas abstracciones guían al programador a dividir el problema en sub-problemas que pueden ser resueltos en forma paralela e independiente por medio de bloques de hilos de ejecución. A su vez cada sub-problema de divide en piezas más chicas que pueden ser resueltas en paralelo y cooperando entre ellas, usando los hilos de ejecución de cada bloque. Descomponer el problema de esta forma permite la escalabilidad automática en el número de procesadores, ya que cada bloque de hilos puede ser despachado hacia cualquier conjunto de procesadores (multiprocesador) disponible en cualquier orden, concurrentemente o secuencialmente. De esta manera una aplicación CUDA puede ejecutar sobre un equipo con diferente número de multiprocesadores y sólo se necesita conocer este número en tiempo de ejecución, lo que implica que no sea necesaria una nueva compilación. En la Figura \ref{fig:DiagramaEjecucionCUDA} se considera una aplicación CUDA que está dividida en cuatro bloques y se muestra como se asignan los bloques de hilos de ejecución en dos GPU distintas, donde una tiene dos multiprocesadores y la otra tiene cuatro.

La extensión del lenguaje C que hace CUDA habilita a definir funciones (de la misma forma que en el lenguaje base) que a diferencia de las funciones comunes de C, cuando son invocadas ejecutan $N$ veces en paralelo, mediante $N$ hilos de ejecución diferentes. Estas funciones propias de CUDA son llamadas \emph{kernels}. Dentro de este tipo especial de funciones se tiene acceso a información propia de CUDA que indica por ejemplo, el identificador del hilo de ejecución o el identificador de bloque que lo contiene. Esta información es de vital importancia ya que es usada para parametrizar la ejecución del \emph{kernel} en función de los hilos de ejecución.

\begin{figure}[H]
    \centering
        \includegraphics[width=0.7\textwidth]{./Capitulo4/diagramaEjecucionCUDA}
    \caption{Ejemplo de escalabilidad automática en el número de multiprocesadores.}
    \label{fig:DiagramaEjecucionCUDA}
\end{figure}

Un \emph{kernel} siempre es invocado desde el \emph{host} (CPU) y ejecuta en el \emph{device} (GPU). La GPU actúa como co-procesador de la CPU y mediante \emph{kernels} la CPU puede asignar trabajo al co-procesador. En la Figura \ref{fig:ModeloKernels} se muestra un ejemplo de una aplicación CUDA que posee un \emph{kernel} ``\emph{kernel A}''. Esta aplicación comienza ejecutando código secuencial en la CPU, en la primer parte secuencial se hace la invocación al \emph{kernel}, el cual ejecuta en la GPU. Una vez terminada la ejecución a nivel de GPU retorna a ejecutar código secuencial en la CPU.

El índice que identifica a un hilo de ejecución es un vector tridimensional, usando el mismo un hilo puede ser identificado usando una, dos o tres componentes del vector. De esta manera los hilos pueden forman un bloque de una, dos o tres dimensiones. Esta forma de agrupar los distintos hilos de un bloque permite invocar \emph{kernels} sobre distintos tipos de dominio (vector, matriz o volumen) de una manera más natural. Los bloques también pueden ser agrupados en una grilla (\emph{grid}) de una o dos dimensiones.

\begin{figure}[H]
    \centering
        \includegraphics[width=0.7\textwidth]{./Capitulo4/modeloKernels}
    \caption{Ejemplo de ejecución de una aplicación CUDA.}
    \label{fig:ModeloKernels}
\end{figure}

Como se muestra en la Figura \ref{fig:JerarquiaMemoriaCUDA}, cada hilo de CUDA puede acceder a múltiples espacios de memoria durante su ejecución, mientras que los diferentes espacios de memoria forman la jerarquía de memoria de la GPU.

En el primer nivel de la jerarquía, donde se da la latencia más baja y la menor capacidad de almacenamiento, se encuentran los registros. Desde la arquitectura menos avanzada (\emph{Compute Capability 1.0}), cada registro tiene 32 bits para almacenar un entero o un punto flotante. Cada hilo de ejecución tiene acceso a una cierta cantidad de registros, donde la cantidad depende del modelo de la GPU y la cantidad de hilos del bloque, y puede llegar hasta un máximo de 4096 en los modelos más avanzados (\emph{Compute Capability 2.0}). Además cada hilo de ejecución tiene su propio espacio privado de memoria local. La memoria local a cada hilo es pequeña, se dispone de 16 KB en la arquitectura menos avanzada y su latencia es relativamente alta (tanto como la memoria global).

Cada bloque tiene un espacio de memoria compartida entre todos sus hilos, este espacio compartido tiene el mismo tiempo de vida que el bloque, es decir, es válido mientras el bloque se encuentra en ejecución. El espacio de memoria compartida de cada bloque es de 16 KB, posee una latencia baja, similar a la de los registros. Puede ser controlada totalmente por el programador y puede ser usada como un caché para mejorar los tiempos de acceso a la memoria global.

\begin{figure}[H]
    \centering
        \includegraphics[width=0.7\textwidth]{./Capitulo2/jerarquiaMemoria}
    \caption{Jerarquía de memoria de la GPU.}
    \label{fig:JerarquiaMemoriaCUDA}
\end{figure}

Además todos los hilos de ejecución de la aplicación tienen acceso a un mismo espacio de memoria global. Este espacio es el que tiene la mayor capacidad de almacenamiento dentro de la jerarquía de memoria llegando hasta 4 GB en los modelos \emph{Tesla C1060}. La memoria global ofrece un alto ancho de banda (superior a 100 GB/s en el modelo \emph{Tesla C1060}) pero padece de latencia alta (cientos de ciclos) y no posee caché.

Existen dos espacios más de sólo lectura en la jerarquía que son accesibles por todos los hilos: el espacio de memoria constante y el espacio de memoria de textura. Ambos espacios de sólo lectura tienen tiempo de vida igual al tiempo de ejecución de la aplicación CUDA y cada uno esta optimizado para distintos usos \cite{nVidiaCUDAWebSite}. Ambos espacios de memoria tienen la misma latencia que la memoria global aunque la de textura posee un caché de 8 KB por cada bloque, lo cual mejora el tiempo de acceso a los datos.


\section{Métodos de aceleración para \emph{ray tracing}}

A partir del gran consumo computacional que significa trazar grandes cantidades de rayos, es vital encontrar métodos de a\-ce\-le\-ra\-ción para este proceso. Whitted al momento de desarrollar su algoritmo (en el año 1980) marcó el alto costo en tiempo en el trazado de rayos, desde ese momento hasta la actualidad se han propuesto diversas técnicas que buscan optimizar este proceso \cite{wald::PhD}.

Los métodos de optimización existentes pueden agruparse en dos categorías, según la forma de abordar el problema. A la primer categoría pertenecen las técnicas que apuntan a reducir el número de rayos a trazar.

Para disminuir la cantidad de rayos a su vez existen dos estrategias:
\begin{itemize}
\item Construir la imagen lanzando menos rayos primarios. Un ejemplo de este tipo de técnicas es la llamada \emph{adaptive sampling}. Usando este método, para cada píxel de la imagen, se trazan rayos primarios por cada uno de sus vértices. Si la intensidad de la luz en cada una de las esquinas del píxel varía significativamente con respecto a las otras, entonces el píxel es dividido en cuatro partes iguales. Luego se lanzan rayos primarios por cada nueva parte de la misma forma que se lanzaron en el píxel original, repitiendo esta división hasta lograr la calidad deseada. Una vez terminada la sub-división, el color del píxel es interpolado según el color de cada una de sus partes \cite{wald::PhD}.

\item Construir la imagen lanzando menos rayos secundarios. Un ejemplo de este tipo de técnicas es la llamada \emph{shadow caching}. La ma\-yo\-rí\-a de los rayos que se tranzan en un algoritmo de \emph{ray tracing} son rayos de sombra, ya que por cada rayo primario se trazan varios rayos de sombra. Para cada rayo de sombra se debe verificar si hay algún objeto en su camino hacia la fuente de luz y alcanza con que interseque con uno para garantizar oclusión. El caché de sombra explota el hecho de que muchos rayos se sombra son similares (sobre todo los que son originados por la misma fuente de luz) y que además intersecan con el mismo objeto \cite{wald::PhD}.
\end{itemize}

A la segunda categoría pertenecen las técnicas que buscan acelerar la intersección de los rayos con la escena. Se puede lograr acelerar el núcleo de los algoritmos de \emph{ray tracing} por varios caminos: eligiendo cuidadosamente las primitivas usadas para la construcción de las escenas y sus algoritmos de intersección, usando volúmenes envolventes que permitan descartar primitivas que no sean alcanzadas por el rayo o utilizando divisiones espaciales (estructuras de aceleración espacial) de la escena que garanticen no recorrer toda su lista de objetos por cada rayo que la atraviesa \cite{wald::PhD}.

Entre las estrategias más importantes para disminuir el tiempo de ejecución del algoritmo de \emph{ray tracing} se encuentra el uso de estructuras de aceleración espacial. Al momento de llevar a cabo cualquier implementación no trivial del algoritmo se deben considerar este tipo de técnicas ya que las mismas permiten reducir su orden (de $O(N)$ a $O(\log N)$) \cite{wald::PhD}. En la siguiente sub-sección se presentan las estructuras de aceleración espacial más usadas.

\section{Estructuras de aceleración espacial}\label{sec:EstAceleracionEsp}
Si se consideran todos los chequeos necesarios para generar una imagen utilizando el algoritmo de \emph{ray tracing}, estos pueden llegar a implicar el 95\% del tiempo de cálculo \cite{TesisEstructuras}.
Se han desarrollado técnicas para optimizar el tiempo que toman las intersecciones rayo-objeto, basadas en tratar de minimizar el número de intersecciones. A continuación se muestran las técnicas más importantes de este tipo según el trabajo de Thrane y Ole \cite{TesisEstructuras}.

\subsection{Subdivisión espacial}
En el método de sub-división espacial el volumen de la escena se divide en regiones. A cada región se le asigna una lista con todos los objetos que contiene, total o parcialmente. Estas listas se completan asignando a cada objeto la celda o las celdas que lo contienen. Esta técnica requiere un preproceso para crear la estructura de datos donde quedará registrada la información relativa al espacio que ocupan los objetos en la escena.

El preproceso consiste en dividir el volumen total de la escena en pequeños volúmenes o cajas. La forma de definir estas cajas es lo que marca la diferencia entre las técnicas de sub-división espacial. Una vez que las cajas están definidas juegan el mismo papel en todas ellas.

La gran ventaja de esta técnica de sub-división es que solo los objetos asignados a las cajas atravesadas por los rayos deben ser probados para una posible intersección.

\subsubsection{Sub-división espacial uniforme}
Cuando las particiones son todas del mismo tamaño la técnica se denomina sub-división espacial uniforme (SEU). En la Figura \ref{fig:ExUniformGrid} se muestra un ejemplo de este tipo de sub-división, que es totalmente independiente de la estructura de la escena.

\begin{figure}[H]
  \centering
    \includegraphics[width=0.7\textwidth]{../DOC_Relevamiento/exampleUniformGrid}
  \caption{Sub-división espacial uniforme aplicada a una escena.}
  \label{fig:ExUniformGrid}
\end{figure}

Otro aspecto a tener en cuenta es que las cajas se procesan en el mismo orden en que son encontradas por el rayo, lo que garantiza que cualquier caja atravesada por un rayo estará más cerca del origen del mismo que las restantes. Por consiguiente, una vez encontrado un punto de intersección, por lo general no será necesario considerar el contenido de las restantes cajas. Esto reduce considerablemente el número de objetos que se han de probar para intersección.
Cuando un rayo atraviesa una caja, se tiene que averiguar si hay intersección con cada uno de los objetos contenidos en ella, y se debe escoger la intersección que se encuentre más cercana al origen del rayo.

La construcción de la sub-división espacial uniforme se realiza de la siguiente forma: dados los bordes de la escena y la lista de objetos de esta se puede construir la sub-división espacial uniforme, el único parámetro necesario para su construcción es su resolución a lo largo de los tres ejes imaginarios.

Según Thrane y Ole \cite{TesisEstructuras} no hay una técnica que garantice la mejor resolución o por lo menos no para todos los casos. En el mismo trabajo se sugiere que la resolución al utilizar SEU sea $3\sqrt[3]{N}$ cajas a lo largo del eje más corto, donde $N$ es el número de triángulos de la escena. Aunque también se menciona que puede ajustarse empíricamente para lograr mejores resultados en imágenes particulares.
Una vez que se determina la resolución, es posible construir una matriz tridimensional de listas de objetos que servirá para manejar las cajas construidas y su contenido. Luego para cada objeto de la escena, se deben encontrar las cajas que lo contienen y agregar una referencia al objeto a cada una de ellas.

La técnica usada para moverse a través de las cajas de la grilla es equivalente (para tres dimensiones) a la técnica para dibujar una línea en dos dimensiones, cuyo algoritmo es denominado Digital Differential Algorithm (DDA) \cite{LibroCompGrafica}. Basados en DDA, Fujimoto et al. \cite{Fujimoto} proponen el algoritmo que permite recorrer la grilla, que es usado por Thrane y Ole en su trabajo, con algunas mejoras propuestas por Amanatides y Woo \cite{TesisEstructuras}.
En el Algoritmo \ref{alg:algoritmoDDA} se muestra un pseudo-código de la técnica para dos dimensiones para facilitar la comprensión (extenderla a tres dimensiones es simple).
\begin{algorithm}
    \caption{Pseudo-código de la recorrida de las cajas atravesadas por un rayo.}
    \label{alg:algoritmoDDA}
    \begin{algorithmic}
        \While{$X$ y $Y$ estén dentro de la grilla}
            \State chequeo de intersección con los triángulos de la caja actual
            \If{hay intersección en esta caja}
                \State se detiene el algoritmo y se retorna la intersección
            \EndIf
            \If{$tmax_{x} < tmax_{y}$}
                \State $X \leftarrow X + step_{x}$
                \State $tmax_{x} \leftarrow tmax_{x} + delta_{x}$
            \Else
                \State $Y \leftarrow Y + step_{y}$
                \State $tmax_{y} \leftarrow tmax_{y} + delta_{y}$
            \EndIf
        \EndWhile\\
        \Return no hay intersección
    \end{algorithmic}
\end{algorithm}

Antes de comenzar la ejecución del Algoritmo \ref{alg:algoritmoDDA}, se debe identificar la caja inicial, es decir la primer caja que atraviesa el rayo. Si el origen del rayo se encuentra dentro de una caja determinada, entonces esta es la inicial. En caso contrario, se busca el primer punto de la grilla que interseca con el rayo y se usa este punto para localizar la caja inicial. Las coordenadas de este se guardan en las variables $X$ e $Y$.
Además, se deben crear las variables $step_{x}$ y $step_{y}$, cuyos valores serán $\pm1$ dependiendo del signo de las componentes $x$ e $y$ del vector dirección del rayo. Estos valores serán usados para incrementar o decrementar las variables $X$ y $Y$, y así ir avanzando a lo largo de la trayectoria del rayo.
Lo próximo que se necesita es la máxima distancia que se puede avanzar a lo largo de la trayectoria del rayo antes de cruzar un borde vertical u horizontal de una caja. Estas distancias están representadas por las variables $tmax_{x}$ y $tmax_{y}$ respectivamente (ver Figura \ref{fig:ExampleDDA}). El mínimo entre estas dos variables determina la máxima distancia que se puede avanzar a través de la trayectoria del rayo sin salir de los bordes de la caja actual.
Por último se calculan $delta_{x}$ y $delta_{y}$. La primera indica la distancia horizontal (en la trayectoria del rayo) que se debe avanzar para pasar a la siguiente caja. Esta se calcula de la siguiente manera: \[delta_{x} = \frac{tamcaja_{x}}{rayodireccion_{x}}\] La segunda variable indica la distancia vertical y se calcula de la misma forma.
Luego de la inicialización de estas variables se usa un algoritmo (Algoritmo \ref{alg:algoritmoDDA}) incremental simple para avanzar a lo largo de las cajas que el rayo atraviesa.
\begin{figure}[H]
  \centering
    \includegraphics[width=0.7\textwidth]{../DOC_Relevamiento/algoritmoVoxels}
  \caption{Relación entre el rayo, $tmax_{x}$, $tmax_{y}$, $delta_{x}$ y $delta_{y}$. La caja inferior izquierda contiene el punto origen del rayo.}
  \label{fig:ExampleDDA}
\end{figure}

La sub-división espacial uniforme fue implementada por primera vez sobre una GPU por Purcell y se convirtió en la única estructura de aceleración en ser paralelizada sobre GPU hasta ese momento (año 2004) \cite{Purcell}.
En el trabajo de Thrane y Ole se resumieron las principales razones por las cuales se considera a esta estructura buena para ser paralelizada sobre una GPU. Estas razones son:
\begin{itemize}
  \item Cada caja atravesada por el rayo puede ser localizada y accedida en tiempo constante usando aritmética simple. Esto elimina la necesidad de recorrer árboles (como en otras estructuras de aceleración) y por lo tanto, el manejo de mucha información a nivel de la GPU, lo cual resulta muy costoso.
  \item El desplazamiento a través de las cajas atravesadas se hace de forma incremental y con sumas sencillas, lo cual elimina la necesidad de una pila y hace posible visitar las cajas en orden, es decir aumentando la distancia desde el origen del rayo.
  \item Se puede explotar el hecho de que las cajas se recorren en orden para detener la recorrida cuando se de una intersección en la caja actual.
  \item El algoritmo de recorrido a través de las cajas que interseca el rayo esta dado por un vector lo cual es altamente compatible con el conjunto de instrucciones de una GPU.
\end{itemize}
En la sub-división espacial se puede dar el caso de que un polígono sea referenciado por más de una caja. Esto genera que en ocasiones especiales, se haga más de una vez el mismo test de intersección. Para resolver esto se han generado técnicas como la denominada \emph{mailboxing}, que mantiene una tabla donde se asocia cada rayo con el último polígono al cual se le realizó el test de intersección \cite{AmanatidesWoo}. Al emplear estrategias de la paralelización este tipo de técnicas no pueden utilizarse, lo que implica que el algoritmo paralelo debería hacer chequeos repetidos \cite{TesisEstructuras}.

\subsubsection{\emph{Kd-Trees}}

Al igual que la sub-división espacial uniforme la estructura \emph{kd-tree} es una instancia particular de la sub-división espacial. La diferencia que tiene es que representa la escena con una estructura jerárquica basada en un árbol binario. En esta estructura se hace una distinción con respecto al tipo de los nodos, se distinguen los nodos internos de las hojas. Los nodos hoja se corresponden con las cajas y tienen las referencias a los objetos que se encuentran dentro de las mismas. Los nodos internos se corresponden con la forma en que se divide el espacio. De esta manera, los nodos internos contienen un plano de corte y referencias a cada uno de los dos sub-árboles, mientras que los nodos hojas contienen listas de objetos.

Esta técnica de división del espacio tiene prácticamente las mismas ventajas que la sub-división espacial uniforme. Pero esta división intenta mejorar a la uniforme considerando que los objetos no están uniformemente distribuidos en la escena.

La construcción de un \emph{kd-tree} se hace de forma recursiva, siguiendo un enfoque top-down. Dada una caja que contenga completamente a la escena y una lista de objetos contenidos en ella, se escoge un plano de corte perpendicular a uno de los ejes de coordenadas, que divida la caja en dos. Al dividir se generan dos nuevos volúmenes, y cada uno de ellos es representado agregando un hijo al nodo asociado a la caja original. Cada uno de los objetos que contiene la caja original es asignado al nodo hijo que lo contiene. En caso de que un objeto tenga intersección no vacía con el plano de corte, entonces este objeto es asignado a ambos hijos. Este procedimiento continúa hasta que se alcanza una profundidad definida de antemano o hasta que el número de objetos contenidos en cada caja sea menor a un número definido anteriormente. Havran \cite{Havran} sugiere que la profundidad máxima sea igual a $16$ y que la cantidad de objetos por caja sea $2$ para lograr un rendimiento óptimo. Thrane y Ole \cite{TesisEstructuras} analizaron estos valores y concluyeron que $16$ como profundidad máxima no era un buen valor para las escenas realistas. Se concluyó que, como la escena es dividida en dos en cada nivel del árbol entonces, una profundidad más convincente sería una que fuera resultado de una función logarítmica en el número de triángulos de la escena. Esta consideración también fue adoptada por Pharr y Humphreys \cite{PharrHumphreys}, los cuales usaron $8 + 1\ldotp3\log(N)$ como profundidad máxima, donde $N$ es el número de triángulos de la escena.

En el Apéndice \ref{sec:ApendiceEstructurasAceleracion} se presenta un relevamiento más profundo del estado del arte de la estructura \emph{kd-tree}.


\subsection{Jerarquía de Volúmenes Envolventes (BVH)}
La estructura BVH divide la escena y guarda la información de la división en una jerarquía definida por un árbol. Difiere de las técnicas de sub-división espacial porque no divide el espacio sino que divide objetos. El volumen envolvente de una pieza de geometría es un objeto geométrico simple que la envuelve, es decir que la contiene en su interior. Claramente, si falla la intersección de un rayo con el volumen envolvente de un objeto, falla la intersección con cualquier cosa que este dentro del mismo y por lo tanto falla la intersección rayo-objeto.

La motivación para usar volúmenes envolventes es que realizar un chequeo de intersección con un objeto simple, como lo es un volumen envolvente, es mucho menos costoso que hacerlo contra el objeto que contiene dentro, que por lo general no es un objeto simple. La aceleración que pueda lograrse mediante esta técnica dependerá de la complejidad de los objetos de la escena y de los volúmenes envolventes que se usen.

Una jerarquía de volúmenes envolventes esta formada por un nodo raíz que contiene un volumen que envuelve a todos los demás volúmenes, y también contiene a todos los objetos de la escena. Cada nodo interno del árbol tiene como hijos a un conjunto de nodos internos, cada uno de ellos con un volumen envolvente asociado, o a un conjunto de nodos hoja, con un número cualquiera de objetos de la escena asociados. En la Figura \ref{fig:BVHExample} se muestra una estructura BVH como ejemplo, la cual utiliza cajas alineadas a los ejes como volúmenes envolventes. Es posible utilizar otros objetos envolventes, por ejemplo, cajas no alineadas a los ejes, cilindros, esferas, etc.

\begin{figure}[H]
  \centering
    \includegraphics[width=0.9\textwidth]{../DOC_Relevamiento/BVHExample}
  \caption{Ejemplo de estructura BVH que utiliza cajas alineadas a los ejes.}
  \label{fig:BVHExample}
\end{figure}

El algoritmo de recorrida de los volúmenes envolventes es realizado usando un simple e intuitivo descenso recursivo.

Una medida razonable de la calidad de una estructura BVH, es el costo promedio de aplicarle el algoritmo de recorrida, dado un rayo arbitrario. No hay ningún algoritmo conocido que construya estructuras BVH óptimas, tampoco es obvio como evaluar el costo promedio de atravesar con un rayo arbitrario una estructura de este tipo.
Goldsmith y Salmon proponen una función de costo conocida como la heurística del área de las superficies \cite{GoldsmithSalmon}. Está formalizada usando el área de la superficie del nodo padre y del nodo hijo y sigue la relación de la Ecuación \ref{eqn:AreasSuperficies}.
\begin{equation} %%% Ecuacion pagina 53!!!
    P(hit(c) | hit(p)) \approx \frac{S_{c}}{S_{p}}
    \label{eqn:AreasSuperficies}
\end{equation}

Donde: $hit(n)$ es el evento en que el rayo atraviesa el nodo $n$, $S_{n}$ es el área de la superficie del nodo $n$ y $c$ y $p$ son el nodo hijo y padre, respectivamente.

La función da un estimativo del costo de la jerarquía cuando se trata de atravesar por un rayo cualquiera.

Como no existe un algoritmo para construir eficientemente una estructura BVH óptima, se han propuesto heurísticas de construcción. Por lo general, estas heurísticas se basan en una de las dos ideas propuestas por Kay y Kajiya \cite{KayKajiya} y Goldsmith y Salmon \cite{GoldsmithSalmon}, en estos trabajos se puede profundizar sobre el tema.

En el Apéndice \ref{sec:ApendiceEstructurasAceleracion} se presenta un relevamiento más profundo del estado del arte de la estructura BVH.


\subsection{Conclusiones sobre aceleración espacial}

En el trabajo de Thrane y Ole se analizan experiencias obtenidas al implementar y usar la sub-división espacial uniforme en la paralelización del algoritmo de trazado de rayos. Para escenas con objetos simples la a\-ce\-le\-ra\-ción lograda a través de esta estructura es mayor que la obtenida a través de \emph{kd-tree} o BVH. Cuando las escenas poseen objetos complejos la a\-ce\-le\-ra\-ción no es tan buena en comparación con las mismas estructuras. Además se menciona que la estructura no es buena para escenas donde se dan grandes variaciones en la densidad de los objetos desde el punto de vista geométrico. También se destaca que el algoritmo para recorrer las cajas es muy simple de implementar y que requiere pocas operaciones aritméticas para avanzar de caja en caja. Así mismo el procedimiento para la construcción de la SEU es más simple que el de las estructuras \emph{kd-tree} o BVH. Estas propiedades del algoritmo de recorrida y de construcción son muy importantes para implementarlo en una GPU, y contrarrestan algunas propiedades negativas que se presentan en el trabajo, como por ejemplo que requiere guardar mayor cantidad de datos para representar el estado del recorrido, en comparación con las estructuras \emph{kd-tree} y BVH. Los autores concluyen que el algoritmo de recorrida de las cajas se puede paralelizar muy fácilmente en una GPU pero que la implementación tendría un bajo rendimiento para escenas complejas y un buen rendimiento para escenas simples y de mediano porte, en comparación con el obtenido al usar las estructuras \emph{kd-tree} o BVH.

Por otro lado, Thrane y Ole \cite{TesisEstructuras} implementaron la estructura de a\-ce\-le\-ra\-ción \emph{kd-tree} sobre GPU. Usaron las técnicas (\emph{restart} y \emph{backtrack}) y concluyeron que para la mayoría de las escenas, esta estructura mejora en rendimiento a la sub-división espacial uniforme. También se recalca que las dos técnicas para realizar la recorrida a través de los \emph{voxeles} sufren de alta complejidad en sus algoritmos (en el contexto de una GPU) y esto no es deseable ya que aumenta el tiempo de ejecución. Aunque también se menciona que el tiempo de ejecución que se agrega por la complejidad puede verse compensado, en cierto grado, por la habilidad de la estructura para adaptarse a los cambios de densidad de objetos en la escena. Con respecto al algoritmo para la construcción de la estructura, se concluye que dada su condición de recursivo su implementación a nivel de GPU es más compleja, en comparación con la sub-división uniforme.

En el trabajo de Lauterbach et al. \cite{Lauterbach06} luego de haber usado la estructura \emph{kd-tree} para diversos casos de prueba se llegó a la conclusión de que con esta se obtienen mejores resultados de los que se obtienen utilizando la estructura BVH, para escenas estáticas (las escenas estáticas se caracterizan por componerse de objetos fijos, que no cambian de posición ni de forma en el tiempo). Esta ganancia en rendimiento tiene como costo asociado un mayor consumo de memoria y una mayor complejidad para implementar y optimizar la construcción de la estructura.

Con respecto a la estructura BVH, Thrane y Ole \cite{TesisEstructuras} implementaron sobre una GPU ambas estrategias de construcción, el enfoque \emph{top-down} y el \emph{bottom-up}, para comparar resultados. Usaron siempre volúmenes envolventes alineados a los ejes, en ambas construcciones. La estrategia de recorrida a lo largo de los nodos hijos fue siempre de izquierda a derecha. Esto en algunos casos no resultó muy eficiente ya que si el rayo atraviesa todos los volúmenes envolventes y el volumen donde se da la intersección más cercana es el último de una lista de hermanos, se debe revisar todos los demás volúmenes antes de llegar a un resultado. En un caso de este tipo prácticamente se está utilizando fuerza bruta para encontrar la intersección, situación que se busca evitar con la introducción de estructuras de aceleración. Una alternativa es recorrer la lista de hermanos según la dirección del rayo pero los autores optaron por no mejorar este aspecto para mantener la simplicidad en el algoritmo (ya que debe ser implementado en una GPU).

La gran ventaja de la estructura BVH es la simplicidad del algoritmo de recorrida y la gran desventaja es el orden fijo en que se recorren los nodos hermanos \cite{TesisEstructuras}. Además Thrane y Ole \cite{TesisEstructuras} concluyeron que para escenas complejas esta estructura es la que tiene mejor rendimiento sobre la GPU, comparando con la sub-división espacial uniforme y con la \emph{kd-tree}. Como un agregado se destaca que la implementación de la construcción es simple, aunque para llevarla a nivel de GPU hay que resolver el problema de la recursión si se elige el enfoque \emph{top-down} o el problema de encontrar un buen orden para la lista de objetos de la escena si se elige el enfoque \emph{bottom-up}. Además, la construcción en cualquiera de los enfoques es computacionalmente más costosa que la construcción de la grilla uniforme.

Lauterbach et al. \cite{Lauterbach06} luego de haber usado la estructura BVH para diversos casos de prueba concluyeron que con esta estructura se obtienen mejores resultados de los que se obtienen utilizando la \emph{kd-tree}, para escenas dinámicas (las escenas dinámicas se caracterizan por componerse de objetos que a medida que el tiempo avanza cambian de posición, forma, etc.). Además, los autores señalan que a la jerarquía de volúmenes envolventes es más fácil agregarle la optimización basada en paquetes de rayos que a la \emph{kd-Tree}.

En la Tabla \ref{table:ConclusionesEstructuras} se resumen las principales conclusiones sobre las estructuras de aceleración espacial.

\begin{table}[!hbt]
\begin{center}
    \small {
    \begin{tabular}{|p{7.5cm}|c|c|c|}
    \hline
    &SEU & Kd-Tree & BVH\\
    \hline
    Complejidad del algoritmo de construcción & Baja & Alta & Media\\
    \hline
    Aceleración lograda para escenas simples & Alta & Baja & Media\\
    \hline
    Aceleración lograda para escenas complejas & Baja & Media & Alta\\
    \hline
    Adaptación frente a escenas no uniformes & Baja & Media & Alta\\
    \hline
    Consumo de memoria & Medio & Alto & Bajo\\
    \hline
    Complejidad del algoritmo de atravesado & Media & Alta & Baja\\
    \hline
    Adaptación frente a escenas estáticas & Mala & Buena & Mala\\
    \hline
    Adaptación frente a escenas dinámicas & Mala & Mala & Buena\\
    \hline
    \end{tabular}
}
\caption{Comparación de las estructuras de aceleración.}
\label{table:ConclusionesEstructuras}
\end{center}
\end{table}

\section{\emph{Ray tracing} interactivo}

Se llama \emph{ray tracing} interactivo (RI) a una implementación del algoritmo que permita modificar parámetros que afecten a la imagen generada y que el ojo humano pueda percibir las consecuencias de las modificaciones como una animación, para lograr esto se necesitan por lo menos 24 FPS (\emph{frames} por segundo). A diferencia del \emph{ray tracing} en tiempo real este tipo de implementaciones no serviría para hacer video-juegos o generadores de video en tiempo real, dado que la cantidad de imágenes por segundo no sería suficiente.

\subsection{Estado del Arte}

El artículo de Wald et al. \cite{Wald:2001:STAR-IRT} plantea cual es el estado del arte en la generación de imágenes para programas en los que uno de los objetivos es la capacidad de interactuar con los usuarios. Según lo relevado en dicho artículo, el algoritmo que generalmente es utilizado para la generación de imágenes es el de rasterización, pero debido al constante aumento del poder de cómputo del \emph{hardware} el algoritmo de \emph{ray tracing} surge como una alternativa válida.

Para lograr que el algoritmo de \emph{ray tracing} sea interactivo se le deben aplicar estrategias de simplificación y aceleración. En el trabajo de Wald et al. se presentan diversas técnicas que permiten utilizar \emph{ray tracing} para lograr buenos efectos visuales en tiempos interactivos, y se clasifican según las categorías que se presentan a continuación:

\begin{itemize}
  \item basadas en rasterización. Este tipo de técnicas combinan la alta velocidad de generación de imagen del \emph{hardware} de rasterización de la actualidad con la calidad superior de las imágenes generadas mediante \emph{ray tracing}. Por ejemplo, existe una técnica que utiliza como base la rasterización y únicamente usa \emph{ray tracing} para el cálculo de algunos efectos de iluminación.
  \item basadas en imagen. Este tipo de técnicas sacan provecho de la coherencia temporal entre las imágenes generadas y se basan en extraer información de la imagen generada en el paso anterior para generar solo algunos píxeles de la imagen siguiente.
  \item basadas en \emph{ray tracing}. Estas técnicas apuntan a reducir el costo por píxel del algoritmo de \emph{ray tracing} mediante optimizaciones al proceso de trazado de rayos.
  \item basadas en acelerar \emph{ray tracing}. Las técnicas pertenecientes a esta ca\-te\-go\-rí\-a intentan bajar los costos computacionales asociados al trazado de rayos, por ejemplo utilizando arquitecturas de memoria de las CPU actuales que puedan ser empleadas de manera eficiente o tratando de explotar la capacidad del algoritmo de ser ejecutado en paralelo.
\end{itemize}

\subsection{Interactividad sobre multiprocesadores de memoria compartida}

El artículo de Wald et al. describe la exploración dentro de las técnicas que buscan acelerar los algoritmos de \emph{ray tracing} de modo de intentar que se puedan ejecutar de manera interactiva. En dicha investigación realizan la implementación de un algoritmo de \emph{ray tracing} que ejecuta en una arquitectura multiprocesador. En la solución desarrollada se logró la interactividad, en gran medida porque la plataforma de ejecución consistió en una plataforma de gran poder de cómputo (SGI Origin 2000). Por otra parte se menciona que aún fuera de estas condiciones (usando PCs de bajo costo) es posible lograr que \emph{ray tracing} sea interactivo por tres características del algoritmo:
\begin{itemize}
  \item escala bien en cientos de procesadores.
  \item para escenas estáticas el tiempo de render de los frames (generación de cada cuadro de una animación) el orden del algoritmo es sub-lineal en la cantidad de objetos básicos en la escena.
  \item permite agregar una gran variedad de objetos básicos y efectos de sombreado programados por el usuario.
\end{itemize}

Para el trabajo de Wald et al. se utilizó como base el algoritmo clásico de Whitted \cite{PaperDel80} modificándolo para obtener mejoras visuales y de performance. Las mejoras que afectan directamente a la velocidad del algoritmo se pueden dividir en dos grandes ramas: aceleración o eliminación de cálculos de verificación de intersección entre rayos y objetos, y paralelización. Para optimizar la cantidad de cálculos de la intersección se genera una división espacial de la escena (SEU) y se combina con volúmenes envolventes para los objetos de la misma.

Para paralelizar el algoritmo se emplea un sistema de memoria compartida, y el algoritmo utiliza una estrategia maestro-esclavo para la generación de la imagen. El proceso maestro inicializa la escena a renderizar y genera rayos que serán lanzados hacia la escena, los cuales se ingresan en una cola. Posteriormente a la etapa de inicialización los procesos esclavos obtendrán a demanda desde la cola los rayos para procesar. Esta estrategia tiene un gran problema en el tiempo necesario para la sincronización entre procesos, por esto los rayos se agrupan de a varios para obtener una mejor performance. Las limitaciones que se pudieron constatar para el algoritmo de \emph{ray tracing} son el balanceo de carga y la sincronización entre los procesos.

En la versión final del algoritmo se logró la interactividad con una cantidad relativamente pequeña de procesadores, 8 procesadores \emph{dual PIII} a \emph{800 MHz} conectados mediante \emph{Gigabit Ethernet}. Esta implementación de \emph{ray tracing} mostró que es un algoritmo muy bueno para presentar efectos de luz dinámicos pero no así para procesar escenas en las cuales los objetos cambian dinámicamente.

\section{Conclusiones sobre aceleración}

La aceleración del algoritmo de \emph{ray tracing} de Whitted puede lograrse empleando diversos métodos. Al estudiar las diferentes técnicas en el relevamiento realizado se identifican las más importantes. La estrategia que se identifica para acelerar \emph{ray tracing} es explotar su gran capacidad de paralelización. En la implementación realizada en este proyecto se paralelizó el algoritmo de Whitted teniendo en cuenta los problemas más comunes de esta estrategia, la sincronización entre hilos y el balanceo de trabajo de procesamiento entre ellos.

Otro problema que se identifica como importante es el de disminuir el tiempo de procesamiento que insume la intersección de los rayos con la escena. Para atacar dicho problema en este proyecto se emplearon estrategias en dos sentidos, disminuir el tiempo que toma cada intersección rayo-primitiva y disminuir la cantidad de intersecciones que se prueban por cada rayo que incide la escena. Para esto se escogió un algoritmo eficiente de intersección rayo-primitiva y se dividió la escena uniformemente según una sub-división espacial uniforme, respectivamente.

