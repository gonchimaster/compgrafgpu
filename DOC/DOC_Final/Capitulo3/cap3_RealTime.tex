\chapter{Aceleración del algoritmo de Raytracing} % 20 páginas mas o menos...

\section{Introducción}
Esta sección presenta en detalle de los algoritmos y técnicas existentes para la aceleración de la generación de imágenes por computadora. Se verán los métodos que fueron analizados durante el desarrollo de este trabajo, centrándose en dos puntos principales que son: las estructuras de aceleración espacial y la paralelización de procesos. Por un lado se busca reducir la cantidad de cálculos requeridos para la generación de una imagen y por otro lado hacer que los cálculos se realicen en menos tiempo. Para la paralelización de algoritmos en este proyecto se optó por utilizar una paralelización del algoritmo en la GPU, en este cápitulo se justifica además por que se consideró esta plataforma para el proyecto.

\section{Paralelización de algoritmos en GPU}

En noviembre de 2006 NVIDIA lanzó CUDA (Compute Unified Device Architecture), una arquitectura de computación paralela de propósito general que hace uso del núcleo de procesamiento paralelo de las GPU de NVIDIA para resolver una amplia variedad de problemas computacionales de una manera más eficiente que en una CPU. El modelo de programación paralela propuesto por NVIDIA fue totalmente nuevo y la programación sobre el mismo se hace a través del lenguaje de alto nivel CUDA que permite el uso del lenguaje C para la programación.

La arquitectura CUDA basa su poder de procesamiento en un conjunto de multiprocesadores (variable dependiente del modelo de GPU), donde cada uno de ellos procesa parte de la carga de trabajo en paralelo con los demás. Un multiprocesador está compuesto por 8 procesadores, una unidad de memoria compartida y otras 3 unidades que permiten controlar el funcionamiento del mismo. Cada multiprocesador crea, administra y ejecuta hilos concurrentemente en el hardware sin incrementar el tiempo de ejecución por la planificación (\emph{scheduling}).

El modelo de programación esta basado en tres abstracciones fundamentales: una jerarquía de grupos de hilos de ejecución, memoria compartida y barreras de sincronización de la ejecución. Estas abstracciones guían al programador a dividir el problema en sub-problemas que pueden ser resueltos en forma paralela e independiente por medio de bloques de hilos de ejecución. A su vez cada sub-problema de divide en piezas más chicas que pueden ser resueltas en paralelo y cooperando entre ellas, usando los hilos de ejecución de cada bloque. Descomponer el problema de esta forma permite la escalabilidad automática en el número de procesadores, ya que cada bloque de hilos puede ser despachado hacia cualquier conjunto de procesadores (multiprocesador) disponible en cualquier orden, concurrentemente o secuencialmente. De esta manera cualquier aplicación CUDA puede ejecutar sobre cualquier número de multiprocesadores y sólo se necesita conocer este número en tiempo de ejecución, lo que implica que no sea necesaria una nueva compilación. En la Figura \ref{fig:DiagramaEjecucionCUDA} se considera una aplicación CUDA que esta dividida en cuatro bloques y se muestra como se asignan los bloques de hilos de ejecución en dos GPU distintas, donde una tiene dos multiprocesadores y la otra tiene cuatro.

En la extensión del lenguaje C que hace CUDA es posible definir funciones (de la misma forma que en el lenguaje base) que a diferencia de las funciones normales de C, cuando son invocadas ejecutan $N$ veces en paralelo, mediante $N$ hilos de ejecución diferentes. Estas funciones propias de CUDA son llamadas \emph{kernels}. Dentro de este tipo especial de funciones se tiene acceso a información propia de CUDA que indica por ejemplo, el identificador del hilo de ejecución o el identificador de bloque que lo contiene. Esta información es de vital importancia ya que es usada para parametrizar la ejecución del \emph{kernel} en función de los hilos de ejecución.

\begin{figure}[H]
    \centering
        \includegraphics[width=0.7\textwidth]{./Capitulo4/diagramaEjecucionCUDA}
    \caption{Ejemplo de escalabilidad automática en el número de multiprocesadores.}
    \label{fig:DiagramaEjecucionCUDA}
\end{figure}

Un \emph{kernel} siempre es invocado desde el \emph{host} (CPU) y ejecuta en el \emph{device} (GPU). La GPU actúa como co-procesador de la CPU y mediante \emph{kernels} la CPU puede asignar trabajo al co-procesador. En la Figura \ref{fig:ModeloKernels} se muestra un ejemplo de una aplicación CUDA que posee un \emph{kernel} ``\emph{kernel A}''. Esta aplicación comienza ejecutando código secuencial en la CPU, en la primer parte secuencial se hace la invocación al \emph{kernel}, el cual ejecuta en la GPU. Una vez terminada la ejecución a nivel de GPU retorna a ejecutar código secuencial en la CPU.

El índice que identifica a un hilo de ejecución es un vector tridimensional, usando el mismo un hilo puede ser identificado usando una, dos o tres componentes del vector. De esta manera los hilos pueden forman un bloque de una, dos o tres dimensiones. Esta forma de agrupar los distintos hilos de un bloque permite invocar \emph{kernels} sobre distintos tipos de dominio (vector, matriz o volumen) de una manera más natural. Los bloques también pueden ser agrupados en una grilla (\emph{grid}) de una o dos dimensiones.

\begin{figure}[H]
    \centering
        \includegraphics[width=0.7\textwidth]{./Capitulo4/modeloKernels}
    \caption{Ejemplo de ejecución de una aplicación CUDA.}
    \label{fig:ModeloKernels}
\end{figure}

Como se muestra en la Figura \ref{fig:JerarquiaMemoriaCUDA}, cada hilo de CUDA puede acceder a múltiples espacios de memoria durante su ejecución, mientras que los diferentes espacios de memoria forman la jerarquía de memoria de la GPU.

En el primer nivel de la jerarquía, donde se da la latencia más baja y la menor capacidad de almacenamiento, se encuentran los registros. Desde la arquitectura menos avanzada (\emph{Compute Capability 1.0}), cada registro tiene 32 bits para almacenar un entero o un punto flotante. Cada hilo de ejecución tiene acceso a una cierta cantidad de registros, donde la cantidad depende del modelo de la GPU, y puede llegar hasta un máximo de 4096 en los modelos más avanzados (\emph{Compute Capability 2.0}). Además cada hilo de ejecución tiene su propio espacio privado de memoria local. La memoria local a cada hilo es pequeña, se dispone de 16 KB en la arquitectura menos avanzada y su latencia es relativamente alta (tanto como la memoria global).

Cada bloque tiene un espacio de memoria compartida entre todos sus hilos, este espacio compartido tiene el mismo tiempo de vida que el bloque, es decir, es válido mientras el bloque se encuentra en ejecución. El espacio de memoria compartida de cada bloque es de 16 KB, posee una latencia baja, similar a la de los registros. Puede ser controlada totalmente por el programador y puede ser usada como un caché para mejorar los tiempos de acceso a la memoria global.

\begin{figure}[H]
    \centering
        \includegraphics[width=0.7\textwidth]{./Capitulo2/jerarquiaMemoria}
    \caption{Jerarquía de memoria de la GPU.}
    \label{fig:JerarquiaMemoriaCUDA}
\end{figure}

Además todos los hilos de ejecución de la aplicación tienen acceso a un mismo espacio de memoria global. Este espacio es el que tiene la mayor capacidad de almacenamiento dentro de la jerarquía de memoria llegando hasta 4 GB en los modelos \emph{Tesla C1060}. La memoria global ofrece un alto ancho de banda (superior a 100 GB/s en el modelo \emph{Tesla C1060}) pero padece de latencia alta (cientos de ciclos) y no posee caché.

Existen dos espacios más de sólo lectura en la jerarquía que son accesibles por todos los hilos: el espacio de memoria constante y el espacio de memoria de textura. Ambos espacios de sólo lectura tienen tiempo de vida igual al tiempo de ejecución de la aplicación CUDA y cada uno esta optimizado para distintos usos \cite{nVidiaCUDAWebSite}. Ambos espacios de memoria tienen la misma latencia que la memoria global aunque la de textura posee un caché de 8 KB por cada bloque, lo cual mejora el tiempo de acceso a los datos.


\section{Métodos de aceleración para raytracing}

A partir del gran consumo computacional que significa trazar grandes cantidades de rayos, es vital encontrar métodos de a\-ce\-le\-ra\-ción para este proceso. Whitted al momento de desarrollar su algoritmo (en el año 1980) marcó el alto costo en tiempo en el trazado de rayos, desde ese momento hasta la actualidad se han propuesto diversas técnicas que buscan optimizar este proceso \cite{wald::PhD}.

Los métodos de optimización existentes pueden agruparse en dos categorías, según la forma de abordar el problema. A la primer categoría pertenecen las técnicas que apuntan a reducir el número de rayos a trazar.

Para disminuir la cantidad de rayos a su vez existen dos estrategias:
\begin{itemize}
\item Construir la imagen lanzando menos rayos primarios. Un ejemplo de este tipo de técnicas es la llamada \emph{adaptive sampling}. Usando este método, para cada pixel de la imagen, se trazan rayos primarios por cada uno de sus vértices. Si la intensidad de la luz en cada una de las esquinas del pixel varía significativamente con respecto a las otras, entonces el pixel es dividido en cuatro partes iguales. Luego se lanzan rayos primarios por cada nueva parte de la misma forma que se lanzaron en el pixel original, repitiendo esta división hasta lograr la calidad deseada. Una vez terminada la subdivisión, el color del pixel es interpolado según el color de cada una de sus partes \cite{wald::PhD}.

\item Construir la imagen lanzando menos rayos secundarios. Un ejemplo de este tipo de técnicas es la llamada \emph{shadow caching}. La ma\-yo\-rí\-a de los rayos que se tranzan en un algoritmo de raytracing son rayos de sombra, ya que por cada rayo primario se trazan varios rayos de sombra. Para cada rayo de sombra se debe verificar si hay algún objeto en su camino hacia la fuente de luz y alcanza con que interseque con uno para garantizar oclusión. El caché de sombra explota el hecho de que muchos rayos se sombra son similares (sobre todo los que son originados por la misma fuente de luz) y que además intersecan con el mismo objeto \cite{wald::PhD}.
\end{itemize}

A la segunda categoría pertenecen las técnicas que buscan acelerar la intersección de los rayos con la escena. Se puede lograr acelerar el núcleo de los algoritmos de raytracing por varios caminos: eligiendo cuidadosamente las primitivas usadas para la construcción de las escenas y sus algoritmos de intersección, usando volúmenes envolventes que permitan descartar primitivas que no sean alcanzadas por el rayo o utilizando divisiones espaciales (estructuras de aceleración espacial) de la escena que garanticen no recorrer toda su lista de objetos por cada rayo que la atraviesa \cite{wald::PhD}.

Entre las estrategias más importantes para disminuir el tiempo de ejecución del algoritmo de Raytracing se encuentra el uso de estructuras de aceleración espacial. Al momento de llevar a cabo cualquier implementación no trivial del algoritmo se deben considerar este tipo de técnicas ya que las mismas permiten reducir su orden (de $O(N)$ a $O(\log N)$) \cite{wald::PhD}. A continuación se presentan las estructuras de aceleración espacial más usadas.

\section{Estructuras de aceleración espacial}
Si se consideran todos los chequeos necesarios para generar una imagen utilizando el algoritmo de Raytracing, estos pueden llegar a tomar el 95\% del tiempo de cálculo \cite{TesisEstructuras}.
Se han desarrollado técnicas para optimizar el tiempo que toman las intersecciones rayo-objeto, basadas en tratar de minimizar el número de intersecciones. A continuación se muestran las más importantes de este tipo de técnicas según el trabajo de Thrane y Ole \cite{TesisEstructuras}.

\subsection{Subdivisión espacial}
En el método de subdivisión espacial el volumen de la escena se divide en regiones. A cada región se le asigna una lista con todos los objetos que contiene, total o parcialmente. Estas listas se completan asignando a cada objeto la celda o las celdas que lo contienen. Esta técnica requiere un preproceso para crear la estructura de datos donde quedará registrada la información relativa al espacio que ocupan los objetos en la escena.

El preproceso consiste en dividir el volumen total de la escena en pequeños volúmenes o voxeles (el término voxel es la extensión a tres dimensiones de su homónimo en dos dimensiones pixel). La forma de definir estos voxeles es lo que marca la diferencia entre las técnicas de subdivisión espacial. Una vez que los voxeles están definidos juegan el mismo papel en todas las técnicas.

La gran ventaja de esta técnica de subdivisión es que solo los objetos asignados a los voxeles atravesados por los rayos deben ser probados para una posible intersección.

\subsubsection{Subdivisión espacial uniforme.}
Cuando las particiones (voxeles) son todas del mismo tamaño la técnica se denomina subdivisión espacial uniforme (SEU). En la Figura \ref{fig:ExUniformGrid} se muestra un ejemplo de este tipo de subdivisión, que es totalmente independiente de la estructura de la escena.
\begin{figure}[H]
  \centering
    \includegraphics[width=0.7\textwidth]{../DOC_Relevamiento/exampleUniformGrid}
  \caption{Subdivisión espacial uniforme aplicada a una escena.}
  \label{fig:ExUniformGrid}
\end{figure}

Otro aspecto a tener en cuenta es que los voxeles se procesan en el mismo orden en que son encontrados por el rayo, lo que garantiza que cualquier voxel intersecado por un rayo estará más cerca del origen del mismo que los restantes. Por consiguiente, una vez encontrado un punto de intersección, por lo general no será necesario considerar el contenido de los restantes voxeles. Esto reduce considerablemente el número de objetos que se han de probar para intersección.
Cuando un rayo atraviesa un voxel, se tiene que averiguar si hay intersección con cada uno de los objetos contenidos en él, y se debe escoger la intersección que se encuentre más cercana al origen del rayo.


La construcción de la subdivisión espacial uniforme se realiza de la siguiente forma: dados los bordes de la escena y la lista de objetos de esta se puede construir la subdivisión espacial uniforme, el único parámetro necesario para su construcción es su resolución a lo largo de los tres ejes imaginarios.

Según Thrane y Ole no hay una técnica que garantice la mejor resolución o por lo menos no para todos los casos. En el mismo trabajo se sugiere que la resolución sea $3\sqrt[3]{N}$ voxeles a lo largo del eje más corto, donde $N$ es el número de triángulos de la escena. Aunque también se sugiere que puede ajustarse empíricamente para lograr mejores resultados en imágenes particulares.
Una vez que la resolución es determinada, es posible construir una matriz tridimensional de listas de objetos que servirá para manejar los voxeles construidos y su contenido. Luego para cada objeto de la escena, se deben encontrar los voxeles que lo contienen y agregar una referencia al objeto a cada uno de ellos.

La técnica usada para moverse a través de los voxeles de la grilla es equivalente (para tres dimensiones) a la técnica para dibujar una línea en dos dimensiones, cuyo algoritmo es denominado Digital Differential Algorithm (DDA) \cite{LibroCompGrafica}. Basados en DDA, Fujimoto et al. \cite{Fujimoto} proponen el algoritmo que permite recorrer la grilla y este es usado por Thrane y Ole, con algunas mejoras propuestas por Amanatides y Woo \cite{TesisEstructuras}.
En el Algoritmo \ref{alg:algoritmoDDA} se muestra un pseudocódigo de la técnica para dos dimensiones para facilitar la comprensión (extenderla a tres dimensiones es simple).
\begin{algorithm}
    \caption{Recorrida de los voxeles atravesados por un rayo.}
    \label{alg:algoritmoDDA}
    \begin{algorithmic}
        \While{$X$ y $Y$ estén dentro de la grilla}
            \State chequeo de intersección con los triángulos del voxel actual
            \If{hay intersección en este voxel}
                \State se detiene el algoritmo y se retorna la intersección
            \EndIf
            \If{$tmax_{x} < tmax_{y}$}
                \State $X \leftarrow X + step_{x}$
                \State $tmax_{x} \leftarrow tmax_{x} + delta_{x}$
            \Else
                \State $Y \leftarrow Y + step_{y}$
                \State $tmax_{y} \leftarrow tmax_{y} + delta_{y}$
            \EndIf
        \EndWhile\\
        \Return no hay intersección
    \end{algorithmic}
\end{algorithm}

Antes de comenzar la ejecución del Algoritmo \ref{alg:algoritmoDDA}, se debe identificar el voxel inicial, es decir el primer voxel que atraviesa el rayo. Si el origen del rayo se encuentra dentro de un voxel determinado, entonces este es el inicial. En caso contrario, se busca el primer punto de la grilla que interseca con el rayo y se usa este punto para localizar el voxel inicial. Las coordenadas de este se guardan en las variables $X$ e $Y$.
Además, se deben crear las variables $step_{x}$ y $step_{y}$, cuyos valores serán $\pm1$ dependiendo del signo de las componentes $x$ e $y$ del vector dirección del rayo. Estos valores serán usados para incrementar o decrementar las variables $X$ y $Y$, y así ir avanzando a lo largo de la trayectoria del rayo.
Lo próximo que se necesita es la máxima distancia que se puede avanzar a lo largo de la trayectoria del rayo antes de cruzar un borde vertical u horizontal de un voxel. Estas distancias están representadas por las variables $tmax_{x}$ y $tmax_{y}$ respectivamente (ver Figura \ref{fig:ExampleDDA}). El mínimo entre estas dos variables determina la máxima distancia que se puede avanzar a través de la trayectoria del rayo sin salir de los bordes del voxel actual.
Por último se calculan $delta_{x}$ y $delta_{y}$. La primera indica la distancia horizontal (en la trayectoria del rayo) que se debe avanzar para pasar al siguiente voxel. Esta se calcula de la siguiente manera: \[delta_{x} = \frac{voxelsize_{x}}{raydirection_{x}}\] La segunda variable indica la distancia vertical y se calcula de la misma forma.
Luego de la inicialización de estas variables se usa un algoritmo (Algoritmo \ref{alg:algoritmoDDA}) incremental simple para avanzar a lo largo de los voxeles que el rayo atraviesa.
\begin{figure}[H]
  \centering
    \includegraphics[width=0.7\textwidth]{../DOC_Relevamiento/algoritmoVoxels}
  \caption{Relación entre el rayo, $tmax_{x}$, $tmax_{y}$, $delta_{x}$ y $delta_{y}$. El voxel inferior izquierdo contiene el punto origen del rayo.}
  \label{fig:ExampleDDA}
\end{figure}

La subdivisión espacial uniforme fue implementada por primera vez sobre una GPU por Purcell y se convirtió en la única estructura de aceleración en ser paralelizada sobre GPU hasta ese momento (año 2004) \cite{Purcell}.
En el trabajo de Thrane y Ole se resumieron las principales razones por las cuales se considera a esta estructura buena para ser paralelizada sobre una GPU. Estas razones son:
\begin{itemize}
  \item Cada voxel atravesado por el rayo puede ser localizado y accedido en tiempo constante usando aritmética simple. Esto elimina la necesidad de recorrer árboles (como en otras estructuras de aceleración) y por lo tanto, el manejo de mucha información a nivel de la GPU, lo cual resulta muy costoso.
  \item El desplazamiento a través de los voxeles atravesados se hace de forma incremental y con sumas sencillas, lo cual elimina la necesidad de una pila y hace posible visitar los voxeles en orden, es decir aumentando la distancia desde el origen del rayo.
  \item Se puede explotar el hecho de que los voxeles se recorren en orden para detener la recorrida cuando se de una intersección en el voxel actual.
  \item El algoritmo de recorrido a través de los voxeles que interseca el rayo esta dado por un vector lo cual es altamente compatible con el conjunto de instrucciones de una GPU.
\end{itemize}
En la subdivisión espacial se puede dar el caso de que un polígono sea referenciado por más de un voxel. Esto genera que en ocasiones especiales, se haga más de una vez el mismo test de intersección. Para resolver esto se han generado técnicas como la denominada Mailboxing, que mantiene una tabla donde se asocia cada rayo con el último polígono al cual se le realizó el test de intersección \cite{AmanatidesWoo}. Al emplear estrategias de la paralelización este tipo de técnicas no pueden utilizarse, lo que implica que el algoritmo paralelo debería hacer chequeos repetidos \cite{TesisEstructuras}.

\subsubsection{KD-Trees}

Al igual que la subdivisión espacial uniforme la estructura kd-tree es una instancia particular de la subdivisión espacial. La diferencia que tiene es que representa la escena con una estructura jerárquica basada en un árbol binario. En esta estructura se hace una distinción con respecto al tipo de los nodos, se distinguen los nodos internos de las hojas. Los nodos hoja se corresponden con los voxeles y tienen las referencias a los objetos que se encuentran dentro de los mismos. Los nodos internos se corresponden con la forma en que se divide el espacio. De esta manera, los nodos internos contienen un plano de corte y referencias a cada uno de los dos subárboles, mientras que los nodos hojas contienen listas de objetos.

Esta técnica de división del espacio tiene prácticamente las mismas ventajas que la subdivisión espacial uniforme. Pero esta división intenta mejorar a la uniforme considerando que los objetos no están uniformemente distribuidos en la escena.

La construcción de un kd-tree se hace de forma recursiva, siguiendo un enfoque top-down. Dada una caja que contenga completamente a la escena y una lista de objetos contenidos en ella, se escoge un plano de corte perpendicular a uno de los ejes de coordenadas, que divida la caja en dos. Al dividir se generan dos nuevos volúmenes, y cada uno de ellos es representado agregando un hijo al nodo asociado a la caja original. Cada uno de los objetos que contiene la caja original es asignado al nodo hijo que lo contiene. En caso de que un objeto tenga intersección no vacía con el plano de corte, entonces este objeto es asignado a ambos hijos. Este procedimiento continúa hasta que se alcanza una profundidad definida de antemano o hasta que el número de objetos contenidos en cada voxel sea menor a un número definido anteriormente. Havran \cite{Havran} sugiere que la profundidad máxima sea igual a $16$ y que la cantidad de objetos por voxel sea $2$ para lograr un rendimiento óptimo. Thrane y Ole \cite{TesisEstructuras} analizaron estos valores y concluyeron que $16$ como profundidad máxima no era un buen valor para las escenas realistas. Se concluyó que, como la escena es dividida en dos en cada nivel del árbol entonces, una profundidad más convincente sería una que fuera resultado de una función logarítmica en el número de triángulos de la escena. Esta consideración también fue adoptada por Pharr y Humphreys \cite{PharrHumphreys}, los cuales usaron $8 + 1\ldotp3\log(N)$ como profundidad máxima, donde $N$ es el número de triángulos de la escena.


\subsection{Jerarquía de Volúmenes Envolventes (BVH)}
La estructura BVH divide la escena y guarda la información de la división en una jerarquía definida por un árbol. Difiere de las técnicas de subdivisión espacial porque no divide el espacio sino que divide objetos. El volumen envolvente de una pieza de geometría es un objeto geométrico simple que la envuelve, es decir que la contiene en su interior. Claramente, si falla la intersección de un rayo con el volumen envolvente de un objeto, falla la intersección con cualquier cosa que este dentro del mismo y por lo tanto falla la intersección rayo-objeto.

La motivación para usar volúmenes envolventes es que realizar un chequeo de intersección con un objeto simple, como lo es un volumen envolvente, es mucho menos costoso que hacerlo contra el objeto que contiene dentro, que por lo general no es un objeto simple. La aceleración que pueda lograrse mediante esta técnica dependerá de la complejidad de los objetos de la escena y de los volúmenes envolventes que se usen.

Una jerarquía de volúmenes envolventes esta formada por un nodo raíz que contiene un volumen que envuelve a todos los demás volúmenes, y también contiene a todos los objetos de la escena. Cada nodo interno del árbol tiene como hijos a un conjunto de nodos internos, cada uno de ellos con un volumen envolvente asociado, o a un conjunto de nodos hoja, con un número cualquiera de objetos de la escena asociados. En la Figura \ref{fig:BVHExample} se muestra una estructura BVH como ejemplo, la cual utiliza cajas alineadas a los ejes como volúmenes envolventes. Es posible utilizar otros objetos envolventes, por ejemplo, cajas no alineadas a los ejes, cilindros, esferas, etc.

\begin{figure}[H]
  \centering
    \includegraphics[width=0.9\textwidth]{../DOC_Relevamiento/BVHExample}
  \caption{Ejemplo de estructura BVH que utiliza cajas alineadas a los ejes.}
  \label{fig:BVHExample}
\end{figure}

El algoritmo de recorrida de los volúmenes envolventes es realizado usando un simple e intuitivo descenso recursivo.

Una medida razonable de la calidad de una estructura BVH, es el costo promedio de aplicarle el algoritmo de recorrida, dado un rayo arbitrario. No hay ningún algoritmo conocido que construya estructuras BVH óptimas, tampoco es obvio como evaluar el costo promedio de atravesar con un rayo arbitrario una estructura de este tipo.
Goldsmith y Salmon proponen una función de costo conocida como la heurística del área de las superficies \cite{GoldsmithSalmon}. Está formalizada usando el área de la superficie del nodo padre y del nodo hijo y sigue la relación de la Ecuación \ref{eqn:AreasSuperficies}.
\begin{equation} %%% Ecuacion pagina 53!!!
    P(hit(c) | hit(p)) \approx \frac{S_{c}}{S_{p}}
    \label{eqn:AreasSuperficies}
\end{equation}

Donde: $hit(n)$ es el evento en que el rayo atraviesa el nodo $n$, $S_{n}$ es el área de la superficie del nodo $n$ y $c$ y $p$ son el nodo hijo y padre, respectivamente.

La función da un estimativo del costo de la jerarquía cuando se trata de atravesar por un rayo cualquiera.

Como no existe un algoritmo para construir eficientemente una estructura BVH óptima, se han propuesto heurísticas de construcción. Por lo general, estas heurísticas se basan en una de las dos ideas propuestas por Kay y Kajiya \cite{KayKajiya} y Goldsmith y Salmon \cite{GoldsmithSalmon}, en estos trabajos se puede profundizar sobre el tema.


\subsection{Conclusiones sobre aceleración espacial}

En el trabajo de Thrane y Ole se analizan experiencias obtenidas al implementar y usar la subdivisión espacial uniforme en la paralelización del algoritmo de trazado de rayos. Para escenas con objetos simples la a\-ce\-le\-ra\-ción lograda a través de esta estructura es mayor que la obtenida a través de Kd-Tree o BVH. Cuando las escenas poseen objetos complejos la a\-ce\-le\-ra\-ción no es tan buena en comparación con las mismas estructuras. Además se menciona que la estructura no es buena para escenas donde se dan grandes variaciones en la densidad de los objetos desde el punto de vista geométrico. También se destaca que el algoritmo para recorrer los voxeles es muy simple de implementar y que requiere pocas operaciones aritméticas para avanzar de voxel a voxel. Así mismo el procedimiento para la construcción de la SEU es más simple que el de las estructuras Kd-Tree o BVH. Estas propiedades del algoritmo de recorrida y de construcción son muy importantes para implementarlo en una GPU, y contrarrestan algunas propiedades negativas que se presentan en el trabajo, como por ejemplo que requiere guardar mayor cantidad de datos para representar el estado del recorrido, en comparación con las estructuras Kd-Tree y BVH. Los autores concluyen que el algoritmo de recorrida de los voxeles se puede paralelizar muy fácilmente en una GPU pero que la implementación tendría un bajo rendimiento para escenas complejas y un buen rendimiento para escenas simples, en comparación con el obtenido al usar las estructuras Kd-Tree o BVH.

Por otro lado, Thrane y Ole \cite{TesisEstructuras} implementaron la estructura de a\-ce\-le\-ra\-ción Kd-Tree sobre GPU. Usaron las técnicas (\emph{restart} y \emph{backtrack}) y concluyeron que para la mayoría de las escenas, esta estructura mejora en rendimiento a la subdivisión espacial uniforme. También se recalca que las dos técnicas para realizar la recorrida a través de los voxeles sufren de alta complejidad en sus algoritmos (en el contexto de una GPU) y esto no es deseable ya que aumenta el tiempo de ejecución. Aunque también se menciona que el tiempo de ejecución que se agrega por la complejidad puede verse compensado, en cierto grado, por la habilidad de la estructura para adaptarse a los cambios de densidad de objetos en la escena. Con respecto al algoritmo para la construcción de la estructura, se concluye que dada su condición de recursivo su implementación a nivel de GPU es más compleja, en comparación con la subdivisión uniforme.

En el trabajo de Lauterbach et al. \cite{Lauterbach06} luego de haber usado la estructura Kd-Tree para diversos casos de prueba se llegó a la conclusión de que con esta se obtienen mejores resultados de los que se obtienen utilizando la estructura BVH, para escenas estáticas (las escenas estáticas se caracterizan por componerse de objetos fijos, que no cambian de posición ni de forma en el tiempo). Esta ganancia en rendimiento tiene como costo asociado un mayor consumo de memoria y una mayor complejidad para implementar y optimizar la construcción de la estructura.

Con respecto a la estructura BVH, Thrane y Ole \cite{TesisEstructuras} implementaron sobre una GPU ambas estrategias de construcción, el enfoque \emph{top-down} y el \emph{bottom-up}, para comparar resultados. Usaron siempre volúmenes envolventes alineados a los ejes, en ambas construcciones. La estrategia de recorrida a lo largo de los nodos hijos fue siempre de izquierda a derecha. Esto en algunos casos no resultó muy eficiente ya que si el rayo atraviesa todos los volúmenes envolventes y el volumen donde se da la intersección más cercana es el último de una lista de hermanos, se debe revisar todos los demás volúmenes antes de llegar a un resultado. En un caso de este tipo prácticamente se está utilizando fuerza bruta para encontrar la intersección, cosa que se buscaba evitar con la introducción de estructuras de aceleración. Una alternativa es recorrer la lista de hermanos según la dirección del rayo pero los autores optaron por no mejorar este aspecto para mantener la simplicidad en el algoritmo (ya que debe ser implementado en una GPU).

La gran ventaja de la estructura BVH es la simplicidad del algoritmo de recorrida y la gran desventaja es el orden fijo en que se recorren los nodos hermanos \cite{TesisEstructuras}. Además Thrane y Ole \cite{TesisEstructuras} concluyeron que para escenas complejas esta estructura es la que tiene mejor rendimiento sobre la GPU, comparando con la subdivisión espacial uniforme y con la Kd-tree. Como un agregado se destaca que la implementación de la construcción es simple, aunque para llevarla a nivel de GPU hay que resolver el problema de la recursión si se elige el enfoque \emph{top-down} o el problema de encontrar un buen orden para la lista de objetos de la escena si se elige el enfoque \emph{bottom-up}. Además, la construcción en cualquiera de los enfoques es computacionalmente más costosa que la construcción de la grilla uniforme.

Lauterbach et al. \cite{Lauterbach06} luego de haber usado la estructura BVH para diversos casos de prueba concluyó que con esta estructura se obtienen mejores resultados de los que se obtienen utilizando la Kd-tree, para escenas dinámicas (las escenas dinámicas se caracterizan por componerse de objetos que a medida que el tiempo avanza cambian de posición, forma, etc.). Además, los autores señalan que a la jerarquía de volúmenes envolventes es más fácil agregarle la optimización basada en paquetes de rayos que a la Kd-Tree.

En la Tabla \ref{table:ConclusionesEstructuras} se resumen las principales conclusiones sobre las estructuras de aceleración espacial.

\begin{table}[!hbt]
\begin{center}
    \small {
    \begin{tabular}{|p{7.5cm}|c|c|c|}
    \hline
    &SEU & Kd-Tree & BVH\\
    \hline
    Complejidad del algoritmo de construcción & Baja & Alta & Media\\
    \hline
    Aceleración lograda para escenas simples & Alta & Baja & Media\\
    \hline
    Aceleración lograda para escenas complejas & Baja & Media & Alta\\
    \hline
    Adaptación frente a escenas no uniformes & Baja & Media & Alta\\
    \hline
    Consumo de memoria & Medio & Alto & Bajo\\
    \hline
    Complejidad del algoritmo de atravesado & Media & Alta & Baja\\
    \hline
    Adaptación frente a escenas estáticas & Mala & Buena & Mala\\
    \hline
    Adaptación frente a escenas dinámicas & Mala & Mala & Buena\\
    \hline
    \end{tabular}
}
\caption{Comparación de las estructuras de aceleración.}
\label{table:ConclusionesEstructuras}
\end{center}
\end{table}

\section{Raytracing interactivo}

Se llama Raytracing Interactivo (RI) a una implementación del algoritmo que permita modificar parámetros que afecten a la imagen generada y que el ojo humano pueda percibir las consecuencias de las modificaciones como una animación, para lograr esto se necesitan por lo menos 24 FPS (\emph{frames} por segundo). A diferencia del Raytracing en tiempo real este tipo de implementaciones no serviría para hacer videojuegos o generadores de video en tiempo real, dado que la cantidad de imágenes por segundo no sería suficiente.


\subsection{Estado del Arte}

El artículo de Wald et al. \cite{Wald:2001:STAR-IRT} plantea cual es el estado del arte en la generación de imágenes para programas en los que uno de los objetivos es la capacidad de interactuar con los usuarios. Según lo relevado en este artículo, el algoritmo que generalmente es utilizado para la generación de imágenes es el de Rasterización, pero debido al constante aumento del poder de cómputo del \emph{hardware} el algoritmo de Raytracing surge como una alternativa válida.

Para lograr que el algoritmo de Raytracing sea interactivo se le deben aplicar estrategias de simplificación y aceleración. Existe una estrategia que consiste en utilizar un algoritmo basado en rasterización, asumiendo que la velocidad de la rasterización es mejor que la de Raytracing se pude utilizar Raytracing solamente para el cálculo de algunos efectos de iluminación y no realizar toda la generación de la imagen con este algoritmo. Otra estrategia saca provecho de la coherencia temporal entre las imágenes generadas, esta técnica se basa en extraer información de la imagen generada en el paso anterior para generar solo algunos pixeles de la imagen siguiente. Utilizando como base Raytracing otra de las formas de mejorar el tiempo de procesamiento es tratando de reducir el costo de cálculo de cada uno de los pixels. Otra forma de aceleración es la utilización de algoritmos que permitan bajar los costos computacionales asociados al trazado de rayos, estos pueden ser utilización de algún tipo de particionamiento espacial, utilización de arquitecturas de memoria de las CPU actuales que puedan ser utilizadas de manera eficiente. Por último la utilización de la capacidad del algoritmo de ser ejecutado en paralelo, esto requiere una buena optimización de los algoritmos teniendo en cuenta el balanceo de carga y las latencias de sincronización.

\subsection{RI sobre multiprocesadores de memoria compartida}

El artículo de Wald et al. describe la exploración dentro de las técnicas de optimización para los algoritmos de Raytracing de modo de intentar que se puedan ejecutar de manera interactiva. En esta investigación realizan la implementación de un Raytracer que corre sobre una arquitectura multiprocesador. En la solución desarrollada se logró la interactividad, en parte porque el sistema corre en una máquina de gran poder de cómputo (SGI Origin 2000). Por otra parte es posible aún en estas condiciones lograr que Raytracing sea interactivo por tres características del algoritmo:
\begin{itemize}
  \item Raytracing escala bien en cientos de procesadores.
  \item Para escenas estáticas el tiempo de render de los frames (generación de cada cuadro de una animación) el orden del algoritmo es sublineal en la cantidad de objetos básicos en la escena.
  \item Permite agregar una gran variedad de objetos básicos y efectos de sombreado programados por el usuario.
\end{itemize}

Estos ítems permiten: que la implementación sea interactiva, poder ge\-ne\-rar imágenes para escenas de gran porte y obtener imágenes con las características de realismo clásicas del Raytracing.

Para el trabajo se utilizó como base el algoritmo clásico de Whitted \cite{PaperDel80} modificándolo para obtener mejoras visuales y de performance. Las mejoras que afectan directamente a la velocidad del algoritmo se pueden dividir en dos grandes ramas: 1) Acelerar o eliminar cálculos de verificación de intersección entre rayos y objetos. 2) Paralelización. Utilizan ambas técnicas buscando la combinación de ambas que les brinde un mejor desempeño. Para optimizar en la cantidad de cálculos de intersección se utiliza división espacial de la escena, utilizando no solamente una estructura sino que se combinan una división en grilla de la escena con volúmenes acotantes para los objetos de dicha escena.

Para paralelizar el algoritmo se utiliza un sistema de memoria compartida, y el algoritmo utiliza una estrategia maestro-esclavo en donde el proceso maestro inicializa la escena a renderizar y se generan los rayos a ser lanzados en una cola de rayos de la cual los procesos esclavos obtendrán a demanda los rayos para procesar. Esta estrategia tiene un gran problema en el tiempo necesario para la sincronización entre procesos, por esto los rayos se agrupan de a varios para obtener una mejor performance. Las limitaciones que se pudieron constatar para el algoritmo de Raytracing son el balanceo de carga y la sincronización entre los procesos.

En la versión final del algoritmo se logró la interactividad con una cantidad relativamente pequeña de procesadores (8) y se logró el objetivo de tiempo real con 64 procesadores. Esta implementación de raytracing mostró que es un algoritmo muy bueno para mostrar efectos de luz dinámicos pero no así para procesar escenas en las cuales los objetos cambian dinámicamente.

\section{Conclusiones del relevamiento}



