\chapter{Propuesta} % 20 páginas mas o menos...

\section{Introducción}

Uno de los objetivos de este proyecto es paralelizar el algoritmo de Whitted para lograr renderizar imágenes en un tiempo menor al que insume el algoritmo tradicional, sin perder calidad en la imagen generada.

Para obtener el color de un pixel usando el algoritmo de Raytracing se debe lanzar un rayo primario (como mínimo), si se quiere renderizar una imagen cuya resolución sea 1024 por 768 pixeles se deben trazar 786432 rayos primarios. En una implementación tradicional del algoritmo de Whitted se procesa un pixel a la vez, es decir se trazan los rayos primarios en forma secuencial. Basado en la información anterior se decidió paralelizar el algoritmo en el trazado de rayos primarios. De esta manera se ataca el cuello de botella que produce el trazado de rayos en el algoritmo tradicional.

Para mantener un punto de comparación del desempeño computacional que se alcanza en el mismo algoritmo cambiando CPU por GPU lo que se hizo fue generar el mismo algoritmo, o muy parecido en lo que a optimizaciones se refiere, en CPU y en GPU. Los algoritmos se implementaron usando el lenguaje C y CUDA respectivamente. Estos algoritmos comparten el programa principal y los datos de la escena. Para que se genere un ejecutable para CPU o para GPU lo que se hace es compilar con directivas al preprocesador de que se genere el ejecutable en una u otra variante según lo que se quiera. En las secciones posteriores se detallan aspectos comunes de ambos algoritmos para luego dar detalles particulares de cada uno por separado.

\section{Descripción general}

Los algoritmos implementados tienen varios aspectos en común, tanto que en algunos casos utilizan el mismo modulo de software. Un ejemplo de esto es el cargado de la escena desde archivo, el cual se ejecuta a nivel de CPU para las soluciones implementadas. La construcción de la estructura de aceleración espacial también se hace utilizando el mismo modulo en ambos algoritmos.

Otros aspectos en común son la recorrida de la estructura de aceleración espacial y el algoritmo de intersección rayo-primitiva. Si bien estos aspectos son comunes se implementaron en dos versiones distintas, una versión en C que usa el algoritmo para CPU y una versión para GPU que utiliza el Raytracing implementado en CUDA.

La estructura de datos que usan ambas implementaciones son similares, comenzaron siendo idénticas al inicio del proyecto pero por razones de optimización la utilizada por el algoritmo para GPU fue modificada en términos de estructura y no en términos de los datos almacenados.

Al mismo tiempo ambas implementaciones son muy distintas en otros aspectos, por ejemplo el núcleo del algoritmo de Raytracing esta implementado en el lenguaje C para el algoritmo para CPU, mientras que el que ejecuta en GPU esta implementado usando el modelo de programación que provee CUDA.

\subsection{Aspectos comunes a ambas implementaciones}\label{sec:AspComunesAmbasImpl}

\subsubsection{Cargador de escena}

El algoritmo de Raytracing de Whitted requiere como entrada una escena, la cual será renderizada. Para cargar la escena a renderizar debe existir una etapa de preprocesamiento. En este trabajo la escena es cargada desde un archivo de texto usando exclusivamente la CPU. El formato de este archivo esta basado en el Wavefront OBJ version 3.0 \cite{OBJFileFormat}. Además de los datos que permite especificar un archivo OBJ, el formato utilizado permite precisar otros objetos que no son parte del estándar de Wavefront pero que son muy útiles para el algoritmo de Raytracing.

El formato Wavefront OBJ es un formato basado en una tira de caracteres ASCII, el cual es muy usado para guardar, intercambiar y representar modelos en tres dimensiones.
El hecho que sea texto plano lo hace muy fácil de comprender y de extender. Por lo general una escena en formato OBJ esta compuesta por dos archivos, un archivo con extensión obj y otro con extensión mtl. En el archivo obj se definen todos los elementos que componen la escena mientras que en el otro se definen los materiales de los elementos.
En este formato se pueden especificar datos a nivel de vertices, como por ejemplo posición, mapeo de textura, normales, etc. También es posible definir elementos, como por ejemplo, puntos, líneas, polígonos, curvas, curvas en dos dimensiones y superficies. En el archivo de materiales (extensión mtl) es posible definir tantos materiales como se desee y asignar los mismos a los distintos elementos de la escena \cite{OBJSpecification}.

En el marco de este proyecto se usa un cargador que ya se encontraba implementado y que extiende al formato base con el agregado de nuevas características \cite{FuenteCargadorOBJ}. Las extensiones son muy útiles para el algoritmo de Raytracing y fueron implementadas por la misma persona que desarrollo el cargador. Las características que extienden el formato OBJ son:
\begin{itemize}
    \item Primitivas: se agregaron nuevas primitivas como plano y esfera.
    \item Elementos: se agregaron nuevos elementos como luces puntuales, luces cuadradas, luces en forma de disco y la posibilidad de definir una cámara.
    \item Materiales: se agregaron nuevas propiedades a los materiales, como por ejemplo el coeficiente de reflexión y el de transmisión.
\end{itemize}

En la propuesta implementada en el proyecto el uso que se le da a este cargador es externo. Después de cargar la escena, esta se almacena en una estructura propia, definida especialmente para el contexto de este proyecto. La metodología explicada permite desacoplar el resto del algoritmo de la etapa de carga, lo cual permite cambiar la herramienta de cargar la escena fácilmente.

\subsubsection{Métodos de aceleración}

En este proyecto se decidió acelerar el algoritmo de Raytracing por medio de disminuir el tiempo de ejecución que toman las intersecciones rayo-objeto, pues estas consumen más del 90\% del tiempo de generación de imagen \cite{TesisEstructuras}. Para esto se tomaron medidas en los caminos posibles para lograr acelerar el algoritmo: implementar un algoritmo de intersección rayo-primitiva eficiente y reducir la cantidad de intersecciones rayo-primitiva que prueban por cada rayo primario.

Es importante escoger un buen método para la verificación de intersección entre los rayos y las primitivas de construcción de escenas, dado que este es parte central del Raytracing. El algoritmo de trazado de rayos implementado solo posee un tipo de primitiva, el triángulo, por lo tanto solo se debió escoger un método para la intersección rayo-triángulo. Se escogió solo el triángulo como primitiva de construcción de escenas porque es una primitiva sencilla y por lo tanto el algoritmo de su intersección con un rayo también lo es. Como el algoritmo de intersección es sencillo, se puede ejecutar utilizando poca cantidad de operaciones aritméticas, lo cual lo hace eficiente. Además de ser una primitiva sencilla es una primitiva ampliamente soportada por la mayoría de herramientas de modelado tridimensional, como pueden ser \emph{3D Studio Max}, \emph{Maya}, \emph{Blender}, etc. También es una primitiva que permite construir a partir de ella cualquier objeto tridimensional que se quiera modelar.

El método utilizado para verificar la intersección entre un rayo y un triángulo es el de coordenadas baricéntricas. Dicho método verifica que el rayo interseque con el plano que contiene al triángulo y luego mediante un cambio de coordenadas verifica que la intersección se de dentro de los límites del mismo \cite{RealTimeRendering02}. Este método no es el más eficiente que existe pero su consumo de memoria es mínimo, lo cual es importante si se quiere implementar en una GPU.

A pesar de contar con un algoritmo de intersección eficiente es importante implementar una estrategia para no probar la intersección con todos los objetos de la escena, para cada rayo primario. En la etapa de relevamiento y evaluación de las distintas estrategias se consideraron tres estructuras de aceleración espacial: la subdivisión espacial uniforme, la subdivisión espacial adaptativa (utilizando Kd-trees) y la jerarquía de volúmenes envolventes (BVH).

La estrategia de aceleración espacial que se adopto en este proyecto fue la subdivisión espacial uniforme. El argumento de mayor peso para la elección de esta estructura fue la simplicidad de construcción y recorrida de la misma, lo cual resulta imprescindible para paralelizar los algoritmos usando una GPU.

\subsubsection{Construcción de la grilla}

Para la construcción de la grilla se adoptaron dos métodos. Esto se hizo así por dos razones, comparar cual resulta más eficiente y validar el resultado del algoritmo más complejo (pero más eficiente) con el resultado del menos eficiente (pero más sencillo de implementar). El algoritmo de construcción se ejecuta exclusivamente en la CPU, aunque se podría acelerar ejecutándolo en la GPU.

El primer algoritmo implementado para generar la subdivisión espacial uniforme fue la construcción por fuerza bruta. Como se muestra en el Algoritmo \ref{alg:SeudoConsGrillaBruto} este método de construcción recorre todos los voxels de la grilla y para cada uno de ellos recorre todos los objetos de la escena para probar si hay intersección voxel-objeto. Este método es ineficiente porque por lo general se recorren muchos voxels innecesarios (que no tienen intersección con el objeto) por cada objeto de la escena.

\begin{algorithm}
    \caption{Seudocódigo del algoritmo menos eficiente de construcción de la grilla uniforme.}
    \label{alg:SeudoConsGrillaBruto}
    \begin{algorithmic}
        \ForAll {voxel en grilla}
            \ForAll {obj en listaObjetos}
                \State //En coordenadas de grilla
                \State bbObj = calcularBoundingBoxObjeto(obj);
                \If{(voxel $\cap$ bbObj) $\neq$ $\emptyset$}
                    \State agregarObjetoEnVoxel(voxel, obj);
                \EndIf
            \EndFor
        \EndFor
    \end{algorithmic}
\end{algorithm}

En el Algoritmo \ref{alg:SeudoConsGrillaOptimizado} se describe un algoritmo de construcción optimizado, en este método de construcción se recorren todos los objetos de la escena, donde para cada uno ellos se calcula (en coordenadas de grilla) una caja alineada a los ejes que lo envuelve. A partir de la caja se obtienen voxels candidatos a solaparse con el objeto. Para cada voxel candidato se prueba el solapamiento caja-objeto y si da positiva se agrega el objeto al voxel que dio origen a la caja. La optimización introducida con respecto al método mostrado en el Algoritmo \ref{alg:SeudoConsGrillaBruto} permite desechar una cantidad importante de voxels que no tienen intersección con el objeto. Si no consideramos el peor caso de este método (cuando todos los objetos de la escena se solapan con todos los voxels de la grilla), que es muy poco probable, este método siempre supera al anterior en cantidad de pruebas de intersección voxel-objeto.

\begin{algorithm}
    \caption{Seudocódigo del algoritmo eficiente de construcción de la grilla uniforme.}
    \label{alg:SeudoConsGrillaOptimizado}
    \begin{algorithmic}
        \ForAll {obj en listaObjetos}
            \State //En coordenadas de grilla
            \State bbObj = calcularBoundingBoxObjeto(obj);
            \ForAll {voxel $\subset$ bbObj}
                \State //En coordenadas de mundo
                \State voxelMundo = transformarCoorMundo(voxel);
                \If{boundingBoxOverlapObject(voxelMundo, obj)}
                    \State agregarObjetoEnVoxel(voxel, obj);
                \EndIf
            \EndFor
        \EndFor
    \end{algorithmic}
\end{algorithm}

\subsubsection{Recorrido de la grilla}

El algoritmo para la recorrida de la grilla está basado en el renderizado de una línea en pantalla que se implementa en las tarjetas gráficas, el algoritmo se basa en incrementos y en cada paso para el cálculo del siguiente paso no se realizan más que unas pocas sumas y evaluaciones de condiciones.
La implementación se realiza en 2 pasos, primero se computa el cálculo del voxel inicial y de los incrementos en cada una de las 3 direcciones para un rayo específico y por otra parte la manera en que se computa cada cambio de voxel.

El voxel inicial se calcula de manera sencilla intersecando el rayo con el cubo que acota toda la escena que se utiliza para generar la grilla, con el punto de intersección se calcula cual es el voxel al que pertenece el punto. Para obtener el incremento se calcula la derivada en cada una de las 3 componentes, con esa derivada y el tamaño de los voxels en x, y, z se obtiene la distancia que debe recorrer el rayo para poder alcanzar el siguiente voxel, esta se calcula para cada una de las 3 componentes y se almacena en una variable, así como también se hace con las derivadas.

Como se muestra en el Algoritmo \ref{alg:SeudoSiguinteVoxelGrilla}, la forma en que se calcula el siguiente voxel es en base a la distancia que tiene que recorrer el rayo desde su origen hasta el siguiente punto de intersección. Se tienen tres distancias que debe recorrer el rayo para pasar al siguiente voxel en el eje X, para pasar al siguiente voxel en el eje Y y para pasar al siguiente voxel en el eje Z. La mínima de estas distancias determina cual de los tres incrementos es el que hay que realizar, el voxel que esté más cerca es el siguiente, por lo tanto hay que incrementar 1 en la dirección determinada por dicho mínimo. El Algoritmo  se muestra un seudocódigo para el cálculo del siguiente voxel.

\begin{algorithm}[H]
    \caption{Seudocódigo del algoritmo para avanzar en los voxels.}
    \label{alg:SeudoSiguinteVoxelGrilla}
    \begin{algorithmic}
        \State DM = Minimo(DX, DY, DZ);
        \If{(DM == DX)}
            \State DX = DX + incrementoX;
            \State VoxelActualX = VoxelActualX + signo(incrementoX) * 1;
        \EndIf
        \If{(DM == DY)}
            \State DY = DY + incrementoY;
            \State VoxelActualY = VoxelActualY + signo(incrementoY) * 1;
        \EndIf
        \If{(DM == DZ)}
            \State DZ = DZ + incrementoZ;
            \State VoxelActualZ = VoxelActualZ + signo(incrementoZ) * 1;
        \EndIf
    \end{algorithmic}
\end{algorithm}

\subsubsection{Estructura de datos}

En el Apéndice \ref{sec:ApendiceEstructurasDatos} se detallan las estructuras de datos utilizadas en los algoritmos de Raytracing (C y CUDA) implementados. En las primeras etapas del proyecto se uso la misma estructura para ambos algoritmos, dado que en ese momento la performance de los mismos no era un objetivo de primera linea. A medida que avanzó el proyecto y la prioridad fue mejorar la eficiencia se creo una estructura por cada algoritmo. La estructura para el algoritmo en CPU se mantuvo igual, mientras que para el algoritmo en GPU se hicieron cambios que afectaron negativamente la legibilidad de código del mismo pero que mejoraron el tiempo de ejecución.

Los cambios en la estructura de almacenamiento de la escena para el algoritmo en CUDA estuvieron determinados por la forma de utilizar la jerarquía de memoria de la GPU. La estructura tuvo que ser modificada de manera de minimizar las operaciones de memoria al momento de cargar los datos de la escena en la GPU. Lo que más afecta la eficiencia es reordenar los datos antes de cargarlos en memoria de textura de la GPU. Es importante que el copiado de memoria de la CPU hacia la GPU sea lo más eficiente posible ya que de esta manera el algoritmo puede tornarse interactivo sin mayores costos computacionales.

Entre los campos más importantes de la estructura utilizada para almacenar la escena se encuentra la lista de objetos de la misma, que se guardan en un arreglo con tope \emph{objetos} (el tope es \emph{cant\_objetos}).

Otro campo importante donde se guarda la información referente a la división espacial de la escena, el campo \emph{grilla}, que es de tipo \emph{UniformGrid}. Este tipo tiene varios campos:
\begin{itemize}
    \item \emph{dimension}: almacena la dimensión de la grilla que divide el espacio de la escena.
    \item \emph{bbEscema}: almacena una caja alineada a los ejes de coordenadas que contiene a toda la escena.
    \item \emph{voxels}: array de punteros a entradas de \emph{listasGrid}. Cada entrada de \emph{voxels} se corresponde con un voxel de la escena y en cada una de sus entradas se almacena un puntero a la lista de objetos que contiene el voxel.
    \item \emph{listasGrid}: array de listas de punteros a objetos.
\end{itemize}

Se puede ver un ejemplo esquemático de la estructura \emph{UniformGrid} en la Figura \ref{fig:exampleEstructuraUGrid}. En este ejemplo se considera una escena con seis objetos, los cuales están completamente contenidos es una caja alineada a los ejes definida por los puntos $min = (-10, -10, -10)$ y $max = (10, 10, 10)$. Al aplicarle una subdivisión espacial uniforme con dimensiones $2\times2\times3$ a la escena se generan $12$ voxels, tal como se muestra en el vector ``voxels''. Cada objeto de la escena se encuentra contenido en una o más divisiones, por lo tanto por cada división se tiene una lista de objetos contenidos. El vector ``listasGrid'' contiene las listas de todos los voxels de la subdivisión y mediante las entradas del vector ``voxels'' se accede a cada una de ellas. El caso especial en que la lista de objetos de un voxel es vacía se marca con un valor especial en el vector ``voxels''.

\begin{figure}[H]
  \centering
    \includegraphics[width=0.9\textwidth]{./../DOC_Implementacion/estructuraGrilla}
  \caption{Ejemplo de estructura \emph{UniformGrid}.}
  \label{fig:exampleEstructuraUGrid}
\end{figure}

\subsubsection{Archivo de configuración}

Ambos algoritmos implementados utilizan un archivo de configuración, el cual debe estar presente para el correcto funcionamiento de los mismos. Se tomó la decisión de utilizar un archivo de configuración ya que para las pruebas de rendimiento es interesante cambiar los valores de los parámetros más importantes de cada algoritmo y no tener que re-compilar el código fuente con cada cambio. En el Algoritmo \ref{fig:EjemploArchivoConfig} se muestra una posible configuración de los algoritmos. Es importante destacar que el archivo de configuración incluye los parámetros de ambas implementaciones ya que, por ejemplo la parte de configuración que tiene relación con la GPU no es usada por el algoritmo para CPU.

\begin{figure}[H]
    \begin{center}
    \begin{boxedverbatim}
#= tamaño de la partición espacial
TAMANIO_GRILLA.X=64
TAMANIO_GRILLA.Y=50
TAMANIO_GRILLA.Z=50
#= resolución de la imagen
RESOLUCION.X=640
RESOLUCION.Y=480
INFINITO= 34028234660000000
#= valor tomado como cero
ZERO=0.000001
#= valor máximo rebotes rayo
PROFUNDIDAD_RECURSION=3
#= hilos por bloque
THREADS.X=8
THREADS.Y=16
ESCENA=../escenas/afrodita.obj
    \end{boxedverbatim}
\end{center}
\caption{Ejemplo de contenido para el archivo de configuración.}
\label{fig:EjemploArchivoConfig}
\end{figure}


En el archivo se debe configurar el tamaño de la subdivisión espacial uniforme, se debe indicar el tamaño de la partición en cada eje de coordenadas. Es posible definir también la resolución de la imagen (en pixeles) que genera el algoritmo de raytracing. En este archivo también se definen valores para el cero y para el infinito que usa el algoritmo de raytracing, el ajuste del primer valor permite solucionar problemas de errores numéricos mientras que el segundo se usa en algoritmos que necesitan definir una distancia ``infinita''. Otro parámetro necesario para el algoritmo de raytracing y que es interesante variar para cada escena, es la profundidad máxima considerada por el algoritmo para cada árbol de rayos que genera cada rayo primario (debido a los sucesivos rebotes por los fenómenos de reflexión y refracción). Por último, se debe especificar la dimensión de los bloques de hilos de ejecución, este parámetro es usado solo por el algoritmo para GPU y en las siguientes secciones quedará perfectamente establecido cual es su cometido.


\subsection{Implementación para C (CPU)}

El principal objetivo de desarrollar un algoritmo de Raytracing que ejecute por completo a nivel de CPU es tener un punto de comparación del rendimiento computacional del algoritmo implementado para GPU. Al implementar la versión en CPU se está cubriendo una parte de los puntos de comparación, otro punto posible es comparar con algoritmos similares implementados por terceros.

Dado que se toma como base de comparación el tiempo de ejecución de este algoritmo, el mismo debe ser lo más eficiente posible de manera de obtener datos de comparación que sean justos. En la implementación para CPU del algoritmo de raytracing se sigue completamente la versión de Whitted, es decir se implementó el algoritmo usando recursión. Teniendo en cuenta que debe que ser lo más eficiente posible, si bien se optó por usar recursión todas las llamadas a procedimientos o subrutinas se hacen usando punteros a memoria de manera de no generar tiempo de copia innecesario.

\subsubsection{Arquitectura}

\begin{figure}[H]
    \centering
        \includegraphics[width=0.8\textwidth]{./Capitulo4/ARQ_RT_C}
    \caption{Arquitectura raytracing implementado en CPU.}
    \label{fig:ArqRayTracingCPU}
\end{figure}

En la Figura \ref{fig:ArqRayTracingCPU} se muestra un diagrama de arquitectura de la solución implementada. El componente ``Cargador OBJ'' es el encargado de leer el archivo en formato ``OBJ'', el cual especifica la escena y los materiales utilizados en la misma. Este componente no fue implementado en el proyecto sino que fue implementado por un tercero \cite{FuenteCargadorOBJ}.

El componente ``Cargador Escena'' fue implementado en el marco de este proyecto y utiliza el ``Cargador OBJ'' para leer la escena desde archivo. Este componente generado en el proyecto, tiene su propia estructura de datos para el almacenamiento de la escena. Debido a esto se encarga de inicializar su estructura a partir de los datos leídos por el cargador externo al proyecto. Además se encarga de la construcción de la subdivisión espacial uniforme.

La división espacial se genera utilizando el componente ``Grilla Uniforme'', esta parte del sistema construye la grilla a partir de la lista de objetos que contiene el encargado de inicializar la estructura de datos de la escena.

El componente ``Raytracing'' es el encargado de renderizar la imagen a través del algoritmo recursivo de Whitted. Dentro de este se implementaron los algoritmos que hacen al núcleo del raytracing, como por ejemplo el algoritmo de recorrida de un rayo dentro de la subdivisión espacial uniforme, el algoritmo de intersección rayo-triángulo, etc. Además el componente ``Raytracing'' es el encargado de presentar la imagen generada en pantalla utilizando la librería externa SDL (Simple Directmedia Layer) \cite{SDLLibrarySite}.


\subsection{Implementación para CUDA (GPU)}

\subsubsection{Paralelización del algoritmo}

El algoritmo de Raytracing tradicional propuesto por Whitted, traza los rayos primarios en forma secuencial. En otras palabras, traza un rayo primario, procesa todo el árbol de rayos generado por los distintos rebotes del rayo en los objetos de la escena y luego, una vez terminado el procesamiento del rayo primario anterior, traza el siguiente. Por consiguiente, el color de los pixeles de la imagen también se determina en forma secuencial.

Para acelerar el algoritmo de Raytracing tradicional se usa la idea de trazar los rayos primarios en paralelo. De esta manera todos los árboles de rayos generados por cada uno de los rayos primarios se procesan en paralelo. Por lo tanto, el color de un pixel se calcula al mismo tiempo que el de los demás pixeles de la imagen.

Para resolver el problema en términos del modelo de programación usado por CUDA se hizo una descomposición en sub-problemas, dividiendo la imagen a renderizar. La imagen se divide usando una grilla uniforme de dos dimensiones, donde cada celda de la grilla tiene la misma cantidad de pixeles. En la Figura \ref{fig:subfigDivisionImagen:a} se muestra una posible división de la imagen. En este ejemplo la imagen se divide en $n \times m$ celdas, quedando así cada celda con $\frac{R_{x}}{n}\times\frac{R_{y}}{m}$ pixeles. En la Figura \ref{fig:subfigDivisionImagen:b} se muestra en detalle la celda definida por los intervalos $[X_{i},X_{i+1}]$ y $[Y_{j},Y_{j+1}]$, la cual contiene una pequeña parte de los pixeles de la imagen.

\begin{figure}[H]
    \centering
    \subfigure[]{
        \label{fig:subfigDivisionImagen:a} %% label for first subfigure
        \includegraphics[width=0.45\textwidth]{./Capitulo4/divisionImagen}}
    \subfigure[]{
        \label{fig:subfigDivisionImagen:b} %% label for second subfigure
        \includegraphics[width=0.45\textwidth]{./Capitulo4/divisionBloque}}
    \caption{Subdivision de la imagen para lograr paralelismo.}
    \label{fig:subfigDivisionImagen} %% label for entire figure
\end{figure}

Cada celda de la grilla se corresponde directamente con un bloque de hilos de ejecución de CUDA, es decir cada división de la imagen es procesada por un bloque de CUDA diferente. Además como cada pixel de la imagen es procesado por un hilo de ejecución diferente, la cantidad de hilos por bloque es igual a la cantidad de pixeles que contiene cada división en su interior. Es por esta razón que la partición queda totalmente establecida cuando se fija la cantidad de hilos de ejecución por bloque (en el archivo de configuración), además de la resolución de la imagen a renderizar. Si se tiene una resolución de imagen de $640\times480$ pixeles y el tamaño de los bloques es de $16\times8$ hilos la imagen es dividida en una grilla de $40\times60$ celdas.

Mediante esta forma de descomponer el problema el raytracing para CUDA puede escalar fácilmente en el número de procesadores de la GPU sin necesidad de re-compilar su código fuente. Además mediante el archivo de configuración es posible cambiar la partición de la imagen a renderizar de manera de optimizarla para cualquier GPU.

La cantidad máxima de hilos de ejecución por bloque es $512$, por consiguiente $512$ es la cantidad máxima de pixels que pueden ser procesados por un mismo bloque, esto es un limite impuesto por CUDA. También hay que tener en cuenta que la cantidad de hilos por bloque puede verse limitada por la cantidad de registros que consuma cada hilo, ya que por ejemplo la cantidad máxima de registros por bloque es $8192$.


\subsubsection{Eliminación de la recursión}

El algoritmo de Raytracing es un algoritmo inherentemente recursivo, esto es una limitación a la hora de hacer que se ejecute en la GPU dado que la ejecución debe ser secuencial, ya que CUDA no tiene soporte para recursión. Este problema puede analizarse como una recorrida en un árbol binario (el árbol de rayos originado por un rayo primario y sus sucesivos rebotes debido a los fenómenos de reflexión y refracción) sin contar con el apoyo de la recursión.

Para resolver este problema se evaluaron dos opciones, la primera consiste en implementar una pila la cual sirva de apoyo para la recorrida del árbol binario. La segunda consiste en simplificar el árbol de manera que degenere en una lista y de esta forma no se necesita del apoyo de una pila. La forma de simplificar el árbol es exigiendo una pre-condición sobre la escena de entrada, la misma exige que en la escena no existan objetos que reflejen y transmitan la luz al mismo tiempo.

La opción elegida fue la segunda ya que simplifica el algoritmo a implementar en la GPU a cambio de un costo muy pequeño a nivel de las escenas de entrada. Otra razón importante para optar por simplificar el árbol, es que en caso de implementarla cada hilo de ejecución debe contar con una y la cantidad de memoria local de cada hilo de ejecución de CUDA es muy limitada.

Para implementar el algoritmo simplificado e iterativo hubo que hacer modificaciones al algoritmo original, generando que cada rayo sea el encargado de hacer su trayectoria de manera iterativa. Para esto hay que hacer que en cada iteración, en caso de que haya algún tipo de reflejo o refracción, el rayo tenga que ser modificado para que en la siguiente iteración se trace, de manera de simular la interacción con materiales con reflexión o refracción.

\subsubsection{Estructura del algoritmo}

El algoritmo es un algoritmo simple, se divide en varios pasos. El primer paso es cargar la escena, esta etapa fue analizada anteriormente en la Sección \ref{sec:AspComunesAmbasImpl}.
Luego de cargar la escena completamente formada por triángulos, se procede a la generación de la grilla que permitirá acelerar el proceso de intersección con los objetos previamente cargados. En la Sección \ref{sec:AspComunesAmbasImpl} se muestra en detalle la construcción de la grilla. Como se muestra en la Figura \ref{fig:DiagramaRTGPU} las dos primeras etapas ejecutan a nivel de la CPU. El último paso antes de ejecutar el primer \emph{kernel} es copiar los datos de la escena a memoria accesible por la GPU.

\begin{figure}[H]
    \centering
        \includegraphics[width=0.8\textwidth]{./Capitulo4/diagramaRT_GPU}
    \caption{Estructura del algoritmo de raytracing implementado en CUDA.}
    \label{fig:DiagramaRTGPU}
\end{figure}

Para lograr que el algoritmo tenga un buen rendimiento es necesario utilizar adecuadamente la jerarquía de memoria de la GPU. Los datos más utilizados por el algoritmo, como por ejemplo la lista de objetos de la escena o los voxeles de la subdivisión espacial, deben estar almacenados en un tipo de memoria que tenga tiempo de lectura bajo y puede ser de solo lectura, ya que esta información es frecuentemente accedida y nunca debe ser actualizada. Es por ello que la lista de triángulos y sus normales, las luces, los voxeles de la grilla de subdivisión espacial y la lista de materiales se copian a la memoria de textura de la GPU. Otra información como los datos de la cámara, la cantidad de luces, la dimensión de la grilla se copian a la memoria constante de la GPU, que también es de solo lectura. La lectura en los dos tipos de memoria mencionados es mucho más rápida que una lectura en memoria global.

El uso de la jerarquía de memoria que provee CUDA afecta directamente a la estructura de datos que almacena la escena. Por ejemplo, la lista de triángulos de la escena ocupa una cantidad grande de memoria y al cargarla desde archivo insume un tiempo de ejecución considerable. Toma prácticamente el mismo tiempo transformar toda la lista de triángulos desde el formato en que esta almacenada hacia el formato que requiere CUDA para cargarla en memoria de textura. Es por esto que se decidió almacenarla directamente en el formato que debe tener para copiarla a memoria de la GPU.

A la memoria de textura solo se pueden copiar vectores de dos o cuatro elementos, debido a esto cada vértice de triángulo se almacena como un vector de cuatro componentes, desperdiciando una componente (4 bytes) por cada vértice. En algunos casos se aprovecha la memoria de la cuarta componente, por ejemplo el identificador de material se guarda en la cuarta componente del primer vértice de cada triángulo. De todas formas para usar la jerarquía de memoria y mejorar el tiempo de ejecución del algoritmo se pierde la generalidad en las estructuras de datos y la legibilidad del código fuente.

Una vez copiados todos los datos de entrada del algoritmo de raytracing a la GPU, se procede a la invocación del \emph{kernel} encargado de calcular los rayos primarios. Como se muestra en la Figura \ref{fig:DiagramaRTGPU}, los datos necesarios para calcular los rayos primarios son: el plano de vista, la cámara y la resolución de la imagen a renderizar. Toda esta información se encuentra en memoria constante y puede ser accedida en cualquier instante del tiempo de vida de la aplicación CUDA. Es importante resaltar que la invocación al \emph{kernel} que calcula rayos se hace desde la CPU y cuando este finaliza su procesamiento retorna nuevamente a la CPU.

Los rayos primarios son datos de entrada para el \emph{kernel} encargado de calcular el color de cada pixel. Inmediatamente después que se tienen calculados los rayos primarios, se invoca el \emph{kernel} (desde la CPU) que genera la imagen. Dentro de este se encuentra implementado el corazón del algoritmo de raytracing. Los datos de entrada necesarios para calcular el color de cada pixel se muestran en la Figura \ref{fig:DiagramaRTGPU} y son leídos desde memoria de textura, cuyo tiempo de vida es igual al de la aplicación CUDA.

La forma de invocación al \emph{kernel} principal es según la división en bloques de la imagen que se presentó anteriormente y la cantidad de hilos que ejecutan el procedimiento de calculo de color es igual a la cantidad de pixeles. Cada uno de los rayos lanzados recorrerá la estructura de aceleración espacial, siguiendo los reflejos y refracciones. Al finalizar esta ejecución es que se realiza la copia de los datos generados en la GPU nuevamente a la CPU para ser mostrados en pantalla.

\section{Versiones}
El desarrollo del raytracing para CUDA fue iterativo-incremental, donde algunas algunas iteraciones fueron más interesantes que otras, desde el punto de vista del rendimiento del algoritmo para renderizar la imagen (tiempo de ejecución). Siguiendo esta linea, en esta sección se detallan las versiones más destacadas que surgieron a lo largo del proyecto, al culminar alguna de las tantas iteraciones.

Uno de los objetivos de este proyecto es que el raytracing para CUDA tenga un tiempo de ejecución menor (para la misma escena) al algoritmo implementado en C y a otros algoritmos similares para GPU implementados por terceros. Por lo tanto las versiones que se detallan a continuación se consideran hitos en los cuales se mejoró sustancialmente el tiempo de ejecución.

El primer hito esta marcado por la versión que implementa el Raytracing de Whitted completo, el siguiente hito esta marcado por la introducción de mejoras que tienen que ver con la jerarquía de memoria de la GPU. El último hito esta señalado por la mejora del algoritmo de intersección rayo-triángulo.

\subsection{Versión 1}

\begin{description}
    \item \textbf{Algoritmo en C}
        \begin{itemize}
            \item Implementación del algoritmo de Whitted con reflexión y refracción de forma recursiva, usando punteros a memoria para no afectar el tiempo de ejecución con copias innecesarias.
            \item Utiliza la estructura de aceleración espacial \emph{Uniform Grid}.
            \item Restricción de la versión: las escenas deben tener una luz puntual como máximo.
            \item Restricción de la versión: la sombra proyectada por un objeto transparente no tiene en cuenta el color del objeto.
        \end{itemize}
    \item \textbf{Algoritmo en CUDA}
        \begin{itemize}
            \item Implementación del algoritmo de Whitted con reflexión y refracción de forma iterativa.
            \item Utiliza la estructura de aceleración espacial \emph{Uniform Grid}.
            \item La generación de rayos primarios se hace en un \emph{kernel} de CUDA.
            \item Para la recorrida de la grilla, el trazado de rayos de sombra y secundarios se utiliza un solo \emph{kernel} de CUDA.
            \item Las operaciones sobre vectores se hacen usando las operaciones propias de CUDA.
            \item Restricción de la versión: las escenas deben tener una luz puntual como máximo.
            \item Restricción de la versión: las escenas no pueden tener objetos reflexivos y transparentes a la vez.
            \item Restricción de la versión: la sombra proyectada por un objeto transparente no tiene en cuenta el color del objeto.
            \item Restricción de la versión: no explota al máximo la estructura de memoria de la GPU.
            \item Restricción de la versión: sufre el problema que genera el sistema operativo al ejecutar un \emph{kernel} por mas de 5 segundos.
        \end{itemize}
\end{description}

\subsection{Versión 2}
\begin{description}
    \item \textbf{Algoritmo en C}
        \begin{itemize}
            \item Idem. que la versión 1.
        \end{itemize}
    \item \textbf{Algoritmo en CUDA}
        \begin{itemize}
            \item Idem. que la versión 1.
            \item Se elimina la restricción ``no explota al máximo la estructura de memoria de la GPU'', usando la jerarquía de memoria (memoria de textura y constante principalmente) para almacenar las estructuras de datos que representan la escena a procesar por el algoritmo.
        \end{itemize}
\end{description}

\subsection{Versión 3}
\begin{description}
    \item \textbf{Algoritmo en C}
        \begin{itemize}
            \item Idem. que la versión 2.
        \end{itemize}
    \item \textbf{Algoritmo en CUDA}
        \begin{itemize}
            \item Idem. que la versión 2.
            \item Se cambia el algoritmo de intersección rayo-triángulo para disminuir el tiempo de ejecución de cada test de intersección.
        \end{itemize}
\end{description}
