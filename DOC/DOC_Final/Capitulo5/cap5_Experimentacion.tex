\chapter{Experimentación} % 20 páginas mas o menos...

\section{Relevamiento calidad imagen}

Para evaluar la corrección de la solución implementada es necesario, además de una evaluación de la velocidad de generación de las imágenes, una medida de la calidad de las mismas. Por eso es que se relevó en el campo de la generación de imágenes cuáles eran los métodos con los que se evaluaba la calidad de los generadores de imágenes más importantes. En esta investigación no se pudieron encontrar estrategias solidas para evaluar la calidad. A continuación se describen a grandes rasgos los algoritmos que existen para la evaluación de calidad de imágenes.




Se realizó una categorización de las medidas de evaluación de calidad, basada en el articulo de Ismail Avcibas y Bülent Sankur \cite{QualityMeasuresCategories} y analizando el resto de la información disponible \cite{HVSQualityAssessment} \cite{IdentifyingComputerGeneratedImages} \cite{SegmentationPerceptualImageQualityAssessment} \cite{StructuralSimilarityPerceptualImageQualityAssessment}. Cabe señalar que si bien el artículo \cite{QualityMeasuresCategories} no es sobre la generación de imágenes, se pueden ver ciertas similitudes en los objetivos de todas y cada una de las medidas de calidad de imágenes.
Las categorías en las que se dividen los algoritmos de evaluación de calidad son:
Basados en diferencias a nivel de píxeles, basados en correlación, basados en aristas, basados en análisis espectral, basados en contexto y basados en el sistema visual humano (HVS por su sigla en inglés).

Las estrategias basadas en diferencias a nivel de píxeles son los más simples, calculan la diferencia entre 2 imágenes tomando como referencia que un pixel en una imagen se corresponde con el mismo pixel de la imagen objetivo y, dependiendo de cuál de los algoritmos se trate, calcula alguna ponderación de los pixeles para retornar un valor que indicará la diferencia que hay entre ambas imágenes, la generada y la imagen objetivo.
Las estrategias basads en correlación son muy similares a los anteriores pero pueden introducir una nueva variable: los píxeles se pueden mover y no estar en el mismo lugar en ambas imágenes. Este tipo de algoritmos son útiles en muchos casos para el área de procesamiento de imagen, en especial porque una misma imagen puede ser generada vista de distintos ángulos y en el análisis de calidad de las mismas considerar que no tienen diferencias.
Otra opción se basa en que las imágenes en general presentan en su composición aristas que son los bordes que separan los componentes de la imagen entre  si, estas aristas se pueden utilizar para el análisis de calidad de imagen. Esta técnica se basa en que si dos imágenes son generadas para la misma escena, entonces las imágenes en la imagen ideal que sería el objetivo, entonces también se deben presentar en la imagen generada.
Las estrategias que se basan en el análisis espectral son particularmente útiles en el análisis de algoritmos de compresión en los que se da este tipo de distorsión. Miden la distorsión en fase y magnitud, esto pertenece al área de tratamiento de señales, base del tratamiento de imágenes, pero tampoco se ve una aplicación directa a este trabajo.
En el análisis de contexto para medir la calidad de imagen se analiza para cada pixel sus vecinos en una cantidad de niveles arbitraria. Estos píxeles en caso de que difieran de alguna manera (esto varía para cada algoritmo dentro de la familia) modificaran, no solo la calidad de ellos mismos como analizan las estrategias de diferencia por pixel, sino también la calidad de los vecinos, dado que no será lo mismo, por ejemplo, un pixel negro entre píxeles rojos que un pixel negro entre píxeles blancos.
Por último, los métodos basados en el análisis de la percepción humana para brindar una medida de calidad de la imagen generada. Este tipo de estrategias utilizan los modelos que se han generado para la percepción del ojo humano declarando que dos imágenes son iguales si para la percepción del ojo humano no tienen diferencias. Este es un modelo razonable en muchos aspectos, en particular para la industria audiovisual, por ejemplo películas, videojuegos, generación de imágenes fotorealistas, entre otras.


Como se puede ver, todas estas estrategias son por ejemplo para comparar imágenes y no lo que realmente interesa en el contexto de este proyecto que es evaluar la calidad de las imágenes generadas por un algoritmo.
En evaluación de imágenes generadas es que se basa el artículo del año 2007 \cite{IdentifyingComputerGeneratedImages}. Claro que plantea, al contrario de lo que se requiere en este caso, detectar que imágenes son generadas por un algoritmo de generación de imágenes y cuales son imágenes reales tomadas con una cámara. Aunque el objetivo que persigue este artículo es muy similar al que se persigue en el análisis de esta sección, el algoritmo propuesto e implementado no cumple con ser fotorealista dado que el modelo utilizado, Raytracing, no es un modelo tan preciso. Por esto es que no se podrían utilizar los métodos propuestos en el artículo.
Por otro lado los algoritmos basados en las capacidades de percepción del sistema visual humano en general también apuntan a evaluar que imágenes son iguales para el ojo humano. Al igual que en el caso anterior, estas estrategias no aplicarían en el contexto que se requiere. En este caso, por lo tanto, no son aplicables las medidas relevadas para la evaluación de calidad de las imágenes generadas. Si bien se entiende que este podría ser un tema de estudio interesante.

\section{Casos de prueba}

Para probar el rendimiento del algoritmo de generación de imágenes implementado es necesario generar escenas a renderizar. Como se ha mencionado en la descripción del algoritmo una escena se especifica mediante dos archivos que siguen un formato establecido.

Al momento de diseñar los casos de prueba para el algoritmo de Raytracing se busco cubrir los aspectos críticos del algoritmo. Un aspecto importante a tener en cuenta es que el algoritmo de Raytracing implementado usa una grilla uniforme como estructura de aceleración. Como se analizó en la etapa de relevamiento del proyecto este tipo de estructura no es buena cuando la escena tiene una distribución espacial no uniforme de sus elementos. Por ello resulta importante probar el mismo con un conjunto de escenas que mantengan fija la cantidad de objetos, pero que varíen la distribución de ellos.

La cantidad de objetos de la escena es un aspecto que afecta directamente el tiempo de ejecución de un algoritmo de Raytracing. Por este motivo es importante verificar el tiempo de ejecución del algoritmo implementado con escenas que tengan distinta cantidad de objetos pero que mantengan fijas todas las demás propiedades.

La comparación con implementaciones similares es importante para establecer la calidad del algoritmo de Raytracing desarrollado en el marco de este proyecto. Por este motivo se incluyen dentro de los casos de prueba escenas pertenecientes a la comunidad web de Raytracing. Dentro de esta clase de escenas externas al proyecto, hay escenas usadas en todo proyecto de generación de imágenes, por ejemplo ``\emph{stanford bunny}'' y también hay escenas únicas de proyectos particulares.

Es importante decir que es difícil encontrar un algoritmo similar al implementado ya que existen numerosas variantes del mismo, se pueden encontrar diversas técnicas de aceleración del algoritmo, entre otros aspectos. Los datos comparables entre las distintas implementaciones son los frames por segundo (FPS), la calidad de la imagen generada, etc.

\subsubsection{Distribución de los objetos en la escena}

Para verificar el comportamiento del algoritmo implementado frente a la uniformidad espacial de los objetos de la escena se diseñaron tres casos de prueba. Como se muestra en la Figura \ref{fig:CPDistrEspacial} los tres casos son similares, la única diferencia entre ellos es la posición de los objetos (cada uno esta compuesto por 1148 triángulos) en la escena.

\begin{figure}
    \centering
    \subfigure[]{
        \label{fig:CPDistrEspacial:a} %% label for first subfigure
        \includegraphics[width=0.3\textwidth]{./Capitulo5/DIST_I}
    }
    \subfigure[]{
        \label{fig:CPDistrEspacial:b} %% label for second subfigure
        \includegraphics[width=0.3\textwidth]{./Capitulo5/DIST_II}
    }
    \subfigure[]{
        \label{fig:CPDistrEspacial:c} %% label for second subfigure
        \includegraphics[width=0.3\textwidth]{./Capitulo5/DIST_III}
    }
    \caption{Escenas con distinta disposición espacial de los objetos.}
    \label{fig:CPDistrEspacial} %% label for entire figure
\end{figure}

En la Tabla \ref{table:CPDistrEspacial} se muestran algunas características importantes de estos casos de prueba, en especial en la primer columna se muestra una referencia que será usada de aquí en más.

\begin{table}[!hbt]
\begin{center}
\resizebox{10cm}{!}{
    \small {
    \begin{tabular}{|c|c|c|c|c|c|}
    \hline
    Ref & Objetos & Luces & Triángulos & Archivo & Imagen\\
    \hline
    DIDT\_I & 9 & 1 & 10338 & elefantesChicosDistUniforme.obj & \ref{fig:CPDistrEspacial:a}\\
    \hline
    DIDT\_II & 9 & 1 & 10338 & elefantesChicosDistNoUniforme.obj & \ref{fig:CPDistrEspacial:b}\\
    \hline
    DIDT\_III & 9 & 1 & 10338 & elefantesChicosDistNoUniformeSOLAP.obj & \ref{fig:CPDistrEspacial:c}\\
    \hline
    \end{tabular}
    }
}
\caption{Datos de entrada para pruebas de distribución.}
\label{table:CPDistrEspacial}
\end{center}
\end{table}


\subsubsection{Cantidad de primitivas de la escena}

Para verificar el comportamiento del algoritmo implementado frente a la cantidad de objetos de la escena de entrada se diseñaron cinco casos de prueba. Los cinco casos de prueba definen la misma escena, la única propiedad que cambia entre uno o otro es la cantidad de primitivas (triángulos) usadas para construir los objetos de la misma. Como se muestra en las Figuras \ref{fig:CPCantidadPrimitivas:a} y \ref{fig:CPCantidadPrimitivas:b} cada escena contiene una esfera y un cubo, y existe una diferencia entre las imágenes generadas dada por la variación de la cantidad de triángulos.

\begin{figure}
    \centering
    \subfigure[]{
        \label{fig:CPCantidadPrimitivas:a} %% label for first subfigure
        \includegraphics[width=0.3\textwidth]{./Capitulo5/PRI_I}
    }
    \subfigure[]{
        \label{fig:CPCantidadPrimitivas:b} %% label for second subfigure
        \includegraphics[width=0.3\textwidth]{./Capitulo5/PRI_V}
    }
    \caption{Imágenes de los casos de prueba de cantidad de primitivas.}
    \label{fig:CPCantidadPrimitivas} %% label for entire figure
\end{figure}

En la Tabla \ref{table:CPCantPrimitivas} se muestran algunas características importantes de estos casos de prueba, en especial en la primer columna se muestra una referencia que será usada de aquí en más.

\begin{table}[!hbt]
\begin{center}
\resizebox{10cm}{!}{
    \small {
    \begin{tabular}{|c|c|c|c|c|c|}
    \hline
    Ref & Objetos & Luces & Triángulos & Archivo & Imagen\\
    \hline
    PRI\_I & 2 & 2 & 194 & cajaEsfera1.obj & \ref{fig:CPCantidadPrimitivas:a}\\
    \hline
    PRI\_II & 2 & 2 & 274 & cajaEsfera2.obj & -\\
    \hline
    PRI\_III & 2 & 2 & 348 & cajaEsfera3.obj & -\\
    \hline
    PRI\_IV & 2 & 2 & 482 & cajaEsfera4.obj & -\\
    \hline
    PRI\_V & 2 & 2 & 606 & cajaEsfera5.obj & \ref{fig:CPCantidadPrimitivas:b}\\
    \hline
    \end{tabular}
    }
}
\caption{Datos de entrada para pruebas de cantidad de primitivas.}
\label{table:CPCantPrimitivas}
\end{center}
\end{table}



\subsubsection{Comparando con otras implementaciones}

Para la evaluación de la calidad del algoritmo implementado en el marco de este proyecto, resulta imprescindible la comparación con otros algoritmos de Raytracing similares. Por ello se buscaron algoritmos que se ajustaran al modelo de Whitted, implementados sobre CUDA por la comunidad mundial de Raytracing.

\begin{figure}
    \centering
    \subfigure[]{
        \label{fig:CPTerceros:a} %% label for first subfigure
        \includegraphics[width=0.2\textwidth]{./Capitulo5/alexandra}
    }
    \subfigure[]{
        \label{fig:CPTerceros:b} %% label for second subfigure
        \includegraphics[width=0.2\textwidth]{./Capitulo5/buddha}
    }
    \subfigure[]{
        \label{fig:CPTerceros:c} %% label for second subfigure
        \includegraphics[width=0.2\textwidth]{./Capitulo5/dragon}
    }
    \subfigure[]{
        \label{fig:CPTerceros:d} %% label for second subfigure
        \includegraphics[width=0.2\textwidth]{./Capitulo5/StanfordBunny}
    }
    \caption{Imágenes de los casos de prueba de cantidad de primitivas.}
    \label{fig:CPTerceros} %% label for entire figure
\end{figure}

Los integrantes del grupo de Computación Gráfica del \emph{Alexandra Institute} de Dinamarca implementaron un algoritmo de Raytracing y se encuentra publicado en su página web \cite{BlogAlexandraInst}. Este algoritmo no permite cambiar la escena que renderiza de forma sencilla, ya que su cargador de escena es distinto al que se usa en este proyecto. Como se dispone de información (cantidad de triángulos de cada uno de los elementos) sobre la escena del algoritmo del \emph{Alexandra Institute}, se decidió replicar manualmente dicha escena en el formato que usa el algoritmo implementado en este proyecto. Esta escena esta formada por un conjunto de 13 cajas y una esfera como se muestra en la Figura \ref{fig:CPTerceros:a}. Cada caja tiene 2 triángulos por cara y la esfera tiene 80 caras, por lo tanto la escena completa tiene 236 triángulos. Al renderizar su escena el Raytracing sobre GPU del \emph{Alexandra Institute} logra 13 \emph{frames} por segundo (FPS).

Las escenas cuyos renders se muestran en las Figuras \ref{fig:CPTerceros:b}, \ref{fig:CPTerceros:c} y \ref{fig:CPTerceros:d}, se encuentran dentro de las escenas clásicas de todo proyecto de ge\-ne\-ra\-ción de imágenes. Contar con estas escenas dentro de los casos de prueba de este proyecto es muy importante porque permite comparar con otros proyectos similares. Además el hecho de que el algoritmo implementado en este proyecto soporte este tipo de casos de prueba, que por lo general se componen de una cantidad importante (100.000) de primitivas, es importante.

En la Tabla \ref{table:CPTerceros} se muestran algunas características importantes de estos casos de prueba, en especial en la primer columna se muestra una referencia que será usada de aquí en más.

\begin{table}[!hbt]
\begin{center}
\resizebox{10cm}{!}{
    \small {
    \begin{tabular}{|c|c|c|c|c|c|}
    \hline
    Ref & Objetos & Luces & Triángulos & Archivo & Imagen\\
    \hline
    ALEXANDRA & 14 & 1 & 236 & escenaAlexandra.obj & \ref{fig:CPTerceros:a}\\
    \hline
    BUDDHA & 1 & 1 & 100.000 & buddhaRT.obj & \ref{fig:CPTerceros:b}\\
    \hline
    DRAGON & 1 & 1 & 100.000 & dragonRT.obj & \ref{fig:CPTerceros:c}\\
    \hline
    STANFORDBUNNY & 1 & 1 & 69698 & StanfordBunny.obj & \ref{fig:CPTerceros:d}\\
    \hline
    \end{tabular}
    }
}
\caption{Escenas que permiten la comparación con otros proyectos.}
\label{table:CPTerceros}
\end{center}
\end{table}

\section{Equipos utilizados}

Las características de los equipos utilizados para ejecutar los casos de prueba se muestran en la Tabla \ref{table:EquiposUtilizados}. Todos los equipos utilizados usan \emph{Windows} como sistema operativo.

\begin{table}[!hbt]
\begin{center}
\resizebox{12cm}{!}{
    \small {
    \begin{tabular}{|c|c|c|c|c|}
    \hline
    Equipo & CPU & Memoria Ram & GPU & Memoria GPU\\
    \hline
    1 & Core 2 Duo T7500 2.20GHz & 4GB DDR2 667 MHz & GeForce 9500M GS & 512 MB\\
    \hline
    2 & Core 2 Duo P8400 2.26GHz & 4GB DDR2 667 MHz & GeForce 9600M GT & 512 MB\\
    \hline
    3 & Core 2 Duo E7500 2.93GHz & 4GB DDR2 667 MHz & GeForce GTX 260 & 896 MB\\
    \hline
    \end{tabular}
    }
}
\caption{Equipos utilizados para ejecutar los casos de prueba.}
\label{table:EquiposUtilizados}
\end{center}
\end{table}

Todos los equipos utilizados para ejecutar los casos de prueba del proyecto usan la versión 2.3 del \emph{driver} de CUDA. Los equipos poseen tarjetas gráficas distintas lo cual implica que las propiedades que afectan la ejecución de las aplicaciones CUDA sobre ellas también lo sean. En la Tabla \ref{table:PropCUDA} se muestran las principales propiedades relacionadas con CUDA de cada tarjeta gráfica utilizada en el proyecto.

\begin{table}[!hbt]
\begin{center}
\resizebox{10cm}{!}{
    \small {
    \begin{tabular}{|c|c|c|}
    \hline
    Equipo & Multiprocesadores & Núcleos\\
    \hline
    1 & - & -\\
    \hline
    2 & 4 & 32\\
    \hline
    3 & 27 & 216\\
    \hline
    \end{tabular}
    }
}
\caption{Características de las GPUs utilizadas.}
\label{table:PropCUDA}
\end{center}
\end{table}


\section{Pruebas}

Falta completar...

\subsection{Comparación entre C y CUDA}

\subsection{Comparación entre versiones}

\subsection{Comparación entre equipos}

\subsection{Casos más exitosos}
