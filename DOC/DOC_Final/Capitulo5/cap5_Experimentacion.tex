\chapter{Experimentación} % 20 páginas mas o menos...

Esta sección detalla las estrategias tomadas para evaluar el trabajo realizado, explicando las pruebas realizadas, así como también los resultados obtenidos en estas pruebas. También se describen otros trabajos y se compara contra estos para evaluar la distancia en cuanto a eficiencia de nuestro algoritmo comparado con otras implementaciones similares.

\section{Estrategias de evaluación de calidad de imagen}

Para evaluar la solución implementada es necesario, además de una evaluación de la velocidad de generación de las imágenes, una medida de la calidad de las mismas. Por esta razón se relevaron los métodos con los que se evaluaba la calidad de los generadores de imágenes. Como resultado de esta investigación no se pudieron determinar estrategias solidas para evaluar la calidad de las imágenes generadas.
Si bien no se encontraron algoritmos que se adaptaran específicamente a las necesidades del trabajo, se presentan a continuación ideas interesantes que podrían servir a la de desarrollar métodos para evaluar la calidad de imágenes generadas por trabajos similares a este.

Se realizó una categorización de las medidas de evaluación de calidad, basada en el artículo de Avcibas y Sankur \cite{QualityMeasuresCategories} y analizando el resto de la información disponible \cite{HVSQualityAssessment} \cite{IdentifyingComputerGeneratedImages} \cite{SegmentationPerceptualImageQualityAssessment} \cite{StructuralSimilarityPerceptualImageQualityAssessment}. Cabe señalar que si bien el trabajo de Avcibas y Sankur \cite{QualityMeasuresCategories} no es sobre generación de imágenes, se pueden establecer ciertas similitudes en los objetivos de todas y cada una de las medidas de calidad de imágenes.
Las categorías en las que se dividen los algoritmos de evaluación de calidad son:
\begin{itemize}
\item Basados en diferencias a nivel de píxeles.
\item Basados en correlación.
\item Basados en aristas.
\item Basados en análisis espectral.
\item Basados en contexto.
\item Basados en el sistema visual humano (HVS por su sigla en inglés).
\end{itemize}

Las estrategias basadas en diferencias a nivel de píxeles son los más simples, calculan la diferencia entre 2 imágenes tomando como referencia que un pixel en una imagen se corresponde con el mismo pixel de la imagen objetivo y, dependiendo de cuál de los algoritmos se trate, calcula alguna ponderación de los pixeles para retornar un valor que indicará la diferencia que hay entre ambas imágenes, la generada y la imagen objetivo.

Las estrategias basadas en correlación son muy similares a los anteriores pero pueden introducir una nueva variable: los píxeles se pueden mover y no estar en el mismo lugar en ambas imágenes. Este tipo de algoritmos son útiles en muchos casos para el área de procesamiento de imagen, en especial porque una misma imagen puede ser generada vista de distintos ángulos y en el análisis de calidad de las mismas considerar que no tienen diferencias.

/////////////////////////RE REDACTAR ESTE PARRAFO/////////////////////////////////////
Otra opción se basa en que las imágenes en general presentan en su composición aristas que son los bordes que separan los componentes de la imagen entre  si, estas aristas se pueden utilizar para el análisis de calidad de imagen. Esta técnica se basa en que si dos imágenes son generadas para la misma escena, entonces las imágenes en la imagen ideal que sería el objetivo, entonces también se deben presentar en la imagen generada.

Las estrategias que se basan en el análisis espectral miden la distorsión de la señal en fase y magnitud, esto pertenece al área de tratamiento de señales, base del tratamiento de imágenes. Si bien son particularmente útiles en el análisis de algoritmos de compresión en los que se da este tipo de distorsión no se encontró una aplicación directa a este trabajo.

En el análisis de contexto para medir la calidad de imagen se analiza para cada pixel sus vecinos en una cantidad de niveles arbitraria. Estos píxeles en caso de que difieran de alguna manera (esto varía para cada algoritmo dentro de la familia) modificaran, no solo la calidad de ellos mismos como analizan las estrategias de diferencia por pixel, sino también la calidad de los vecinos, dado que no será lo mismo, por ejemplo, un pixel negro entre píxeles rojos que un pixel negro entre píxeles blancos.

Por último, los métodos basados en el análisis de la percepción humana para brindar una medida de calidad de la imagen generada. Este tipo de estrategias utilizan los modelos que se han generado para la percepción del ojo humano declarando que dos imágenes son iguales si para la percepción del ojo humano no tienen diferencias. Este es un modelo razonable en muchos aspectos, en particular para la industria audiovisual, por ejemplo películas, videojuegos, generación de imágenes fotorealistas, entre otras.


Como se puede ver, todas estas estrategias son para comparar imágenes y no son aplicables directamente en el contexto de este proyecto donde el objetivo es evaluar la calidad de las imágenes generadas por un algoritmo.
En evaluación de imágenes generadas es que se basa el artículo de Dirik, Bayram, Sencar y Memon \cite{IdentifyingComputerGeneratedImages}. Pero plantea, al contrario de lo que se requiere en este proyecto, detectar que imágenes son generadas por un algoritmo de generación de imágenes y cuales son imágenes reales tomadas con una cámara. Aunque el objetivo que persigue este artículo es muy similar al que se persigue en el análisis de esta sección, el área de trabajo de este proyecto no son las imágenes fotorealistas dado que el modelo abordado, Raytracing, no es un modelo tan preciso. Por esto es que no se podrían utilizar los métodos propuestos en el artículo de Dirik, Bayram, Sencar y Memon.

////////////////NO ENTENDÍ LA CORRECCIÓN////////////////
Por otro lado los algoritmos basados en las capacidades de percepción del sistema visual humano en general también apuntan a evaluar que imágenes son iguales para el ojo humano. Al igual que en el caso anterior, estas estrategias no aplicarían en el contexto que se requiere. En este caso, por lo tanto, no son aplicables las medidas relevadas para la evaluación de calidad de las imágenes generadas. Si bien se entiende que este podría ser un tema de estudio interesante.

\section{Casos de prueba}

Para probar el desempeño de los algoritmos de generación de imágenes implementados es necesario disponer de un conjunto de casos de prueba con distintas características.

La comparación con implementaciones similares es importante para establecer la calidad del algoritmo de Raytracing desarrollado en el marco de este proyecto. Por este motivo se incluyen dentro de los casos de prueba escenas pertenecientes a distintas instituciones que realizan investigación y desarrollo sobre el algoritmo de Raytracing. Dentro de esta clase de escenas externas al proyecto, hay escenas usadas en todo proyecto de generación de imágenes, por ejemplo ``\emph{stanford bunny}'' y también hay escenas únicas de proyectos particulares.

Al no disponer de un conjunto estándar de pruebas a realizar sobre el algoritmo, ya que no están establecidas por la diversidad de pruebas a realizarse, es que se eligieron y diseñaron casos de prueba según criterios justificados que se adapten a los objetivos del trabajo.

En este sentido, al momento de diseñar los casos de prueba para las versiones de Raytracing se buscó cubrir los aspectos críticos del algoritmo. Un aspecto importante a tener en cuenta es que los algoritmos implementados usan una grilla uniforme como estructura de aceleración. Como se analizó anteriormente este tipo de estructura no es buena cuando la escena tiene una distribución espacial no uniforme de sus elementos. Por ello resulta importante probar las versiones con un conjunto de escenas que mantengan fija la cantidad de objetos, pero que varíen la distribución de ellos.

La cantidad de objetos de la escena es un aspecto que afecta directamente el tiempo de ejecución de un algoritmo de Raytracing. Por este motivo es importante verificar el tiempo de ejecución del algoritmo implementado con escenas que tengan distinta cantidad de objetos pero que mantengan fijas todas las demás propiedades.

\subsubsection{Distribución de los objetos en la escena}

Para verificar el comportamiento del algoritmo implementado frente a la uniformidad espacial de los objetos de la escena se diseñaron tres casos de prueba. Como se muestra en la Figura \ref{fig:CPDistrEspacial} los tres casos son similares, la única diferencia entre ellos es la posición de los objetos (cada uno esta compuesto por 1148 triángulos) en la escena.

\begin{figure}
    \centering
    \subfigure[]{
        \label{fig:CPDistrEspacial:a} %% label for first subfigure
        \includegraphics[width=0.3\textwidth]{./Capitulo5/DIST_I}
    }
    \subfigure[]{
        \label{fig:CPDistrEspacial:b} %% label for second subfigure
        \includegraphics[width=0.3\textwidth]{./Capitulo5/DIST_II}
    }
    \subfigure[]{
        \label{fig:CPDistrEspacial:c} %% label for second subfigure
        \includegraphics[width=0.3\textwidth]{./Capitulo5/DIST_III}
    }
    \caption{Escenas con distinta disposición espacial de los objetos.}
    \label{fig:CPDistrEspacial} %% label for entire figure
\end{figure}

En la Tabla \ref{table:CPDistrEspacial} se muestran algunas características importantes de estos casos de prueba, en especial en la primer columna se muestra una referencia que será usada de aquí en más.

\begin{table}[!hbt]
\begin{center}
\resizebox{10cm}{!}{
    \small {
    \begin{tabular}{|c|c|c|c|c|c|}
    \hline
    Ref & Objetos & Luces & Triángulos & Archivo & Imagen\\
    \hline
    DIDT\_I & 9 & 1 & 10338 & elefantesChicosDistUniforme.obj & \ref{fig:CPDistrEspacial:a}\\
    \hline
    DIDT\_II & 9 & 1 & 10338 & elefantesChicosDistNoUniforme.obj & \ref{fig:CPDistrEspacial:b}\\
    \hline
    DIDT\_III & 9 & 1 & 10338 & elefantesChicosDistNoUniformeSOLAP.obj & \ref{fig:CPDistrEspacial:c}\\
    \hline
    \end{tabular}
    }
}
\caption{Datos de entrada para pruebas de distribución.}
\label{table:CPDistrEspacial}
\end{center}
\end{table}


\subsubsection{Cantidad de primitivas de la escena}

Para verificar el comportamiento del algoritmo implementado frente a la cantidad de objetos de la escena de entrada se diseñaron cinco casos de prueba. Los cinco casos de prueba definen la misma escena, la única propiedad que cambia entre uno o otro es la cantidad de primitivas (triángulos) usadas para construir los objetos de la misma. Como se muestra en las Figuras \ref{fig:CPCantidadPrimitivas:a} y \ref{fig:CPCantidadPrimitivas:b} cada escena contiene una esfera y un cubo, y existe una diferencia entre las imágenes generadas dada por la variación de la cantidad de triángulos.

\begin{figure}
    \centering
    \subfigure[]{
        \label{fig:CPCantidadPrimitivas:a} %% label for first subfigure
        \includegraphics[width=0.3\textwidth]{./Capitulo5/PRI_I}
    }
    \subfigure[]{
        \label{fig:CPCantidadPrimitivas:b} %% label for second subfigure
        \includegraphics[width=0.3\textwidth]{./Capitulo5/PRI_V}
    }
    \caption{Imágenes de los casos de prueba de cantidad de primitivas.}
    \label{fig:CPCantidadPrimitivas} %% label for entire figure
\end{figure}

En la Tabla \ref{table:CPCantPrimitivas} se muestran algunas características importantes de estos casos de prueba, en especial en la primer columna se muestra una referencia que será usada de aquí en más.

\begin{table}[!hbt]
\begin{center}
\resizebox{10cm}{!}{
    \small {
    \begin{tabular}{|c|c|c|c|c|c|}
    \hline
    Ref & Objetos & Luces & Triángulos & Archivo & Imagen\\
    \hline
    PRI\_I & 2 & 2 & 194 & cajaEsfera1.obj & \ref{fig:CPCantidadPrimitivas:a}\\
    \hline
    PRI\_II & 2 & 2 & 274 & cajaEsfera2.obj & -\\
    \hline
    PRI\_III & 2 & 2 & 348 & cajaEsfera3.obj & -\\
    \hline
    PRI\_IV & 2 & 2 & 482 & cajaEsfera4.obj & -\\
    \hline
    PRI\_V & 2 & 2 & 606 & cajaEsfera5.obj & \ref{fig:CPCantidadPrimitivas:b}\\
    \hline
    \end{tabular}
    }
}
\caption{Datos de entrada para pruebas de cantidad de primitivas.}
\label{table:CPCantPrimitivas}
\end{center}
\end{table}



\subsubsection{Comparación con otras implementaciones}

Para la evaluación de desempeño de los algoritmos implementados en el marco de este proyecto, resulta imprescindible la comparación con otros algoritmos de Raytracing similares. Por ello se buscaron algoritmos que se ajustaran al modelo de Whitted, implementados sobre CUDA por desarrolladores de Raytracing.

\begin{figure}
    \centering
    \subfigure[]{
        \label{fig:CPTerceros:a} %% label for first subfigure
        \includegraphics[width=0.2\textwidth]{./Capitulo5/alexandra}
    }
    \subfigure[]{
        \label{fig:CPTerceros:b} %% label for second subfigure
        \includegraphics[width=0.2\textwidth]{./Capitulo5/buddha}
    }
    \subfigure[]{
        \label{fig:CPTerceros:c} %% label for second subfigure
        \includegraphics[width=0.2\textwidth]{./Capitulo5/dragon}
    }
    \subfigure[]{
        \label{fig:CPTerceros:d} %% label for second subfigure
        \includegraphics[width=0.2\textwidth]{./Capitulo5/StanfordBunny}
    }
    \caption{Imágenes de los casos de prueba de cantidad de primitivas.}
    \label{fig:CPTerceros} %% label for entire figure
\end{figure}

Los integrantes del grupo de Computación Gráfica del \emph{Alexandra Institute} de Dinamarca \cite{BlogAlexandraInst} implementaron un algoritmo de Raytracing y se encuentra publicado en su página web. Este algoritmo no permite cambiar la escena que renderiza de forma sencilla, ya que su cargador de escena es distinto al que se usa en este proyecto. Como se dispone de información (cantidad de triángulos de cada uno de los elementos) sobre la escena del algoritmo del \emph{Alexandra Institute}, se decidió replicar manualmente dicha escena en el formato que usa el algoritmo implementado en este proyecto. Esta escena esta formada por un conjunto de 13 cajas y una esfera como se muestra en la Figura \ref{fig:CPTerceros:a}. Cada caja tiene 2 triángulos por cara y la esfera tiene 80 caras, por lo tanto la escena completa tiene 236 triángulos.

Las escenas cuyos renders se muestran en las Figuras \ref{fig:CPTerceros:b}, \ref{fig:CPTerceros:c} y \ref{fig:CPTerceros:d}, se encuentran dentro de las escenas clásicas de todo proyecto de ge\-ne\-ra\-ción de imágenes. Contar con estas escenas dentro de los casos de prueba de este proyecto es muy importante porque permite comparar con otros proyectos similares. Además el hecho de que el algoritmo implementado en este proyecto soporte este tipo de casos de prueba, que por lo general se componen de una cantidad importante (100.000) de primitivas, es importante.

En la Tabla \ref{table:CPTerceros} se muestran algunas características destacables de estos casos de prueba, en especial en la primer columna se muestra una referencia que será usada de aquí en más.

\begin{table}[!hbt]
\begin{center}
\resizebox{10cm}{!}{
    \small {
    \begin{tabular}{|c|c|c|c|c|c|}
    \hline
    Ref & Objetos & Luces & Triángulos & Archivo & Imagen\\
    \hline
    ALEXANDRA & 14 & 1 & 236 & escenaAlexandra.obj & \ref{fig:CPTerceros:a}\\
    \hline
    BUDDHA & 1 & 1 & 100.000 & buddhaRT.obj & \ref{fig:CPTerceros:b}\\
    \hline
    DRAGON & 1 & 1 & 100.000 & dragonRT.obj & \ref{fig:CPTerceros:c}\\
    \hline
    BUNNY & 1 & 1 & 69698 & StanfordBunny.obj & \ref{fig:CPTerceros:d}\\
    \hline
    \end{tabular}
    }
}
\caption{Escenas que permiten la comparación con otros proyectos.}
\label{table:CPTerceros}
\end{center}
\end{table}

\section{Equipos utilizados}

Las características de los equipos utilizados para ejecutar los casos de prueba se muestran en la Tabla \ref{table:EquiposUtilizados}. Todos los equipos utilizados usan \emph{Windows} como sistema operativo.

\begin{table}[!hbt]
\begin{center}
\resizebox{12cm}{!}{
    \small {
    \begin{tabular}{|c|c|c|c|c|}
    \hline
    Equipo & CPU & Memoria Ram & GPU & Memoria GPU\\
    \hline
    9500M & Core 2 Duo T7500 2.20GHz & 4GB DDR2 667 MHz & GeForce 9500M GS & 512 MB\\
    \hline
    9600M & Core 2 Duo P8400 2.26GHz & 4GB DDR2 667 MHz & GeForce 9600M GT & 512 MB\\
    \hline
    GTX260 & Core 2 Duo E7500 2.93GHz & 4GB DDR2 667 MHz & GeForce GTX 260 & 896 MB\\
    \hline
    \end{tabular}
    }
}
\caption{Equipos utilizados para ejecutar los casos de prueba.}
\label{table:EquiposUtilizados}
\end{center}
\end{table}

Todos los equipos utilizados para ejecutar los casos de prueba del proyecto usan la versión 2.3 del \emph{driver} de CUDA. Los equipos poseen tarjetas gráficas distintas lo cual implica que las propiedades que afectan la ejecución de las aplicaciones CUDA sobre ellas también lo sean. En la Tabla \ref{table:PropCUDA} se muestran las principales propiedades relacionadas con CUDA de cada tarjeta gráfica utilizada en el proyecto.

\begin{table}[!hbt]
\begin{center}
\resizebox{10cm}{!}{
    \small {
    \begin{tabular}{|c|c|c|c|c|c|}
    \hline
    Equipo & Multiprocesadores & Núcleos & Clock (MHz)& Shader clock (MHz)& Memory clock (MHz)\\
    \hline
    9500M & 4 & 32 & 475 & 950 & 400\\
    \hline
    9500M & 4 & 32 & 500 & 1250 & 400\\
    \hline
    GTX260 & 27 & 216 & 576 & 1242 & 999\\
    \hline
    \end{tabular}
    }
}
\caption{Características de las GPUs utilizadas.}
\label{table:PropCUDA}
\end{center}
\end{table}


\section{Experimentos}

Las pruebas realizadas en este proyecto se pueden dividir en dos grandes líneas. La primera es comparar resultados dentro del propio proyecto, por ejemplo la comparación entre los dos algoritmos implementados, uno para CPU y el otro para GPU.La otra línea de prueba es la comparación con algoritmos similares implementados por terceros. En esta clase de pruebas se hicieron comparaciones con implementaciones que pudieron ser ejecutadas en los equipos utilizados en el proyecto y también con resultados de otras experiencias similares extraídos de artículos científicos.

La mayoría de las pruebas realizadas se hicieron fijando la resolución de la imagen a generar en 640 por 480 pixeles. Las únicas excepciones a esta regla se dan cuando se hacen pruebas de comparación con algoritmos implementados por terceros. Para las pruebas de comparación con el \emph{Alexandra Institute} se uso una resolución de 800 por 600, mientras que para la comparación con los resultados del artículo de Günther et al. \cite{GuntherPopov} se uso una resolución de 1024 por 1024 pixeles. En el caso del \emph{Alexandra Institute} la resolución quedó determinada por su implementación del algoritmo de Raytracing, que no permite variar la misma. En el caso del artículo de Günther la resolución quedo determinada por los resultados descritos en él, ya que fueron obtenidos usando una resolución fija (1024 por 1024).

Las pruebas realizadas a lo largo del proyecto mostraron que una buena elección del tamaño de la grilla puede incrementar notablemente la velocidad de generación de imágenes, siendo esto un parámetro crítico que se debe definir correctamente. Como primer aproximación se toma la medida sugerida por Thrane y Ole \cite{TesisEstructuras}, la cual indica que la resolución sea $3\sqrt[3]{N}$ voxeles a lo largo del eje más corto, donde $N$ es el número de triángulos de la escena. Después varias pruebas realizadas se comprobó que esta división no siempre es la mejor y que una buena resolución para la grilla se encuentra entre $\sqrt[3]{N}$ y $3\sqrt[3]{N}$ a lo largo del eje más corto. Dentro de este intervalo se debe buscar empíricamente la grilla de mejor rendimiento. En todas las pruebas realizadas en esta sección se siguió esta metodología para encontrar el tamaño de grilla óptimo (o grilla optima), así mismo se muestran también otros tamaños de grilla para cada escena.

\subsection{Comparación entre C y CUDA}\label{sec:ComparacionCvsCUDA}

La comparación de rendimiento entre el algoritmo para CPU y el algoritmo para GPU se hizo usando los casos de prueba DIST\_I, DIST\_II, DIST\_II y BUNNY. Para esta comparación se usa la versión más eficiente de los algoritmos, la Versión RT(GPU-JM-IR) y la Versión RT(CPU-IR), ejecutando en el Equipo GTX260. En la Tabla \ref{table:CvsCUDACPU} se muestran los resultados obtenidos al ejecutar los casos de prueba sobre CPU, mientras que en la Tabla \ref{table:CvsCUDAGPU} se muestran los resultados obtenidos al ejecutar los mismos casos sobre GPU.

\begin{table}
\begin{center}
\resizebox{12cm}{!}{
    \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
    \multirow{2}{*}{\textbf{Escena}}&\multicolumn{6}{|c|}{\textbf{Tamaño de grilla}}\\
    \cline{2-7}
    &10x10x10&22x22x22&50x50x50&65x65x65&100x100x100&200x200x200\\
    \hline
    DIST\_I&0.3&0.9&1.4&1.3&1.1&0.3\\
    \hline
    DIST\_II&0.3&1.0&1.5&1.4&1.1&0.3\\
    \hline
    DIST\_III&0.4&1.3&1.6&1.4&1.1&0.3\\
    \hline
    \multirow{2}{*}{}&\multicolumn{6}{|c|}{}\\
    \cline{2-7}
    &20x20x20&41x41x41&80x80x80&123x123x123&200x200x200&300x300x300\\
    \hline
    BUNNY&1.2&3.0&4.2&4.0&3.2&2.1\\
    \hline
    \end{tabular}
}
\caption{FPS de DIST\_I, DIST\_II, DIST\_III y BUNNY en el Equipo GTX260 sobre CPU.}
\label{table:CvsCUDACPU}
\end{center}
\end{table}

Los resultados obtenidos sugieren que el tamaño de la grilla depende exclusivamente de la cantidad de triángulos con que esta construida la escena, ya que en los tres primeros casos (que tienen la misma cantidad de triángulos) el tamaño de grilla donde se logran más FPS es siempre el mismo. Además como lo muestra el caso BUNNY, al incrementarse la cantidad de primitivas de la escena aumenta la resolución de la grilla óptima. Se concluye también que el tamaño de la grilla óptima es independiente al \emph{hardware} de ejecución, la grilla que permite más FPS tiene igual resolución en CPU y en GPU.

\begin{table}
\begin{center}
\resizebox{12cm}{!}{
    \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
    \multirow{2}{*}{\textbf{Escena}}&\multicolumn{6}{|c|}{\textbf{Tamaño de grilla}}\\
    \cline{2-7}
    &10x10x10&22x22x22&50x50x50&65x65x65&100x100x100&200x200x200\\
    \hline
    DIST\_I&10.5&15.4&17.2&14.2&10.7&5.1\\
    \hline
    DIST\_II&10.7&16.7&20.1&17.5&12.0&5.1\\
    \hline
    DIST\_III&8.9&18.5&21.1&18.2&12.5&5.1\\
    \hline
    \multirow{2}{*}{}&\multicolumn{6}{|c|}{}\\
    \cline{2-7}
    &20x20x20&41x41x41&80x80x80&123x123x123&200x200x200&300x300x300\\
    \hline
    BUNNY&13.9&20.7&23.8&20.8&14.4&10.1\\
    \hline
    \end{tabular}
}
\caption{FPS de DIST\_I, DIST\_II, DIST\_III y BUNNY en el Equipo GTX260 sobre GPU.}
\label{table:CvsCUDAGPU}
\end{center}
\end{table}

Los casos de prueba DIST\_I, DIST\_II y DIST\_III fueron pensados para buscar una debilidad de la estructura de aceleración. La debilidad de la estructura de subdivisión espacial uniforme se da cuando los objetos de la escena están distribuidos de forma no uniforme en la misma. Es por esto que se pensaba que con el caso DIST\_III, que tiene todos los objetos concentrados en el centro de la escena, se lograrían menos FPS que con el DIST\_II y con el DIST\_I. De la misma forma se pensaba que con el caso DIST\_II se lograrían menos FPS que con el caso DIST\_I. Los resultados obtenidos reflejan totalmente lo contrario a lo que se pensaba de antemano. La explicación que se encuentra y que es para el caso de este tipo de escenas, es que cuanto mas uniformemente distribuidos en la escena estén los objetos, más sombra arrojan. Como el calculo de sombra es un cálculo computacionalmente costoso, se cree que este costo contrarresta al beneficio que brinda la grilla cuando existe distribución espacial uniforme de los objetos en la escena.

\begin{figure}
    \centering
    \subfigure[]{
        \label{fig:CvsCudaRenderBunny:a} %% label for first subfigure
        \includegraphics[width=0.3\textwidth]{./Capitulo5/renderBunnyCPU}
    }
    \subfigure[]{
        \label{fig:CvsCudaRenderBunny:b} %% label for second subfigure
        \includegraphics[width=0.3\textwidth]{./Capitulo5/renderBunnyGPU}
    }
    \caption{Render de BUNNY en CPU y en GPU respectivamente.}
    \label{fig:CvsCudaRenderBunny} %% label for entire figure
\end{figure}

Los resultados obtenidos con los casos de prueba DIST\_I, DIST\_II, DIST\_III y BUNNY demuestran que el algoritmo para GPU genera imágenes en un tiempo menor que el algoritmo para CPU. En la Tabla \ref{table:CvsCudaAceleracion} se muestra la aceleración lograda por el algoritmo para GPU para cada caso de prueba. En promedio, considerando los cuatro casos de prueba, el algoritmo para GPU es más de 11 veces más rápido que el algoritmo para CPU. En la Figura \ref{fig:CvsCudaRenderBunny:a} se muestra la imagen generada por el algoritmo implementado en C, mientras que en la Figura \ref{fig:CvsCudaRenderBunny:b} se muestra la imagen generada por el algoritmo implementado en CUDA. Observando estas imágenes el ojo humano no percibe diferencia alguna, entonces el algoritmo para GPU logra una muy buena aceleración con respecto al que ejecuta en CPU y sin pérdida en la calidad de imagen.

\begin{table}
\begin{center}
\resizebox{10cm}{!}{
    \small {
    \begin{tabular}{|c|c|c|c|c|}
    \hline
    Escena & Tamaño Grilla & CPU (FPS) & GPU (FPS) & Aceleración\\
    \hline
    DIST\_I & 50x50x50 & 1.4 & 17.2 & 12\\
    \hline
    DIST\_II & 50x50x50 & 1.5 & 20.1 & 14\\
    \hline
    DIST\_III & 50x50x50 & 1.6 & 21.1 & 13\\
    \hline
    BUNNY & 80x80x80 & 4.2 & 23.8 & 6\\
    \hline
    \end{tabular}
    }
}
\caption{Aceleración lograda por algoritmo para GPU.}
\label{table:CvsCudaAceleracion}
\end{center}
\end{table}

\subsection{Comparación entre versiones}

La comparación de rendimiento entre las diferentes versiones del algoritmo para GPU se hizo usando los casos de prueba PRI\_I a PRI\_V. Esta comparación entre versiones consta de dos partes, en la primera se determina la grilla optima para cada caso de prueba y en la segunda se ejecuta cada caso de prueba en cada una de las versiones del algoritmo utilizando su grilla optima.

Para determinar la grilla optima para cada escena de prueba se usa la Versión RT(GPU-JM-IR) del algoritmo para GPU, ejecutando en el Equipo GTX260. En la Tabla \ref{table:CompVersionesBuscarGrilla} se muestran los resultados obtenidos al ejecutar los casos de prueba sobre GPU. Observando los resultados se puede concluir que la grilla optima para todos los casos de prueba se construye partiendo en dos cada eje.

Los resultados obtenidos en estas primeras pruebas muestran que a medida que aumenta la cantidad de primitivas con que esta construida la escena aumenta el tiempo de generación de imagen, y por lo tanto disminuyen los FPS. Esto se pensaba antes de ejecutar estos casos de prueba y fue corroborado por los mismos. También se pensaba que al aumentar la cantidad de primitivas de la escena aumentaría la cantidad de voxels que debía tener la grilla optima, pero esto no fue validado por los resultados obtenidos. Esto puede deberse a que el incremento de la cantidad de primitivas no es suficientemente grande como para obligar a aumentar la resolución de la grilla.

\begin{table}
\begin{center}
\resizebox{12cm}{!}{
    \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
    \multirow{2}{*}{\textbf{Escena}}&\multicolumn{6}{|c|}{\textbf{Tamaño de grilla}}\\
    \cline{2-7}
    & 1x1x1 & 2x2x2 & 4x4x4 & 6x6x6 & 10x10x10 & 15x15x15\\
    \hline
    PRI\_I & 18.7 & 36.7 & 32.7 & 29.7 & 27.3 & 24.7\\
    \hline
    PRI\_II & 13.9 & 27.6 & 25.4 & 23.3 & 21.5 & 20.1\\
    \hline
    PRI\_III & 11.3 & 24.5 & 22.8 & 20.9 & 19.2 & 18.0\\
    \hline
    PRI\_IV & 8.4 & 18.5 & 18.0 & 16.5 & 15.9 & 15.1\\
    \hline
    PRI\_V & 6.7 & 16.6 & 15.5 & 14.6 & 13.8 & 13.5\\
    \hline
    \end{tabular}
}
\caption{FPS de PRI\_I,\ldots, PRI\_V en el Equipo GTX260 sobre GPU.}
\label{table:CompVersionesBuscarGrilla}
\end{center}
\end{table}

Una vez determinada la grilla optima para cada caso de prueba, se ejecuta cada caso utilizando su grilla optima en cada una de las versiones del algoritmo para GPU, en la Tabla \ref{table:CompVersionesFPS} se muestran los resultados obtenidos.

\begin{table}
\begin{center}
\resizebox{12cm}{!}{
    \begin{tabular}{|c|c|c|c|c|}
    \hline
    Escena & Tamaño Grilla Óptimo & RT(GPU) (FPS) & RT(GPU-JM) (FPS) & RT(GPU-JM-IR) (FPS)\\
    \hline
    PRI\_I & 2x2x2 & 5.8 & 26.2 & 36.7\\
    \hline
    PRI\_II & 2x2x2 & 5.1 & 20.2 & 27.6\\
    \hline
    PRI\_III & 2x2x2 & 4.9 & 18.2 & 24.5\\
    \hline
    PRI\_IV & 2x2x2 & 4.3 & 14.1 & 18.5\\
    \hline
    PRI\_V & 2x2x2 & 3.9 & 12.6 & 16.6\\
    \hline
    \end{tabular}
}
\caption{FPS de PRI\_I,\ldots, PRI\_V en el Equipo GTX260 sobre GPU para cada versión del algoritmo.}
\label{table:CompVersionesFPS}
\end{center}
\end{table}

Sin duda los resultados de la Tabla \ref{table:CompVersionesFPS} reflejan que a medida que se fue mejorando el algoritmo se incrementaron los FPS para todos los casos de prueba.

El incremento del tiempo de generación de imagen es mayor en el primer cambio de versión, esta diferencia esta determinada por el uso de la jerarquía de memoria de la GPU. En la Versión RT(GPU) todos los accesos a memoria son a memoria global mientras que en la Versión RT(GPU-JM) la mayoría de los datos de entrada del algoritmo de Raytracing se encuentran en memoria de textura. Considerando estos casos de prueba, el correcto uso de la jerarquía de memoria permite que el algoritmo pierda menos tiempo accediendo a memoria siendo así (en promedio) tres veces y media más rápido que el algoritmo que no la usa.

En el segundo cambio de versión se mejora el algoritmo de intersección rayo-triángulo, el nuevo test de intersección logra el mismo objetivo que el anterior pero con menos operaciones aritméticas, lo cual implica una disminución del tiempo de generación de la imagen. Considerando los resultados obtenidos esta mejora del algoritmo de Raytracing ayuda a que la Versión RT(GPU-JM-IR) genere la imagen un 30\% más rápido que en la Versión RT(GPU-JM).

\begin{figure}
    \centering
    \subfigure[]{
        \label{fig:CompVersionesRenders:a} %% label for first subfigure
        \includegraphics[width=0.3\textwidth]{./Capitulo5/renderPRI5Version1}
    }
    \subfigure[]{
        \label{fig:CompVersionesRenders:b} %% label for second subfigure
        \includegraphics[width=0.3\textwidth]{./Capitulo5/renderPRI5Version2}
    }
    \subfigure[]{
        \label{fig:CompVersionesRenders:c} %% label for second subfigure
        \includegraphics[width=0.3\textwidth]{./Capitulo5/renderPRI5Version3}
    }
    \caption{Render de PRI\_V en GPU con la Versión RT(GPU), RT(GPU-JM) y RT(GPU-JM-IR) respectivamente.}
    \label{fig:CompVersionesRenders} %% label for entire figure
\end{figure}

En la Figura \ref{fig:CompVersionesRenders} se muestran los renders del caso de prueba PRI\_V con cada una de las versiones del algoritmo implementado en CUDA. No se observan diferencias importantes entre las imágenes generadas por las diferentes versiones del algoritmo. El aumento de número de versión del algoritmo implica un aumento en la cantidad de FPS, esta disminución del tiempo de generación de imágenes no implica perdida de calidad de imagen.


\subsection{Comparación entre equipos}\label{sec:ComparacionEquipos}

La comparación de rendimiento entre los diferentes equipos del proyecto se hizo usando la Versión RT(GPU-JM-IR) del algoritmo implementado para GPU. Los casos de prueba de esta comparación son: DRAGON, BUDDHA y ALEXANDRA. En cada equipo del proyecto, se corren los casos de prueba usando varios tamaños de grilla, de esta forma se puede determinar el tamaño de grilla óptimo para cada caso y equipo. El mejor tiempo de generación de imagen para cada caso y equipo es analizado y comparado con los demás.

En las Tablas \ref{table:EquiposEquipo1}, \ref{table:EquiposEquipo2} y \ref{table:EquiposEquipo3} se muestran los resultados obtenidos para el Equipo 9500M, Equipo 9600M y Equipo GTX260 respectivamente.

\begin{table}
\begin{center}
\resizebox{12cm}{!}{
    \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
    \multirow{2}{*}{\textbf{Escena}}&\multicolumn{6}{|c|}{\textbf{Tamaño de grilla}}\\
    \cline{2-7}
    & 20x20x20 & 46x46x46 & 92x92x92 & 138x138x138 & 180x180x180 & 230x230x230\\
    \hline
    DRAGON & 1.4 & 2.3 & 2.8 & 2.0 & 1.6 & 1.3\\
    \hline
    BUDDHA & 1.3 & 2.4 & 2.5 & 2.1 & 1.7 & 1.3\\
    \hline
    \multirow{2}{*}{}&\multicolumn{6}{|c|}{}\\
    \cline{2-7}
    & 1x1x1 & 3x3x3 & 6x6x6 & 10x10x10 & 15x15x15 & 30x30x30\\
    \hline
    ALEXANDRA & 4.6 & 11.5 & 15.6 & 13.1 & 12.3 & 9.1\\
    \hline
    \end{tabular}
}
\caption{FPS de DRAGON, BUDDHA y ALEXANDRA en el Equipo 9500M sobre GPU.}
\label{table:EquiposEquipo1}
\end{center}
\end{table}

De los resultados obtenidos se desprende que para los casos de prueba DRAGON, BUDDHA y ALEXANDRA el tamaño de grilla donde se logran más FPS es el mismo independientemente del equipo en donde se ejecuten. El modelo de programación de CUDA es capaz de ejecutar más hilos en paralelo cuanto más procesadores tenga la GPU. Basado en esto se puede afirmar que el tamaño de grilla óptimo no depende del grado de paralelismo que se logre.

Todas la pruebas realizadas en esta comparación confirmaron que cuanto más procesadores posea la GPU más rápido será la generación de imágenes mediante el algoritmo de Raytracing para CUDA. Los resultados demuestran que la aplicación CUDA implementada puede escalar automáticamente en el número de procesadores de la GPU, esta importante característica surge como consecuencia del modelo de programación de CUDA que permite lograrlo muy fácilmente.

La GPU del Equipo GTX260 tiene un poco más de seis veces más procesadores que la del Equipo 9600M. Si consideramos los resultados de los casos DRAGON, BUDDHA y ALEXANDRA con sus grillas óptimas, se observa que la a\-ce\-le\-ra\-ción en la generación de imagen nunca llega a 6, sino que es aproximadamente 5, 4 y 4 respectivamente. Basado en esta información se puede concluir que la ganancia de FPS no es lineal con respecto al aumento de procesadores. Esto se debe al tiempo empleado para la lectura de datos de entrada, a retrasos por se\-ria\-li\-za\-ción de los accesos a memoria o por sincronizaciones entre hilos al momento de escribir los resultados.

\begin{table}
\begin{center}
\resizebox{12cm}{!}{
    \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
    \multirow{2}{*}{\textbf{Escena}}&\multicolumn{6}{|c|}{\textbf{Tamaño de grilla}}\\
    \cline{2-7}
    & 20x20x20 & 46x46x46 & 92x92x92 & 138x138x138 & 180x180x180 & 230x230x230\\
    \hline
    DRAGON & 1.7 & 3.3 & 3.4 & 2.6 & 2.0 & 1.6\\
    \hline
    BUDDHA & 1.4 & 2.8 & 3.1 & 2.6 & 2.1 & 1.7\\
    \hline
    \multirow{2}{*}{}&\multicolumn{6}{|c|}{}\\
    \cline{2-7}
    & 1x1x1 & 3x3x3 & 6x6x6 & 10x10x10 & 15x15x15 & 30x30x30\\
    \hline
    ALEXANDRA & 5.9 & 14.0 & 20.0 & 18.4 & 17.5 & 12.8\\
    \hline
    \end{tabular}
}
\caption{FPS de DRAGON, BUDDHA y ALEXANDRA en el Equipo 9600M sobre GPU.}
\label{table:EquiposEquipo2}
\end{center}
\end{table}

\begin{table}
\begin{center}
\resizebox{12cm}{!}{
    \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
    \multirow{2}{*}{\textbf{Escena}}&\multicolumn{6}{|c|}{\textbf{Tamaño de grilla}}\\
    \cline{2-7}
    & 20x20x20 & 46x46x46 & 92x92x92 & 138x138x138 & 180x180x180 & 230x230x230\\
    \hline
    DRAGON & 5.0 & 12.2 & 16.8 & 14.2 & 11.4 & 9.3\\
    \hline
    BUDDHA & 4.9 & 9.8 & 12.4 & 11.4 & 10.3 & 8.4\\
    \hline
    \multirow{2}{*}{}&\multicolumn{6}{|c|}{}\\
    \cline{2-7}
    & 1x1x1 & 3x3x3 & 6x6x6 & 10x10x10 & 15x15x15 & 30x30x30\\
    \hline
    ALEXANDRA & 28.0 & 49.3 & 71.2 & 67.6 & 62.5 & 49.4\\
    \hline
    \end{tabular}
}
\caption{FPS de DRAGON, BUDDHA y ALEXANDRA en el Equipo GTX260 sobre GPU.}
\label{table:EquiposEquipo3}
\end{center}
\end{table}

En la Figura \ref{fig:CompEquiposRenders} se muestran renders del caso de prueba BUDDHA con el algoritmo implementado en CUDA. El render de la Figura \ref{fig:CompEquiposRenders:a} fue generado usando el Equipo 9500M, el de la Figura \ref{fig:CompEquiposRenders:b} fue generado usando el Equipo 9600M y el de la Figura \ref{fig:CompEquiposRenders:c} con el Equipo GTX260. No se observan diferencias importantes entre las imágenes generadas por los diferentes equipos utilizados en el proyecto. El aumento del poder de computo de la GPU implica un aumento en la cantidad de FPS, esta disminución del tiempo de generación de imágenes no implica perdida de calidad de las mismas.

\begin{figure}
    \centering
    \subfigure[]{
        \label{fig:CompEquiposRenders:a} %% label for first subfigure
        \includegraphics[width=0.3\textwidth]{./Capitulo5/renderBuddhaEquipo1}
    }
    \subfigure[]{
        \label{fig:CompEquiposRenders:b} %% label for second subfigure
        \includegraphics[width=0.3\textwidth]{./Capitulo5/renderBuddhaEquipo2}
    }
    \subfigure[]{
        \label{fig:CompEquiposRenders:c} %% label for second subfigure
        \includegraphics[width=0.3\textwidth]{./Capitulo5/renderBuddhaEquipo3}
    }
    \caption{Render de BUDDHA en GPU sobre los Equipos 9500M, 9600M y GTX260 respectivamente.}
    \label{fig:CompEquiposRenders} %% label for entire figure
\end{figure}

\subsection{Casos más exitosos}

Un caso de prueba que permite evaluar un resultado positivo en la implementación del algoritmo de Raytracing en CUDA es la escena BUNNY. En el trabajo de Johannes Günther et al. \cite{GuntherPopov} se hizo una implementación similar a la de este proyecto del algoritmo de Raytracing. En este trabajo se generan renders de una escena que es igual a la escena BUNNY y se presentan resultados de tiempos de generación de imágenes. Debido a que solo se presentan resultados y no se tiene acceso al código fuente, las pruebas con el algoritmo implementado se adaptaron al trabajo de Günther para lograr resultados comparables.

Se deben considerar algunas excepciones con respecto a la igualdad de las escenas, la escena BUNNY esta construida mediante la observación minuciosa de un render del trabajo de Günther. Por ejemplo, la cantidad de luces es la misma pero la posición de estas no son exactamente las mismas, el material del objeto principal de la escena no pudo ser reproducido con exactitud debido a la falta de información, etc.

En el trabajo de Johannes Günther se usa una resolución de 1024 por 1024 pixeles por lo tanto las pruebas de comparación se hacen utilizando la misma resolución.

Günther et al. usan la estructura Kd-Tree como método de a\-ce\-le\-ra\-ción espacial, como se dijo en la sección de relevamiento de estructuras de a\-ce\-le\-ra\-ción, la Kd-Tree es más eficiente que la utilizada en este proyecto. Debido a esto, para la comparación con el algoritmo implementado en este proyecto se usa el tamaño de grilla que permite generar la imagen en el menor tiempo posible, dicho tamaño se definió empíricamente en la sección \ref{sec:ComparacionCvsCUDA}.

La GPU utilizada en el trabajo de Günther es nVidia modelo GeForce 8800 GTX, la cual posee 112 núcleos. En el marco de este proyecto la GPU que más se adapta para este caso es la del Equipo GTX260, ya que si bien posee más cantidad de núcleos de procesamiento esta cantidad se ve compensada por el uso de la estructura Kd-Tree por parte del algoritmo de Günther et al.

En la Figura \ref{fig:ExitosoBunnyRenders:a} se muestra el render extraído del trabajo de Johannes Günther y en la Figura \ref{fig:ExitosoBunnyRenders:b} se muestra el render de la escena BUNNY generado con la Versión RT(GPU-JM-IR) del algoritmo implementado para GPU.

\begin{figure}
    \centering
    \subfigure[]{
        \label{fig:ExitosoBunnyRenders:a} %% label for first subfigure
        \includegraphics[width=0.45\textwidth]{./Capitulo5/renderPaperBunny}
    }
    \subfigure[]{
        \label{fig:ExitosoBunnyRenders:b} %% label for second subfigure
        \includegraphics[width=0.45\textwidth]{./Capitulo5/renderGPU3Bunny}
    }
    \caption{Render de BUNNY en el trabajo de Günther y en este proyecto respectivamente.}
    \label{fig:ExitosoBunnyRenders} %% label for entire figure
\end{figure}

El rendimiento en FPS del algoritmo implementado en este proyecto bajo las condiciones descritas anteriormente es de $6.1$ FPS, mientras que el rendimiento del algoritmo del trabajo de Günther es de $5.9$ FPS. El rendimiento de ambos algoritmos para este caso de prueba es muy similar. El algoritmo implementado en este proyecto tiene a favor que la GPU donde ejecuta es más potente y en contra que usa una estructura de aceleración menos eficiente. El algoritmo implementado en el trabajo de Günther tiene a favor que usa una estructura de aceleración más eficiente y en contra que ejecuta en una GPU de menor capacidad de cálculo. De todas formas es importante que el algoritmo implementado en este proyecto tenga rendimientos competitivos con algoritmos desarrollados en otros proyectos similares.


Otro caso de prueba que permite evaluar un resultado positivo del algoritmo implementado para GPU es la escena ALEXANDRA.

La resolución de la imagen que genera el algoritmo de Raytracing implementado por el \emph{Alexandra Institute} es de 800 por 600 pixeles y no puede ser modificada, por lo tanto se usa esta resolución para las pruebas de comparación. El Raytracing del \emph{Alexandra Institute} no usa estructura de aceleración espacial, mientras que el algoritmo implementado en este proyecto usa un tamaño de grilla de 6 voxels por dimensión. Este tamaño de grilla genera el mejor rendimiento del algoritmo y fue hallado empíricamente en la sección \ref{sec:ComparacionEquipos}.

Debido a que se tiene acceso al ejecutable del algoritmo del \emph{Alexandra Institute} se optó por ejecutar la comparación de rendimiento entre ambos algoritmos en el Equipo 9600M.

En la Figura \ref{fig:ExitosoAlexRenders:a} se muestra un render generado por la aplicación desarrollada por el \emph{Alexandra Institute} y en la Figura \ref{fig:ExitosoAlexRenders:b} se muestra el render de la escena ALEXANDRA generado con la Versión RT(GPU-JM-IR) del algoritmo implementado para GPU sobre el Equipo 9600M.

\begin{figure}
    \centering
    \subfigure[]{
        \label{fig:ExitosoAlexRenders:a} %% label for first subfigure
        \includegraphics[width=0.45\textwidth]{./Capitulo5/renderAlexTercero}
    }
    \subfigure[]{
        \label{fig:ExitosoAlexRenders:b} %% label for second subfigure
        \includegraphics[width=0.45\textwidth]{./Capitulo5/renderAlexNuestro}
    }
    \caption{Render de la aplicación del \emph{Alexandra Institute} y render de ALEXANDRA en GPU sobre Equipo 9600M usando la Versión RT(GPU-JM-IR), respectivamente.}
    \label{fig:ExitosoAlexRenders} %% label for entire figure
\end{figure}

El rendimiento en FPS del algoritmo implementado en este proyecto bajo las condiciones descritas anteriormente es de $13$ FPS, mientras que el rendimiento del raytracing del \emph{Alexandra Institute} es de $11.7$ FPS. El algoritmo implementado en este proyecto tiene en contra (para su rendimiento) que renderiza escenas genéricas, es decir, no fue concebido para generar imágenes de solo un tipo de escena, lo cual implica que para una misma escena se requiere mayor espacio de almacenamiento y más accesos a memoria. Parte de la escena del algoritmo desarrollado por el instituto de Dinamarca se encuentra en el código fuente del mismo, lo cual brinda mayor eficiencia para el caso puntual. Es posible afirmar que para este caso de prueba ambos algoritmos tienen rendimientos similares, esto demuestra que el algoritmo implementado es competitivo con otros algoritmos de raytracing implementados en CUDA.

En las imágenes generadas por ambos algoritmos se pueden apreciar diferencias, como por ejemplo el color de fondo que no pudo ser correctamente reproducido en la escena de prueba ALEXANDRA. Se nota otra diferencia en el brillo especular de la esfera, esto se debe a la reproducción incorrecta del material de la misma. Aunque en el render generado por el algoritmo implementado en este proyecto se aprecia mejor el reflejo de los objetos cercanos a la esfera sobre la superficie de la misma. Otra diferencia que es que el algoritmo del \emph{Alexandra Institute} trata a las luces de la escena como un objeto más de la misma, esto no es considerado por el algoritmo implementado en este proyecto. Se puede concluir que no existen diferencias de calidad significativas entre ambos renders.
