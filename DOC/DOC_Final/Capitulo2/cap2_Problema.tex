\chapter{Problema} % 20 páginas mas o menos...

\section{Introducción}
Este proyecto aborda una problemática actual existente en el mundo de la computación gráfica que es la generación de imágenes fotorealistas en tiempos de cálculo bajos. En la actualidad existen muchos algoritmos para la generación de imágenes fotorrealistas, esto se evidencia por la cantidad de películas de animación con modelos 3D o que simplemente utilizan efectos 3D para realzar las escenas. Un tema no menor es el tiempo de procesamiento que requieren este tipo de trabajos, para cada una de las imágenes que se van a incluir en la versión final de la película toman varios minutos u horas dependiendo de la complejidad de la imagen a generar. Estos tiempos dependeran de si la escena tiene reflejos o no, si tiene transparencias, si tiene muchos fragmentos pequeños de objetos, entre otros aspéctos de calidad del modelo 3D a mostrar en la pantalla. No solo son un problema los tiempos que se requieren para generar las imágenes sino que además estas imágenes requieren de una capacidad de computo enorme. Por esto, en general, se utilizan grandes clusters de computadoras para realizar la generación de las imágenes.
Para poder comprender la forma en que se generan las imágenes fotorealistas por computadora es necesario conocer en profundidad: cómo se especifican los modelos y cuáles son las formas en que se puede, a partir de los modelos, generar o computar las imágenes. En las siguientes subsecciones se introduce a dichas temáticas.
Este capítulo intentará interiorizar al lector en los conceptos escenciales tales como: que es una escena y los algoritmos utilizados para generar imágenes. También se mostrarán los modelos para la iluminación que se utilizan, así como la clasificación de los algoritmos en base a estos modelos.


\subsection{Concepto de escena}
Una escena es una colección de objetos y fuentes de luz que será vista por medio de una cámara. Cada una de estas partes esta colocada en lo que se llama ``mundo'', que es un espacio resultante de modelar cuerpos tridimensionales en una imagen bidimensional \cite{Hearn88}. Por ejemplo, si se quiere una imagen de una habitación con una mesa en el centro, la escena debe estar compuesta por dos objetos principales que representen la habitación y la mesa, una o más fuentes de luz, y la cámara, que es desde donde se ve la escena.

Cada objeto de una escena es una ``primitiva geométrica'', que por lo general es una figura geométrica simple como un polígono, una esfera ó un cono. Sin embargo las primitivas en una escena pueden ser matemáticamente más complejas, algunos ejemplos pueden ser superficies de Bezier, subdivisiones de superficies, superficies ISO, etc. Casi cualquier tipo de objeto puede ser usado como primitiva de una escena.

\subsection{Trazado de rayos}
El rayo $R(t) = O + tD$ es por lo general representado mediante un punto de origen $O$ y una dirección $D$. En el marco de un algoritmo que traza rayos hay fundamentalmente tres problemas que deben ser resueltos: encontrar la intersección más cercana al origen del rayo $O$, encontrar alguna intersección a lo largo del rayo\footnote{Se define $t_{max}$, si $t > t_{max}$ no se consideran las intersecciones.} y encontrar todas las intersecciones a lo largo de él.
La clave de la eficiencia de cualquier tipo de algoritmo trazador de rayos es encontrar eficientementela intersección de un rayo con una escena compuesta por una lista de primitivas geométricas.

La operación más utilizada en este tipo de algoritmos es obtener la in\-ter\-sec\-ción más cercana al origen del rayo. Los datos que se requieren son la primitiva $P$ más cercana que interseca con el rayo y la distancia $t_{hit}$ desde $O$ al punto de intersección. Además pueden determinarse otros pa\-r\'a\-me\-tros opcionales que serán utilizados en pasos posteriores del algoritmo, como pueden ser propiedades de la superficie o la normal a la misma en el punto de intersección.
Para gran parte de las primitivas usadas para construir escenas existen diferentes algoritmos que evalúan la intersección con un rayo. Cada uno de los algoritmos tienen diferentes valores respecto a propiedades como velocidad, mantenibilidad, precisión o robustez lo cual hace que no resulte fácil la elección del mismo \cite{RealTimeRendering02}.
Las escenas serán entonces aptas para un algoritmo de trazas mientras sea posible evaluar su intersección con un rayo.

La segunda operación por orden de relevancia es la que determina si existe alguna intersección a lo largo del rayo. El problema que surge a partir de esta operación es igual a la prueba de visibilidad entre dos puntos, en este caso los puntos son: $O$ y $O + t_{max}D$. Encontrar si existe alguna intersección en el camino del rayo es un problema más simple que encontrar la intersección más cercana. Si bien puede emplearse el mismo procedimiento que para encontrar la intersección más cercana, existen algoritmos más eficientes que resuelven este caso especial de trazado de rayo.

El tercer problema, encontrar todas las intersecciones a lo largo de un rayo, es el menos requerido y solo es requerido para algoritmos de iluminación avanzados. Excepto para estos modelos de iluminación especiales, este problema no es común en los algoritmos trazadores de rayos.

\subsection{Algoritmos}
Raycasting \cite{Appel1968} y Raytracing \cite{PaperDel80} son algoritmos utilizados en computación gráfica para la generación de imágenes bidimensionales a partir de escenas tridimensionales que se basan en lanzar rayos desde el ``ojo'' del observador o punto de vista hasta una fuente de luz.

\section{Modelos computacionales de iluminación}
En esta sección se abordarán las técnicas más populares para la generación de imágenes fotorealistas. Comenzando por los algoritmos en el que se basan la mayoría de los algoritmos actuales: Raycasting de Appel y Raytracing de Whitted. Hay que tener en cuenta que estos algoritmos no son los algoritmos más rápidos para la generación de imágenes. La técnica más popular para la generación de gráficos tridimensionales por computadora es rasterización que funciona en tiempo real. La técnica es simplemente el proceso de computar la correspondencia entre la geometría de la escena y los pixels de la imagen y no tiene una forma particular de computar el color de esos pixels. Por ejemplo, esta técnica no tiene en cuenta el cálculo de sombras ni las re\-fle\-xio\-nes entre objetos, como si lo hace, por ejemplo Raytracing.

\subsection{Raycasting}
Fue introducido por Arthur Appel en 1968. Es un algoritmo cuyo funcionamiento se basa en lanzar rayos desde el punto de vista del observador hacia un plano de vista que se encuentra entre el observador y la escena. La unidad mínima de visualización en los dispositivos actuales (monitores o dispositivos similares) es el pixel, cada uno de los cuadros de la grilla en la que se basa la vi\-sua\-li\-za\-ción de imágenes. Por esto el algoritmo genera tantos rayos como pixels haya en el dispositivo de visualización a utilizar. También puede ser que se tenga un tamaño de imagen en pixels, en este caso se genera un rayo por cada pixel de la imagen a generar. Las coordenadas de los pixels se mapean a coordenadas del plano de vista, lanzando un rayo desde el punto de vista del observador que pase por la coordenada del plano de vista y calculando el punto de intersección con la escena, en caso de haberlo. Luego de hallado el punto de intersección con la escena se procede a calcular cuánta energía le llega al punto desde las fuentes de luz, sin tener en cuenta los posibles ``rebotes'' de la luz, como tampoco la posibilidad de que un objeto se encuentre interpuesto entre el objeto y la fuente de luz. Este algoritmo permite calcular fácilmente cuales son los objetos visibles además de facilitar la inclusión de objetos geométricos no planares en las escenas. Este último hecho, en el momento que se propuso el algoritmo, fue muy importante porque con los algoritmos que se utilizaban en la generación de gráficos no era posible incluir este tipo de objetos de forma sencilla. Los algoritmos utilizados en esa época eran algoritmos de scan lines se basan en rasterización mientras que en el algoritmo de Raycasting los rayos no van más allá del primer objeto encontrado.


\subsection{Raytracing}
El algoritmo de Raytracing propuesto por Turner Whitted en 1980 está basado en el algoritmo de Raycasting. Whitted extendió la idea proponiendo hacer la traza de rayos recursiva. Entonces el algoritmo no termina cuando el rayo encuentra un objeto en su trayectoria, sino que en ese momento se hace la invocación recursiva del trazado de rayo, desde el punto de la intersección en el caso de ser necesario. Con la posibilidad de la invocación recursiva del algoritmo se añade la capacidad de sombreado realista dado que se puede calcular la interposición de otros objetos de la escena entre el objeto y la luz.
 Al igual que Raycasting es un algoritmo sencillo para la ge\-ne\-ra\-ción de imágenes que tiene un modelo de iluminación propio y muy simple que se basa en emular las características que cumple la luz al llegar a los objetos o al cambiar de un medio de transmisión a otro. Por ejemplo al pasar del aire al agua, ese es el cambio de medio, se genera una desviación de la luz, dando la impresión de que los objetos se deforman. Así mismo introduce también los conceptos reflexión a las imágenes, admitiendo objetos espejados en las escenas obteniendo un grado de realismo visual superior de los generados por Raycasting.

\subsubsection{Iluminación}

En el algoritmo original, además de considerar las fuentes de luz para obtener sombras en la escena, el algoritmo de trazado de rayos recursivo de Whitted genera rayos de reflexión y de refracción desde el punto de intersección, como se muestra en la Figura~\ref{fig:exampleRT}.

Los rayos de sombra ($L_{i}$), reflexión ($R_{i}$) y refracción ($T_{i}$) son llamados secundarios para diferenciarlos de los primarios que son los que salen desde el punto de vista del observador o cámara.

\begin{figure}[H]
  \centering
    \includegraphics[width=0.7\textwidth]{../DOC_Relevamiento/exampleRT}
  \caption{Generación de rayos del algoritmo de Whitted a partir de un único rayo primario.}
  \label{fig:exampleRT}
\end{figure}

En el primer nivel del algoritmo, cuando se traza un rayo primario, solo se tienen dos posibilidades: el rayo interseca con algún objeto de la escena o no lo hace. Si el rayo no encuentra ningún objeto en su camino, entonces, se debe usar el color de fondo de la escena para pintar ese pixel. Por el contrario, si encuentra un objeto en su trayectoria, se deben realizar los siguientes pasos en el punto de intersección:
\begin{itemize}
  \item Paso uno: para calcular las sombras, se traza un rayo de sombra ($L_{1}$) desde el punto de intersección del rayo con el objeto hacia cada fuente de luz existente en la escena. Si alguno de estos rayos interseca cualquier objeto en su camino hacia la fuente de luz, dependiendo del material del objeto se debe calcular la cantidad de luz que pasa a través de él. Si el objeto es opaco, como es el caso del objeto más pequeño de la Figura~\ref{fig:exampleRT}, la luz es bloqueada totalmente y el punto de intersección estará bajo la sombra del objeto. Esto quiere decir que esta fuente de luz no será tomada en cuenta para calcular la iluminación en el punto. Si el objeto es transparente, como es el caso del objeto más grande de la Figura~\ref{fig:exampleRT}, la intensidad de la fuente de luz se ve disminuida, incluso puede ser absorbida totalmente por el objeto. Existen tablas que indican que cantidad de luz es absorbida por cierto material transparente. En caso de que la luz no sea bloqueada totalmente por el objeto, esta contribuirá a la iluminación del punto de intersección del rayo primario.
  \item Paso dos: si el objeto tiene reflexión especular, como es el caso de la Figura~\ref{fig:exampleRT}, un rayo de reflexión es reflejado a partir del rayo primario, con respecto a la normal ($N_{1}$) en el punto de intersección, en la dirección del vector $R_{1}$. Este rayo permite obtener la cantidad de luz que llega al punto de intersección del rayo primario por el fenómeno de reflexión. Esta cantidad de luz puede verse afectada por el material del objeto, para considerar esto se usa un coeficiente dependiente del material, que escala la cantidad de luz.
  \item Paso tres: si el objeto es transparente, como es el caso de la Figura~\ref{fig:exampleRT} y no ocurre refracción total, es decir si la luz no es absorbida totalmente por la transparencia que posee el objeto, entonces un rayo de refracción es trazado a través del objeto siguiendo la dirección del vector $T_{1}$. Esta dirección es calculada usando la ley de Snell \cite{LibroCompGrafica}. Este rayo permite obtener la cantidad de luz que llega al punto de intersección del rayo primario por el fenómeno de refracción. Esta cantidad de luz puede verse afectada por el material del objeto, para considerar esto se usa un coeficiente dependiente del material, que escala la cantidad de luz.
\end{itemize}
Cada uno de los rayos de reflexión genera rayos de sombra, reflexión y refracción. Lo mismo sucede con cada uno de los de refracción. En el ejemplo de la Figura~\ref{fig:exampleRT}, para calcular la intensidad de luz aportada por $R_{1}$ se usan los mismos pasos que para calcular la intensidad aportada por el rayo primario. Por consiguiente los pasos dos y tres se deben calcular recursivamente. De esta manera se forma un árbol de rayos para cada rayo primario, como se muestra en la Figura~\ref{fig:TreeExample}.
\begin{figure}[H]
  \centering
    \includegraphics[width=0.7\textwidth]{../DOC_Relevamiento/TreeExample}
  \caption{Árbol de rayos que surge del ejemplo de la Figura~\ref{fig:exampleRT}.}
  \label{fig:TreeExample}
\end{figure}
La profundidad del árbol de rayos afecta directamente el tiempo de ejecución del algoritmo y la calidad de la imagen que se quiere obtener. Dicha profundidad está determinada por distintos aspectos como por ejemplo un máximo dispuesto por el usuario del algoritmo o por no haber intersección entre los rayos reflejados y refractados y algún objeto o por la capacidad de almacenamiento del sistema donde ejecuta el algoritmo.

Luego de obtener la cantidad de luz aportada por cada uno de los pasos anteriores, están dadas las condiciones para calcular la iluminación en el punto de intersección del rayo primario. Para esto se debe recorrer un árbol de rayos (por ejemplo el de la Figura~\ref{fig:TreeExample}) de abajo hacia arriba, aplicando la ecuación de iluminación desarrollada por Whitted.

La ecuación de Whitted que se presenta en la Ecuación \ref{eqn:EcIluWhitted}, considera tres componentes, la primera es la iluminación local, es decir, la iluminación dada por el ambiente y por las fuentes de luz de la escena pero sin considerar que los objetos reflejan o refractan luz. Esta primera parte usa la ecuación de iluminación de Phong \cite{LibroCompGrafica}. La segunda ($k_{s}I_{r\lambda}$) y la tercera ($k_{t}I_{t\lambda}$) componente consideran la reflexión y la refracción de los objetos respectivamente.

\begin{equation}
    I_{\lambda} = I_{a\lambda}k_{a}O_{d\lambda}
                + \sum_{1 \leq i \leq m} S_{i} f_{att_{i}} I_{p\lambda_{i}} [k_{d}O_{d\lambda}(\overline{N} \cdot \overline{L_{i}})
                                                                            + k_{s} (\overline{N} \cdot \overline{H_{i}})^n]
                + k_{s}I_{r\lambda}
                + k_{t}I_{t\lambda}
    \label{eqn:EcIluWhitted}
\end{equation}

En la siguiente lista se puede observar el significado de cada variable presente en la Ecuación \ref{eqn:EcIluWhitted}:
\begin{itemize}
  \item $I_{a\lambda}$ - Intensidad de la luz ambiente: luz que ha sido esparcida por todo el ambiente y es imposible determinar su origen, cuando golpea una superficie se esparce igualmente en todas direcciones.
  \item $k_{a}$ - Coeficiente de reflexión de luz ambiente: se encuentra entre 0 y 1. Determina la cantidad de luz ambiente reflejada por la superficie del objeto. Es una propiedad del material del objeto.
  \item $O_{d\lambda}$ - Componente difusa del color del objeto.
  \item $m$ - Cantidad de luces de la escena.
  \item $S_{i}$ - Indicador de sombra: indica si hay algún objeto entre la fuente de luz número $i$ y el punto de evaluación. Toma el valor 1 si la luz no está bloqueada y 0 en caso contrario.
  \item $f_{att_{i}}$ - Factor de atenuación para la luz número $i$: soluciona el problema de que dos superficies se vean iguales al estar a distinta distancia de una fuente de luz. Lo más común es usar el inverso del cuadrado de la distancia hacia la luz.
  \item $I_{p\lambda_{i}}$ - Intensidad de la fuente de luz número $i$ en el punto de evaluación.
  \item $k_{d}$ - Coeficiente de reflexión de luz difusa: se encuentra entre 0 y 1. Determina la cantidad de luz difusa reflejada por la superficie del objeto. Es una propiedad del material del objeto.
  \item $k_{s}$ - Coeficiente de reflexión de luz especular: se encuentra entre 0 y 1. Determina la cantidad de luz especular reflejada por la superficie del objeto. Es una propiedad del material del objeto.
  \item $\overline{H_{i}}$ - Vector de dirección media o vector de iluminación máxima: vector utilizado por la ecuación de iluminación de Phong \cite{LibroCompGrafica}. Se calcula como la dirección media entre el vector normal y el vector que indica la dirección del observador.
  \item $n$ - Exponente de ajuste de la iluminación: este exponente sirve para ajustar la imagen, no es un resultado teórico sino que es resultado de la observación empírica.
  \item $I_{r\lambda}$ - Intensidad del rayo reflejado: esta intensidad es determinada evaluando recursivamente la Ecuación \ref{eqn:EcIluWhitted}.
  \item $k_{t}$ - Coeficiente de trasmisión: se encuentra entre 0 y 1. Determina la cantidad de luz que pasa a través del objeto. Es una propiedad del material del objeto. Existen tablas con valores para distintos materiales.
  \item $I_{t\lambda}$ - Intensidad del rayo refractado: esta intensidad es determinada evaluando recursivamente la Ecuación \ref{eqn:EcIluWhitted}.
\end{itemize}

\subsubsection{Algoritmo}

El algoritmo de Raytracing tiene como ventajas la simplicidad de su implementación, así como también el realismo que logra. Las simplificaciones que utiliza el modelo de iluminación no permiten que se generen envolventes de los rayos de luz reflejados o refractados por una superficie curva. A los efectos generados por este fenómeno se les llama cáusticas.

Otra simplificación en el cálculo de la iluminación es la introducción de un componente de color de ``luz ambiente'', luz que tiene origen en alguna fuente de luz desconocida y parece llegar de todas las direcciones, esto permite no calcular algunos rebotes de la luz en objetos de la escena que harían más complejo al algoritmo. Dada esta última simplificación tampoco se generan efectos de ``sangrado de luz'', este fenómeno es causado por la reflexión de luz de los objetos en forma parcial que hace que el color de una pared, por ejemplo, sea extendido por la zona del suelo cercana a la pared, dando la idea de que la pared ``sangra'' color sobre el suelo.

Una de las principales desventajas que muestra el algoritmo es el costo computacional en especial en los modelos utilizados en la mayoría de las aplicaciones 3D basados en la ras\-te\-ri\-za\-ci\'on de imágenes formadas por polígonos. Por este motivo Raytracing no es una técnica utilizable para la aplicaciones que necesiten mostrar imágenes que se actualicen en tiempo real. Sin embargo, en los últimos tiempos se han desarrollado diferentes esfuerzos por alcanzar tiempo real en aplicaciones basadas en Raytracing, como por ejemplo el juego Quake 3 que utiliza el motor openRT, que utiliza un cluster de 20 nodos que cuentan con procesadores Athlon 64. Dependiendo de lo que se esté intentando dibujar en el juego en ese momento puede requerir algo más de capacidad de cómputo para funcionar de manera adecuada.

En el Algoritmo \ref{alg:algoritmoRTracingI} se muestra un pseudocódigo del algoritmo de Raytracing.

\begin{algorithm}
    \caption{Pseudocódigo del algoritmo de Raytracing.}
    \label{alg:algoritmoRTracingI}
    \begin{algorithmic}
        \ForAll{pixel $p$ en imagen a generar}
            \State $r = rayo(observador, p);$
            \State $p.color = trazarRayo(r, 1);$
        \EndFor
    \end{algorithmic}
\end{algorithm}

 En el Algoritmo \ref{alg:algoritmoRTracingII} se presenta el pseudocódigo de la función $trazarRayo$. Cada objeto de la escena es analizado para probar si el mismo es atravesado por el rayo; del conjunto de objetos atravesados interesa el objeto que tiene el punto de intersección más cercano a la posición del observador. Una vez obtenido el punto de intersección más cercano (si existe) se aplica la Ecuación \ref{eqn:EcIluWhitted}.

La función $verificarSombra$ del Algoritmo \ref{alg:algoritmoRTracingII} se resuelve lanzando un rayo desde el punto de intersección hacia cada uno de los focos de luz para comprobar cuanta luz incide en el objeto. Si todos los rayos intersecan a un objeto antes de llegar al foco de luz entonces el punto está en sombra, caso contrario se tendrá alguna función que calcule cuanto aporta el foco a la iluminación del punto.
Si el objeto atravesado más cercano tiene reflexión se genera un rayo reflejado con origen en la intersección y cuya dirección es calculada en función del ángulo de incidencia del rayo original sobre la superficie del objeto. Si la superficie del objeto tiene refracción se genera un rayo refractado con origen en la intersección cuya dirección es calculada en base a las densidades de los medios por los que atraviesa el rayo utilizando, por ejemplo, la ley de Snell \cite{LibroCompGrafica}. Los rayos reflejado y refractado se usan para invocar recursivamente. Con el color del objeto, el trazado de los rayos de sombra y las dos invocaciones recursivas, de reflexión y refracción se calcula el color del pixel invocando a la función $calcularColorFinal$. Esta función aplica la ecuación de iluminación del modelo de Whitted.

\begin{algorithm}
    \caption{Seudocódigo de la función trazarRayo.}
    \label{alg:algoritmoRTracingII}
    \begin{algorithmic}
        \Require Rayo $r$, Entero $profActual$
        \Ensure Color $color$
        \If {$profActual < MAXPROF$}
            \State \Return $colorNulo$;
        \EndIf
        \State $objetoMasCercano = \infty;$
        \ForAll{objeto $o$ en la escena}
            \If {$hayInterseccion(o, r)$}
                \If {$masCercaObservador(o, objetoMasCercano)$}
                    \State $objetoMasCercano = o;$
                \EndIf
            \EndIf
        \EndFor
        \If {$objetoMasCercano <> \infty$}
            \State $sombra = verificarSombra(objetoMasCercano,r,luces);$
            \If {$objetoMasCercano$ es reflectivo}
                \State $rR = rayoReflejado(objetoMasCercano, r);$
			    \State $reflex = trazarRayo(rR, profActual + 1);$
            \EndIf
            \If {$objetoMasCercano$ es transparente}
                \State $rT = rayoRefractado(objetoMasCercano, r);$
    			\State $refrac = trazarRayo(rT, profActual + 1);$
            \EndIf
            \State $color = calcularColorFinal(objetoMasCercano, sombra, reflex, refrac);$
        \Else
            \State $color = obtenerColorFondo(r)$;
        \EndIf
    \end{algorithmic}
\end{algorithm}


\subsubsection{Clasificación de los algoritmos}

Todos los algoritmos, independientemente de la categoría en la que se encuentren, buscan dada una escena, definición matemática o en algún tipo de representación abstracta, generar una imagen en base a eso. En el trabajo se referencia siempre al concepto de  generación de imágenes realistas aunque los mismos algoritmos podrían ser utilizados para generar otro tipo de escenas. No obstante la diferencia de los enfoques de todos los algoritmos, todos buscan de alguna manera modelar la cantidad de energia lumínica, o radiancia, que está presente en cada punto los distintos objetos que forman la escena. De esta manera calcular de que manera se debería ver la imagen según los parámetros de iluminación que se establezcan. Las categorías que se identifican son las siguientes.

\begin{itemize}
\item El modelo planteado por Whitted que fue descripto previamente.

\item El modelo basado en elementos finitos es bastante simple al igual que el modelo de Whitted pero a su vez muy diferente, ya que plantea para calcular la radiancia la división de la escena en pequeñas partes y se utiliza alguna solución numérica para aproximar los valores.

\item Los algoritmos cuyo modelo de iluminación está basado en métodos de Monte Carlo buscan aproximar los valores de radiancia en base a aproximaciones estadísticas basadas en la integración de Monte Carlo. Esta familia de algoritmos encuentra su mayor exponente actualmente en el algoritmo de Photon Mapping.
\end{itemize}

Por lo tanto Los algoritmos basados en Raytracing pueden ser clasificados utilizando distintas estrategias, en este trabajo se presentan agrupados por el modelo para el cálculo de la iluminación utilizado.

\begin{itemize}
  \item modelo simple de iluminación local diseñado por Whitted.
  \item modelo de iluminación global.
      \begin{itemize}
        \item elementos finitos
        \item métodos de Monte Carlo.
      \end{itemize}
\end{itemize}

\subsection{Radiosidad}
El algoritmo de radiosidad utiliza los principios de Raytracing para el cálculo de las superficies visibles y sombras, así como las reflexiones y refracciones pero a diferencia del algoritmo de Raytracing básico plantea que para hacer el cálculo de la iluminación es necesario pre calcular los valores de iluminación en cada uno de los parches en los que se divide arbitrariamente la escena, por esta división es que este es un método de elementos finitos. Luego de realizado el cálculo de la radiancia de cada uno de los parches se utiliza un rastreo de la escena para el cálculo de los valores de color de los pixels de la imagen que se quiere generar. Como se pre calculan los valores de la iluminación en toda la escena a menos que se modifique la escena o las luces se pueden utilizar los mismos valores de radiancia pre calculados para generar imágenes desde distintos puntos de vista.
\subsection{Photon mapping}
Este algoritmo fue introducido por Henrik Wan Jensen en el año 1996\cite{Jensen2001}. Este algoritmo está aún en desarrollo dado que cuenta con una excelente calidad en las imágenes que puede generar y a su vez es computacionalmente menos costoso que el algoritmo de radiosidad. En lugar de utilizar el modelo de elementos finitos utiliza un modelo basado en métodos de Monte Carlo para el cálculo de la cantidad de energía en cada punto.
El algoritmo de Photon Mapping tiene dos etapas diferenciadas al igual que el algoritmo de radiosidad, pero tiene una aproximación distinta para el cálculo de la radiancia de los puntos. La primera pasada es similar a la recorrida de la escena por el algoritmo de Raytracing con la diferencia que sigue el sentido inverso. Esta primer pasada se llama emisión de fotones, se generan fotones, cuantos más se generen más fiable será el resultado de la iluminación, que son lanzados desde los emisores de luz hacia la escena en direcciones que sean factibles. Se calcula el lugar en el que el fotón incide en la escena recursivamente de manera análoga al algoritmo de Raytracing. Esto es debido a que en el caso de los objetos reales, estos no absorben toda la luz incidente sino que hay luz que es reflejada y por lo tanto fotones son vueltos a lanzar desde el punto en el que chocaron con un objeto. Para hallar la dirección con la que es emitido el nuevo fotón y la energía que tendrá el mismo se utiliza un modelo para los materiales de los objetos de la escena teniendo que agregar al material de los objetos una función de BRDF (Función de Distribución de Reflectancia Bidireccional). Esta función representa la proporción de radiación reflejada por una determinada superficie en cada dirección del rayo reflejado, proyectada sobre el plano horizontal.


\section{Paralelización de algoritmos}

En noviembre de 2006 NVIDIA lanzó CUDA (Compute Unified Device Architecture), una arquitectura de computación paralela de propósito general que hace uso del núcleo de procesamiento paralelo de las GPU de NVIDIA para resolver una amplia variedad de problemas computacionales de una manera más eficiente que en una CPU. El modelo de programación paralela propuesto por NVIDIA fue totalmente nuevo y la programación sobre el mismo se hace a través de un lenguaje de alto nivel, CUDA permite el uso del lenguaje C para la programación.

\begin{figure}[H]
    \centering
        \includegraphics[width=0.8\textwidth]{./Capitulo4/diagramaEjecucionCUDA}
    \caption{Ejemplo de escalabilidad automática en el número de multiprocesadores.}
    \label{fig:DiagramaEjecucionCUDA}
\end{figure}

Una ventaja muy importante del modelo es que cualquier aplicación desarrollada en CUDA puede ejecutarse sobre cualquier número de procesadores, sin necesidad de volver a compilar el código. Esto permite crear aplicaciones capaces de escalar en el número de procesadores, lo cual permite que una aplicación ejecute en cualquier GPU que soporte CUDA.

\begin{figure}[H]
    \centering
        \includegraphics[width=0.8\textwidth]{./Capitulo4/modeloKernels}
    \caption{Ejemplo de ejecución de una aplicación CUDA.}
    \label{fig:ModeloKernels}
\end{figure}

El modelo de programación esta basado en tres abstracciones fundamentales, dispone de una jerarquía de grupos de hilos de ejecución, memoria compartida y barreras de sincronización de la ejecución. Estas abstracciones guían al programador a dividir el problema en sub-problemas que pueden ser resueltos en forma paralela e independiente por medio de bloques de hilos de ejecución. A su vez cada sub-problema de divide en piezas más chicas que pueden ser resueltas en paralelo y cooperando entre ellas, usando los hilos de ejecución de cada bloque. Descomponer el problema de esta forma permite la escalabilidad automática en el número de procesadores, ya que cada bloque de hilos puede ser despachado hacia cualquier conjunto de procesadores (multiprocesador) disponible, en cualquier orden, concurrentemente o secuencialmente. De esta manera cualquier aplicación CUDA puede ejecutar sobre cualquier número de multiprocesadores y solo se necesita conocer este número en tiempo de ejecución. En la Figura \ref{fig:DiagramaEjecucionCUDA} se considera una aplicación CUDA que esta dividida en cuatro bloques y se muestra como se asignan los bloques de hilos de ejecución en dos GPU distintas, donde una tiene dos multiprocesadores y la otra tiene cuatro.

En la extensión del lenguaje C que hace CUDA es posible definir funciones (de la misma forma que en el lenguaje base) que a diferencia de las funciones normales de C, cuando son invocadas ejecutan $N$ veces en paralelo, mediante $N$ hilos de ejecución de CUDA diferentes. Estas funciones propias de CUDA son llamadas \emph{kernels}. Dentro de este tipo especial de funciones se tiene acceso a información propia de CUDA que indica por ejemplo, el identificador del hilo de ejecución o el identificador de bloque que lo contiene. Esta información es de vital importancia ya que es usada para parametrizar la ejecución del \emph{kernel} en función de los hilos de ejecución.

Un \emph{kernel} siempre es invocado desde el \emph{host} (CPU) y ejecuta en el \emph{device} (GPU). La GPU actúa como co-procesador de la CPU y mediante \emph{kernels} la CPU puede asignar trabajo al co-procesador. En la Figura \ref{fig:ModeloKernels} se muestra un ejemplo de una aplicación CUDA que posee un \emph{kernel} ``\emph{kernel A}''. Esta aplicación comienza ejecutando código secuencial en la CPU, en la primer parte secuencial se hace la invocación al \emph{kernel}, el cual ejecuta en la GPU. Una vez terminada la ejecución a nivel de GPU retorna a ejecutar código secuencial en la CPU.

El índice que identifica a un hilo de ejecución es un vector tridimensional, usando el mismo un hilo puede ser identificado usando una, dos o tres componentes del vector. De esta manera los hilos pueden forman un bloque de una, dos o tres dimensiones. Esta forma de agrupar los distintos hilos de un bloque permite invocar \emph{kernels} sobre distintos tipos de dominio (vector, matriz o volumen) de una manera más natural. Los bloques también pueden ser agrupados en una grilla (\emph{grid}) de una o dos dimensiones.

Como se muestra en la Figura \ref{fig:JerarquiaMemoriaCUDA}, cada hilo de CUDA puede acceder a múltiples espacios de memoria durante su ejecución, mientras que los diferentes espacios de memoria forman la jerarquía de memoria de la GPU.

En el primer nivel de la jerarquía (latencia más baja y menor capacidad de almacenamiento) se encuentran los registros, cada uno de ellos tiene 32 bits para almacenar un entero o un punto flotante. Cada hilo de ejecución tiene acceso una cierta cantidad de registros, donde la cantidad depende del modelo de la GPU, y puede llegar hasta un máximo de 1024 en los modelos más avanzados. Además cada hilo de ejecución tiene su propio espacio privado de memoria local. La memoria local a cada hilo es pequeña y su latencia es relativamente alta (tanto como la memoria global).

\begin{figure}[H]
    \centering
        \includegraphics[width=0.8\textwidth]{./Capitulo2/jerarquiaMemoria}
    \caption{Jerarquía de memoria de la GPU.}
    \label{fig:JerarquiaMemoriaCUDA}
\end{figure}

Cada bloque tiene un espacio de memoria compartida entre todos sus hilos, este espacio compartido tiene el mismo tiempo de vida que el bloque, es decir, es válido mientras el bloque se encuentra en ejecución. El espacio de memoria compartida de cada bloque es de 16 KB, posee una latencia baja, similar a la de los registros. Puede ser controlada totalmente por el programador y puede ser usada como un cache para mejorar los tiempos de acceso a la memoria global.

Además todos los hilos de ejecución de la aplicación tienen acceso a un mismo espacio de memoria global. Este espacio es el que tiene la mayor capacidad de almacenamiento dentro de la jerarquía de memoria llegando hasta 4 GB en los modelos \emph{Tesla}. La memoria global ofrece un alto ancho de banda (superior a 100 GB/s en el modelo \emph{Tesla}) pero padece de latencia alta (cientos de ciclos) y no posee cache.

Existen dos espacios más de solo lectura en la jerarquía que son accesibles por todos los hilos: el espacio de memoria constante y el espacio de memoria de textura. Ambos espacios de solo lectura tienen tiempo de vida igual al tiempo de ejecución de la aplicación CUDA y cada uno esta optimizado para distintos usos \cite{nVidiaCUDAWebSite}. Ambos espacios de memoria tienen la misma latencia que la memoria global aunque la de textura posee un cache de 8 KB por cada bloque, lo cual mejora el tiempo de acceso a los datos.


